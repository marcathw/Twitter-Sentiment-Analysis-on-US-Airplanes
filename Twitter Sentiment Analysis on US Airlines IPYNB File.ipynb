{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0089f23a-ab1c-4adf-8621-675e208995d0",
   "metadata": {},
   "source": [
    "### **DATASET OVERVIEW**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498c2afd-834f-4aab-b1e1-0c8e660e5e9e",
   "metadata": {},
   "source": [
    "Dataset source: [**Link**](https://www.kaggle.com/datasets/crowdflower/twitter-airline-sentiment/data)  \n",
    "A sentiment analysis job about the problems of each major U.S. airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045e9888-35d9-466a-885e-0fd6a9d057aa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **IMPORT LIBRARIES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f64b9609-1cdc-468f-8200-d6d896e50b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from gensim.models import Word2Vec, FastText\n",
    "import gensim.downloader as api\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45f7b2b2-6bbd-4ac9-8b3d-dde7c101e451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', quiet = True)\n",
    "nltk.download('stopwords', quiet = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ed8600-26d1-4665-b2f6-b70fde78b2e4",
   "metadata": {},
   "source": [
    "> Here, I've imported the neccessary libraries for the whole process of reading data to performing sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdf2088-090d-40c0-bd7f-1e28b004c23f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **READ DATA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11f0393a-ef51-40ae-bb56-9f8e70c3d6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Dataset/Tweets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57159525-f811-47a8-b276-a1cb565b17ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ad6700-a392-4ba7-b649-70fa67c1fda3",
   "metadata": {},
   "source": [
    "> Based on the output above, the data has been successfully read."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2744d82c-72eb-464d-a6c0-6fc2ef4da2b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **EDA AND PREPROCESSING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b20001f-c5b3-4e2d-b0d3-1583d2464701",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **DATA EXPLORATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a83431e4-1488-40ba-acc5-fb25c7a5d670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14640 entries, 0 to 14639\n",
      "Data columns (total 15 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   tweet_id                      14640 non-null  int64  \n",
      " 1   airline_sentiment             14640 non-null  object \n",
      " 2   airline_sentiment_confidence  14640 non-null  float64\n",
      " 3   negativereason                9178 non-null   object \n",
      " 4   negativereason_confidence     10522 non-null  float64\n",
      " 5   airline                       14640 non-null  object \n",
      " 6   airline_sentiment_gold        40 non-null     object \n",
      " 7   name                          14640 non-null  object \n",
      " 8   negativereason_gold           32 non-null     object \n",
      " 9   retweet_count                 14640 non-null  int64  \n",
      " 10  text                          14640 non-null  object \n",
      " 11  tweet_coord                   1019 non-null   object \n",
      " 12  tweet_created                 14640 non-null  object \n",
      " 13  tweet_location                9907 non-null   object \n",
      " 14  user_timezone                 9820 non-null   object \n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e15591e-3e80-4541-8644-5b5dca127eea",
   "metadata": {},
   "source": [
    "> The data conssists of 14640 observations and 15 columns.  \n",
    "> However, since I'm aiming to perform a sentiment analysis on the tweet, I'm keeping only the **text** section and the **airline_sentiment** (target).\n",
    "> The main reason is to avoid the model from capturing spurious correlations.  \n",
    "> For example, if I keep **retweet_count**, the model may miscalculate it with \"the more retweet the tweet have, the more positive the tweet is\", but in fact, people can retweet both positive and negative tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66679aa4-2d12-48e7-9ff5-845053866340",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[[\"text\", \"airline_sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8327bf39-c783-419c-8b6d-84a543c5bf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text airline_sentiment\n",
       "0                @VirginAmerica What @dhepburn said.           neutral\n",
       "1  @VirginAmerica plus you've added commercials t...          positive\n",
       "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
       "3  @VirginAmerica it's really aggressive to blast...          negative\n",
       "4  @VirginAmerica and it's a really big bad thing...          negative"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d9642e-33d2-45d7-ac51-10f452fbc68d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **DUPLICATES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f272aae0-bacd-422e-b166-da06bbc6ffd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c1aaec-581d-4e0d-9073-cb7ab26a0261",
   "metadata": {},
   "source": [
    "> From the 14640 observations in the data, there are 188 duplicated entries, so I will be dropping them to ensure that the model does not become overly influenced by repeated samples, which could lead to overfitting rather than genuine generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0c3ed2a-9017-462a-9887-87e2ffe3e5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1d0bf67-f5e6-4031-bff7-06a8cf1d0dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d5a716-3297-4274-ab6b-b8448f7f3cb5",
   "metadata": {},
   "source": [
    "> After removing duplicate observations, I check for identical texts assigned to different sentiment labels, as such inconsistencies may confuse the model during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08984e80-385e-4437-88ef-ffcfe46fdb2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2e591946-ec52-4557-b664-ab84ed4a9571",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12005</th>\n",
       "      <td>@AmericanAir - keeping AA up in the Air! My cr...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>@AmericanAir - keeping AA up in the Air! My cr...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>@AmericanAir @Clarkey_19 we done it with 1 tru...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12006</th>\n",
       "      <td>@AmericanAir @Clarkey_19 we done it with 1 tru...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002</th>\n",
       "      <td>@AmericanAir @RobertDwyer AA doesnt charge any...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11896</th>\n",
       "      <td>@AmericanAir @RobertDwyer AA doesnt charge any...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11997</th>\n",
       "      <td>@AmericanAir Believe me, I understand. Flight ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11843</th>\n",
       "      <td>@AmericanAir Believe me, I understand. Flight ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>@AmericanAir I don't think you should help him...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11876</th>\n",
       "      <td>@AmericanAir I don't think you should help him...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11998</th>\n",
       "      <td>@AmericanAir I might look into that. My wife t...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11866</th>\n",
       "      <td>@AmericanAir I might look into that. My wife t...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12013</th>\n",
       "      <td>@AmericanAir I was happy to purchase the upgra...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11973</th>\n",
       "      <td>@AmericanAir I was happy to purchase the upgra...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11944</th>\n",
       "      <td>@AmericanAir I'd like to apologize to the gate...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12007</th>\n",
       "      <td>@AmericanAir I'd like to apologize to the gate...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12008</th>\n",
       "      <td>@AmericanAir None of the #LAX flights into #DF...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11949</th>\n",
       "      <td>@AmericanAir None of the #LAX flights into #DF...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12448</th>\n",
       "      <td>@AmericanAir Thank you</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12889</th>\n",
       "      <td>@AmericanAir Thank you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11867</th>\n",
       "      <td>@AmericanAir Thank you, you too!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11999</th>\n",
       "      <td>@AmericanAir Thank you, you too!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11968</th>\n",
       "      <td>@AmericanAir Thanks so much!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12012</th>\n",
       "      <td>@AmericanAir Thanks so much!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001</th>\n",
       "      <td>@AmericanAir Trying desperately to get my boyf...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11884</th>\n",
       "      <td>@AmericanAir Trying desperately to get my boyf...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11911</th>\n",
       "      <td>@AmericanAir Would love to DM you, but my Twit...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12003</th>\n",
       "      <td>@AmericanAir Would love to DM you, but my Twit...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11918</th>\n",
       "      <td>@AmericanAir continues to win: I've never miss...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12004</th>\n",
       "      <td>@AmericanAir continues to win: I've never miss...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12014</th>\n",
       "      <td>@AmericanAir my flight to DFW from LIT on my w...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11976</th>\n",
       "      <td>@AmericanAir my flight to DFW from LIT on my w...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12454</th>\n",
       "      <td>@AmericanAir thank you</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13161</th>\n",
       "      <td>@AmericanAir thank you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12010</th>\n",
       "      <td>@AmericanAir thanks for the info Is there a nu...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11960</th>\n",
       "      <td>@AmericanAir thanks for the info Is there a nu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11952</th>\n",
       "      <td>@AmericanAir thanks!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>@AmericanAir thanks!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12011</th>\n",
       "      <td>@AmericanAir we are off to Kax premium.  Hopin...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11961</th>\n",
       "      <td>@AmericanAir we are off to Kax premium.  Hopin...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5500</th>\n",
       "      <td>@SouthwestAir Thank you!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4431</th>\n",
       "      <td>@SouthwestAir Thank you!</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5843</th>\n",
       "      <td>@SouthwestAir yes please</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4847</th>\n",
       "      <td>@SouthwestAir yes please</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10717</th>\n",
       "      <td>@USAirways thank you</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11535</th>\n",
       "      <td>@USAirways thank you</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3322</th>\n",
       "      <td>@united Thank you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>@united Thank you.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3554</th>\n",
       "      <td>@united thanks</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>@united thanks</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "12005  @AmericanAir - keeping AA up in the Air! My cr...          positive\n",
       "11919  @AmericanAir - keeping AA up in the Air! My cr...           neutral\n",
       "11926  @AmericanAir @Clarkey_19 we done it with 1 tru...           neutral\n",
       "12006  @AmericanAir @Clarkey_19 we done it with 1 tru...          positive\n",
       "12002  @AmericanAir @RobertDwyer AA doesnt charge any...           neutral\n",
       "11896  @AmericanAir @RobertDwyer AA doesnt charge any...          positive\n",
       "11997  @AmericanAir Believe me, I understand. Flight ...          negative\n",
       "11843  @AmericanAir Believe me, I understand. Flight ...          positive\n",
       "12000  @AmericanAir I don't think you should help him...           neutral\n",
       "11876  @AmericanAir I don't think you should help him...          positive\n",
       "11998  @AmericanAir I might look into that. My wife t...           neutral\n",
       "11866  @AmericanAir I might look into that. My wife t...          positive\n",
       "12013  @AmericanAir I was happy to purchase the upgra...          negative\n",
       "11973  @AmericanAir I was happy to purchase the upgra...          positive\n",
       "11944  @AmericanAir I'd like to apologize to the gate...           neutral\n",
       "12007  @AmericanAir I'd like to apologize to the gate...          negative\n",
       "12008  @AmericanAir None of the #LAX flights into #DF...          negative\n",
       "11949  @AmericanAir None of the #LAX flights into #DF...          positive\n",
       "12448                             @AmericanAir Thank you          positive\n",
       "12889                             @AmericanAir Thank you           neutral\n",
       "11867                   @AmericanAir Thank you, you too!           neutral\n",
       "11999                   @AmericanAir Thank you, you too!          positive\n",
       "11968                       @AmericanAir Thanks so much!           neutral\n",
       "12012                       @AmericanAir Thanks so much!          positive\n",
       "12001  @AmericanAir Trying desperately to get my boyf...           neutral\n",
       "11884  @AmericanAir Trying desperately to get my boyf...          negative\n",
       "11911  @AmericanAir Would love to DM you, but my Twit...           neutral\n",
       "12003  @AmericanAir Would love to DM you, but my Twit...          negative\n",
       "11918  @AmericanAir continues to win: I've never miss...          positive\n",
       "12004  @AmericanAir continues to win: I've never miss...          negative\n",
       "12014  @AmericanAir my flight to DFW from LIT on my w...          negative\n",
       "11976  @AmericanAir my flight to DFW from LIT on my w...           neutral\n",
       "12454                             @AmericanAir thank you          positive\n",
       "13161                             @AmericanAir thank you           neutral\n",
       "12010  @AmericanAir thanks for the info Is there a nu...           neutral\n",
       "11960  @AmericanAir thanks for the info Is there a nu...          positive\n",
       "11952                               @AmericanAir thanks!           neutral\n",
       "12009                               @AmericanAir thanks!          positive\n",
       "12011  @AmericanAir we are off to Kax premium.  Hopin...          positive\n",
       "11961  @AmericanAir we are off to Kax premium.  Hopin...           neutral\n",
       "5500                            @SouthwestAir Thank you!          positive\n",
       "4431                            @SouthwestAir Thank you!           neutral\n",
       "5843                            @SouthwestAir yes please           neutral\n",
       "4847                            @SouthwestAir yes please          positive\n",
       "10717                               @USAirways thank you          positive\n",
       "11535                               @USAirways thank you           neutral\n",
       "3322                                  @united Thank you.          positive\n",
       "613                                   @united Thank you.           neutral\n",
       "3554                                      @united thanks           neutral\n",
       "503                                       @united thanks          positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "duplicates = data[data['text'].duplicated(keep = False)].sort_values('text')\n",
    "\n",
    "display(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff1b20e-db32-455b-8efd-26c4c98558ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop_duplicates(subset = 'text', keep = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02b4bab9-6070-44bc-929a-fa9901f3b30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"text\"].duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40327632-da11-409b-86c5-c7c0a4d0c161",
   "metadata": {},
   "source": [
    "> Here, I have removed all duplicates and identical texts with conflicting sentiment labels to ensure data consistency before proceeding to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa566d9-46be-4a8f-9152-366b1a0e1ef9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **CARDINALITY CHECK**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41e8fe2c-a8e9-4714-bc9f-8b35005a6629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 14402 entries, 0 to 14451\n",
      "Data columns (total 2 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   text               14402 non-null  object\n",
      " 1   airline_sentiment  14402 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 337.5+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a23270a7-b3ae-472a-8aee-3fcf855f1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cardinality Check Result:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column name</th>\n",
       "      <th>data type</th>\n",
       "      <th>unique values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text</td>\n",
       "      <td>object</td>\n",
       "      <td>14402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>airline_sentiment</td>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         column name data type  unique values\n",
       "0               text    object          14402\n",
       "1  airline_sentiment    object              3"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cardinal = pd.DataFrame({\n",
    "    \"column name\": data.columns.tolist(),\n",
    "    \"data type\": [data[c].dtype for c in data.columns],\n",
    "    \"unique values\": [data[c].nunique() for c in data.columns]\n",
    "})\n",
    "print(\"Cardinality Check Result:\")\n",
    "cardinal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a317c6-43b8-49fe-8802-63a3a1ab39de",
   "metadata": {},
   "source": [
    "> Here, I can infer that the texts inside the data are all unique with 3 different sentiments.  \n",
    "> This confirms that no redundant textual data remain, ensuring a clean and unbiased foundation for sentiment classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8867561-725d-49e2-8100-cd50620eb76c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **MISSING VALUES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28fa43a2-f0f1-4f67-a664-458fb25dec25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text                 0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d729d97b-0293-40af-966c-566e78ac3b44",
   "metadata": {},
   "source": [
    "> The data has no missing observations.  \n",
    "> Hence, further handling is unneccessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe7bcfd-52b6-4ed2-ab6b-55b55a1260ac",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **DATA DISTRIBUTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9be5c281-f040-41df-a289-75f14d574e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'positive' 'negative'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data[\"airline_sentiment\"].unique(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49bc5e0-efef-4a05-9eec-44cfc2af1b20",
   "metadata": {},
   "source": [
    "> The data contains three sentiment classes: positive, neutral, and negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a855ec8-f254-4486-9691-7553dd5bb8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (11521, 2)\n",
      "Test Shape: (2881, 2)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = train_test_split(data, test_size = 0.2, stratify = data[\"airline_sentiment\"], random_state = 42)\n",
    "print(f\"Train Shape: {train_data.shape}\")\n",
    "print(f\"Test Shape: {test_data.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e97b408-b1ce-4e38-be45-3e7282b8bacc",
   "metadata": {},
   "source": [
    "> Here, I perform a train-test split to prevent data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82eceee7-f096-4885-8065-eaf2cde11355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='airline_sentiment', ylabel='count'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x = \"airline_sentiment\", data = train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dd5637-7c5f-4aac-b910-cabf1cdbd00e",
   "metadata": {},
   "source": [
    "> Based on the sentiment distribution above, it can be inferred that the data is highly imbalanced, with negative sentiment samples being roughly three to four times more frequent than the positive and neutral ones.  \n",
    "> This imbalance may cause the model to favor the negative class.  \n",
    "> Therefore, one of the main objectives of this notebook is to compare model performance before and after applying imbalance handling techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19e66f58-d43c-4ea3-b04a-b4c0ae9209e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1sAAAIkCAYAAADoPzGlAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAfp1JREFUeJzs3Xl8lOW9///3PftM9j0EkhB2BMQNcQc33LXa1q1arLTH/lxROJ56bI9oPbgdqf3KsbWnVFzq0rprqwUroIgogihKZJGQsCSEQPbZZ+7fHyFTImELM0yW1/PxyAPmnmuu+Uzu3Mm8577u6zJM0zQFAAAAAIgrS7ILAAAAAIDeiLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFADggCxculGEYmjFjRrJL6dEMw9DEiROT8tzXXXedDMPQxo0bY9u6w34dOHCgBg4cmLTnB4BEIWwBwGG2ePFiGYahiy66qNP7b7jhBhmGoaOPPrrT+3/961/LMAw9/PDDiSyzT5g4caIMwzjoxw0cOFCGYcS+nE6n8vLydPzxx+umm27S4sWLE1CtNGPGDBmGoYULFyak/0TpLOQBQF9gS3YBANDXjB8/XikpKfrggw8UiURktVo73N9+puGLL77Qzp07lZ2dvcf9knT66acfrpLRCavVql/+8peSpHA4rPr6eq1atUpPPvmknnjiCV100UV6+umnlZWV1eFx5eXl8ng8yShZDzzwgH7xi1+of//+SXn+vfnnP/+Z7BIAICEIWwBwmNntdp188smaN2+eVqxYoXHjxsXuq66u1tq1a3XZZZfp1Vdf1aJFi3TppZfG7g8Gg/r444+Vnp6uY445JhnlYxebzdbp0LvKykpNmTJFb731li699FK9//77slj+NZBkxIgRh7HKjvr166d+/fol7fn3ZvDgwckuAQASgmGEAJAE7WelvjscrP32tGnTlJqausf9n3zyiXw+n0477bQOZ8TefvttnX766crIyJDb7dZRRx2lxx57TJFIpMPjN27cKMMwdN111+mbb77RZZddptzc3A5DvHw+n37xi1+ouLhYLpdLo0eP1v/93//t8/VUVFTo5z//ucrKyuR0OpWfn6+JEydq7ty5e7R9+umndcIJJyg1NVWpqak64YQT9PTTT+/Rbu7cuTIMo9M+9nadUfv1UNu3b9f111+v/Px8ud1unXDCCXt8Lw3D0KJFi2L/b/+67rrr9vla96e0tFRvvfWWjjjiCC1atEgvv/xypzXurrGxUf/1X/+lI444QqmpqcrIyNCIESP0k5/8RJs2bZLUNuTx3nvvldT289Ne7+7XOrVf+9TQ0KBbb71VxcXFstlsse/h/obzffDBB5owYYJSU1OVnZ2tq6++Wps3b96j3b6uO/vu9VcDBw6M7d+ysrJY3bs/fm/XbHm9Xs2YMUMjRoyQy+VSdna2LrjgAi1ZsmSPtrsPsfzLX/6iY445Rm63W/369dOtt94qn8/Xab0AkEic2QKAJGgPWwsWLNC///u/x7YvWLBAaWlpOv7443XyySdrwYIFHR7Xfnv3IYS//e1vNXXq1Nib45SUFL311lu6/fbb9eGHH+rll1/e47qk9evX64QTTtCoUaM0efJk7dy5Uw6HQ9FoVBdffLHee+89jRkzRldffbV27Nih22+/fa/DFj/++GOdd955ampq0jnnnKMrr7xS9fX1+vzzz/Xb3/62Q3i5/fbb9dhjj6l///6aMmWKDMPQK6+8ouuuu05ffPGFZs2adUjfV0lqaGjQySefrPT0dP3oRz9SbW2tXnrpJZ1zzjlavny5Ro8eLUm65557NHfuXFVWVuqee+6JPf6oo4465BrcbremT5+u66+/Xi+99JIuv/zyvbY1TVPnnHOOPvnkE5188sk699xzZbFYtHHjRr322muaPHmyiouLY9/HRYsWafLkybFwkpmZ2aG/QCCgM844Q83NzbrooovkcDhUUFCw35qXLl2qBx54QBdccIFuvfVWrVixQi+88IIWL16sZcuWHVAfnZk6darmzp2rL774Qrfddlus3v1NiBEIBHTmmWdq6dKlOuaYYzR16tTYvpw3b55eeuklXXbZZXs87n//93/1zjvv6JJLLtHEiRP17rvv6vHHH9eOHTv05z//uUuvAQC6zAQAHHbhcNhMS0sz09LSzFAoFNs+dOhQ89xzzzVN0zRnzpxpGoZhbt++PXb/6aefbkoyV6xYYZqmaX777bemzWYz8/Pzzaqqqli7QCBgTpgwwZRkPvvss7HtFRUVpiRTkvmrX/1qj7qeeuopU5J57rnnmuFwOLb9yy+/NB0OhynJvOeee2Lb/X6/WVxcbFosFvOdd97Zo79NmzbF/v/BBx+YksyRI0eaDQ0Nse0NDQ3miBEjTEnmhx9+uEctTz311B79LliwYI9aTNOMvbYbb7zRjEQise1//OMfTUnmDTfc0KF9+/foYJWWlppOp3Ofbb799ltTkllcXLxHjRMmTIjd/vLLL01J5qWXXrpHH36/32xubo7dvueee0xJ5oIFC/ZalyRz0qRJptfr3eP+yZMnm5LMioqK2Lb276Uk849//GOH9vfee68pybz++uv3+Rq+W0Npael+n3d/j7nvvvtMSeaPfvQjMxqNxrZ/8cUXptPpNLOyssympqbY9vbvTUZGhvnNN9/Etnu9XnPYsGGmYRjmli1bOn1+AEgUhhECQBJYrVadeuqpam5u1vLlyyVJW7du1bp16zRhwgRJ0oQJE2SaZmyoWzAY1NKlS5WVlaWxY8dKkv785z8rHA5r2rRpKi4ujvXvcDj04IMPSlKnw/AKCwtjkzvs7plnnpEk/fd//3eHYYpjxozRtddeu0f7N998U5s2bdI111yjc889d4/7BwwYEPt/ex0zZsxQRkZGbHtGRkbszFJntR6slJQUPfTQQx2uk5o8ebJsNpuWLVt2yP0fqKKiIklSXV3dAbV3u917bHM6nUpNTT3o537kkUc67W9fhg8fruuvv77Dtn//939XXl6eXnjhBQWDwYOu41DMnTtXdrtdDz74YIczs0ceeaSuu+461dfX64033tjjcbfddpuGDx8eu+12u3XVVVfJNM3YsQYAhwthCwCSZPehhNK/rtdqv5Zl3Lhx8ng8sfuXLl0qn8+niRMnxoLE559/3uExuzvhhBPkdru1cuXKPe4bO3asHA7HHtu/+OILeTyeTiffOPXUU/fY9umnn0qSJk2atI9Xqv3W2r6ts1oP1tChQ/cIKDabTQUFBWpoaDjk/g+UaZoH1G7kyJEaM2aMnn/+eZ122mmaNWuWli1btsf1dgfK5XJpzJgxB/24k08+eY/hpm63W8cee6x8Pp/Wrl3bpXq6oqmpSRs2bNCQIUM6BPZ2+/p56exnt72Pw7n/AUAibAFA0pxxxhmS/hWyFixYoJSUFB133HGS2mYtPPHEEzvcL3W8XqupqUmS9no9TX5+vhobG/fYvrf2jY2Nys/P7/S+zh7T/ub1QKYSb2pqksViUV5eXqd9WyyWTms9WLufNdudzWbrcoDpiurqaknq9PXuzmaz6f3339dNN92k9evXa9q0aTr++ONVWFio++6776Brzs/P79LaYfvb7/HYNwdqfz/XhYWFe62ps/1vs7Vdon449z8ASIQtAEiao446SllZWVq8eLHC4bAWLlyok08+OfbGUGr7BP/rr79WbW1tp+trpaenS5K2bdvW6XPU1tbG2uxub2/GMzIyVFtb2+l9nT1H+2QHW7Zs6fQxu0tPT1c0GtX27ds7rTMajXaotf3sXTgc3qP94Xzj31Xt+2v3qf33Jjc3V7Nnz9aWLVu0evVqzZ49Wzk5ObrnnnsOevHqrgQtSfvd77uHGMMwOt0vUnz2zf5+rtu3d/azDQDdCWELAJLEYrHotNNOU2trq15//XWtX78+dr1Wu/bb8+bN09KlS5WXl6dRo0bF7j/66KMl7TmFvNQ2xM/n8x3U7Hpjx46V1+vVihUr9rjvww8/3GPb8ccfH6tvf/ZVa/t1abvX2r4YcGdBrn1I4qFqvy4t3mc8fD6fHn30UUnSVVdddcCPMwxDI0eO1E033aT58+dLarsurl2i6pWkjz76aI+hjz6fT8uXL5fb7dawYcNi27OysjrdLxs3bux0qN7B1p2enq5BgwZp/fr1nT5PZz8vANAdEbYAIInaz1K1r5/03euZjj/+eLlcLj300EPy+/2aOHFihzMXV199tWw2m2bNmqWtW7fGtodCIf3iF7+QpINaN6p9Eoy77767wxvjVatW6dlnn92j/cUXX6wBAwboueee0z/+8Y897t/9jfLkyZNjr7V9mJjUNmSs/fW3t5Harr0xDEMvvvii/H5/bPu6dev029/+9oBf075kZ2dLUqdrSXVVZWWlLrroIq1evVqnn356p9OT766iokKrV6/eY3v72ZvdJ7pIRL3t1qxZoz/96U8dtj3yyCPavn27rrrqqg7X+B133HHauHFjh+AcDAZ1xx13dNp3V+qePHmyQqGQ7rrrrg4h8KuvvtJTTz2ljIwMfe973zvg/gAgGVhnCwCSqD1sffXVV/J4PHsMOXM6nR0W5P3uWleDBw/WQw89pGnTpunII4/U5ZdfrpSUFL399tv65ptvdMkll+iaa6454HomT56s559/Xu+++66OPvponXfeedq5c6deeOEFTZo0SW+//fYe9f3lL3/Rueeeq/POO0/nnnuuxo4dq6amJq1cuVJerzd2Fuq0007TLbfcoscff1yjR4/W97//fZmmqVdffVWbNm3SrbfeqtNOOy3Wd//+/XXFFVfoxRdf1LHHHqtzzz1XtbW1eu2113TuuefqlVdeOeDXtTdnnHGGXn75Zf3whz/U+eefH5tc4oILLtjvY8PhcGxR5Ugkovr6eq1atUofffSRIpGILrnkktjCzPvyxRdf6NJLL9W4ceM0evRoFRYWasuWLXr99ddltVo1bdq0WNv2xYzvvvtuffPNN8rIyFBGRob+v//v/zuk74PUNsnJjTfeqL/97W8aMWKEVqxYoX/84x8qLi7WzJkzO7S9/fbbNW/ePF1wwQW66qqr5PF4NH/+fGVmZqpfv3579H3GGWfof/7nf3TDDTfohz/8oVJSUlRSUqKrr756r/Xceeed+tvf/qZnn31W5eXlOvPMM7V9+3a99NJLCoVCeuaZZ5SWlnbIrxsAEiqZ884DQF8XjUbN3NxcU5J51llnddqmff0gSWZ5eXmnbd544w1zwoQJZlpamul0Os0xY8aYjz76aIc1vEzzX+tsTZ48ea81tba2mnfeeafZv39/0+l0mkcccYT55JNP7nVtK9M0zfXr15tTpkwxBwwYYNrtdjM/P9+cOHGi+cwzz+zR9k9/+pM5btw40+PxmB6Pxxw3bpz5pz/9aa+13HLLLWZBQYHpdDrNI4880vzzn/+8z3W2Dmb9p1AoZN55551mSUmJabPZ9vu92b2v9n0iyXQ4HGZubq45btw488YbbzQXL16818d+t8ZNmzaZv/jFL8wTTjjBzM/PNx0Oh1lSUmL+4Ac/MD/55JM9Hj937lxzzJgxptPpNCV1eE2dvcbd7WudrXvuucdctGiReeqpp5oej8fMzMw0r7zyyg7rt+3upZdeMseMGWM6HA6zsLDQvOWWW8zm5ua91vDwww+bQ4cONe12+x7fg709pqWlxfzVr35lDhs2zHQ4HGZmZqZ53nnndViPrd2+1iDb15ptAJBIhmke4Ny0AAAAAIADxjVbAAAAAJAAhC0AAAAASADCFgAAAAAkAGELAAAAABKAsAUAAAAACUDYAgAAAIAEYFHjAxSNRrV161alpaXtd4FKAAAAAL2XaZpqbm5WUVGRLJa9n78ibB2grVu3qri4ONllAAAAAOgmNm3apAEDBuz1fsLWAUpLS5PU9g1NT09PcjUAAAAAkqWpqUnFxcWxjLA3hK0D1D50MD09nbAFAAAAYL+XFyV1gowPPvhAF110kYqKimQYhl5//fXYfaFQSP/xH/+hMWPGKCUlRUVFRfrxj3+srVu3dugjEAjolltuUW5urlJSUnTxxRdr8+bNHdrU19fr2muvVUZGhjIyMnTttdeqoaHhMLxCAAAAAH1VUsNWa2urxo4dq9mzZ+9xn9fr1YoVK/SrX/1KK1as0Kuvvqq1a9fq4osv7tBu6tSpeu211/Tiiy9q8eLFamlp0YUXXqhIJBJrc/XVV2vlypV699139e6772rlypW69tprE/76AAAAAPRdhmmaZrKLkNpOwb322mv63ve+t9c2y5Yt0/HHH6/KykqVlJSosbFReXl5evbZZ3XFFVdI+tdEFn//+991zjnnqLy8XEcccYSWLl2q8ePHS5KWLl2qE088Ud98842GDx9+QPU1NTUpIyNDjY2NDCMEAAAA+rADzQY9ap2txsZGGYahzMxMSdLy5csVCoU0adKkWJuioiKNHj1aS5YskSR9/PHHysjIiAUtSTrhhBOUkZERa9OZQCCgpqamDl8AAAAAcKB6TNjy+/36xS9+oauvvjqWHmtqauRwOJSVldWhbUFBgWpqamJt8vPz9+gvPz8/1qYzDzzwQOwar4yMDKZ9BwAAAHBQekTYCoVCuvLKKxWNRvXEE0/st71pmh1mBulslpDvtvmuu+66S42NjbGvTZs2da14AAAAAH1Stw9boVBIl19+uSoqKjR//vwOYyILCwsVDAZVX1/f4TG1tbUqKCiItdm2bdse/W7fvj3WpjNOpzM2zTvTvQMAAAA4WN06bLUHrXXr1um9995TTk5Oh/uPPfZY2e12zZ8/P7aturpaX331lU466SRJ0oknnqjGxkZ9+umnsTaffPKJGhsbY20AAAAAIN6SuqhxS0uL1q9fH7tdUVGhlStXKjs7W0VFRfrBD36gFStW6O2331YkEoldY5WdnS2Hw6GMjAxNmTJF06ZNU05OjrKzszV9+nSNGTNGZ511liRp5MiROvfcc/Wzn/1MTz75pCTp3/7t33ThhRce8EyEAAAAAHCwkjr1+8KFC3X66afvsX3y5MmaMWOGysrKOn3cggULNHHiREltE2f8+7//u55//nn5fD6deeaZeuKJJzpMaLFz507deuutevPNNyVJF198sWbPnh2b1fBAMPU7AAAAAOnAs0G3WWeruyNsAQAAAJB66TpbAAAAANBTELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlgS3YBAAD0JFVVVaqrq0tY/7m5uSopKUlY/wCAw4ewBQDAAaqqqtLIkSPl9XoT9hwej0fl5eUELgDoBQhbAAAcoLq6Onm9Xv1y9hyVDhke9/4r16/R/TdPUV1dHWELAHoBwhYAAAepdMhwDT/yqGSXAQDo5pggAwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAEkNWx988IEuuugiFRUVyTAMvf766x3uN01TM2bMUFFRkdxutyZOnKivv/66Q5tAIKBbbrlFubm5SklJ0cUXX6zNmzd3aFNfX69rr71WGRkZysjI0LXXXquGhoYEvzoAAAAAfVlSw1Zra6vGjh2r2bNnd3r/ww8/rFmzZmn27NlatmyZCgsLdfbZZ6u5uTnWZurUqXrttdf04osvavHixWppadGFF16oSCQSa3P11Vdr5cqVevfdd/Xuu+9q5cqVuvbaaxP++gAAAAD0XbZkPvl5552n8847r9P7TNPUY489prvvvluXXXaZJOnpp59WQUGBnn/+ed1www1qbGzUnDlz9Oyzz+qss86SJD333HMqLi7We++9p3POOUfl5eV69913tXTpUo0fP16S9H//93868cQTtWbNGg0fPrzT5w8EAgoEArHbTU1N8XzpAAAAAHq5bnvNVkVFhWpqajRp0qTYNqfTqQkTJmjJkiWSpOXLlysUCnVoU1RUpNGjR8fafPzxx8rIyIgFLUk64YQTlJGREWvTmQceeCA27DAjI0PFxcXxfokAAAAAerFuG7ZqamokSQUFBR22FxQUxO6rqamRw+FQVlbWPtvk5+fv0X9+fn6sTWfuuusuNTY2xr42bdp0SK8HAAAAQN+S1GGEB8IwjA63TdPcY9t3fbdNZ+3314/T6ZTT6TzIagEAAACgTbc9s1VYWChJe5x9qq2tjZ3tKiwsVDAYVH19/T7bbNu2bY/+t2/fvsdZMwAAAACIl24btsrKylRYWKj58+fHtgWDQS1atEgnnXSSJOnYY4+V3W7v0Ka6ulpfffVVrM2JJ56oxsZGffrpp7E2n3zyiRobG2NtAAAAACDekjqMsKWlRevXr4/drqio0MqVK5Wdna2SkhJNnTpVM2fO1NChQzV06FDNnDlTHo9HV199tSQpIyNDU6ZM0bRp05STk6Ps7GxNnz5dY8aMic1OOHLkSJ177rn62c9+pieffFKS9G//9m+68MIL9zoTIQAAAAAcqqSGrc8++0ynn3567PYdd9whSZo8ebLmzp2rO++8Uz6fTzfeeKPq6+s1fvx4zZs3T2lpabHH/OY3v5HNZtPll18un8+nM888U3PnzpXVao21+fOf/6xbb701NmvhxRdfvNe1vQAAAAAgHgzTNM1kF9ETNDU1KSMjQ42NjUpPT092OQCAJFixYoWOPfZY/d+7izX8yKPi3v+aL1fqZ+eeouXLl+uYY46Je/8AgPg40GzQba/ZAgAAAICejLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEACELYAAAAAIAEIWwAAAACQAIQtAAAAAEgAwhYAAAAAJABhCwAAAAASgLAFAAAAAAlA2AIAAACABCBsAQAAAEAC2JJdAAAA6P284ahqfWGFoqbsFkNOiyGn1aIsp0WGYSS7PABICMIWAACIu1DU1Or6gNY2BFTri6g5FO20XYrN0KB0hwanO1SWbpfTyqAbAL0HYQsAAMTNDn9YK+r8+mpnQIGI2eG+LKdFLqtFoaipYMSUNxxVa9jUqp0BrdoZkNNi6PgCt8blueWwcrYLQM9H2AIAAIfMH47qg2qvPq/zqz1iZTosGpvjUnGqXXlu6x5nrcJRU5tbQvq2Kah1jUE1BKP6sNqr5dt9OrHAo2NyXbJaCF0Aei7CFgAA6DLTNPXVzoAWbG2VN9wWs4akO3RMnktlafZ9Xo9lsxgamO7QwHSHzuhvqrw+qA+qW9UQjOqfW1q1uj6gSwamKdNpPVwvBwDiirAFAAC6xBuO6u2NzdrQHJIk5TitOrs4RQPTHAfdl2EYOiLbqeFZDn25w69FW72q9ob11JoGXVCSqmGZzniXDwAJR9gCAAAHbWtrSK9XNKspFJXNkE4u9Oj4fPchD/uzGoaOznVrULpDb1Q0a6s3rFcrmjUuL6TT+6fIwsyFAHoQwhYAADhgpmnq8zq/3tvSqqjZNunFpWXpynfH9y1FhsOqHw3N0MKtrVq23a9l2/1qDZu6oDRVVgIXgB6CsAUAAA6IaZp6b0urlm/3S5KGZTh0fmmqXLsmvqiqqlJdXV1cnzNL0pHyaJWRo9X1AYWjpi4ZmMbEGQB6BMIWAADYr3DU1NuVzfqmIShJmljk0fh8d2wCjKqqKo0cOVJerzchzz/27It09UNztLYxqFcqmnRpWbrsBC4A3RxhCwAA7FMgEtWrG5pV2RKSxZAuLE3TEVkdJ6yoq6uT1+vVL2fPUemQ4XF9/sr1a3T/zVP0yIPb9YUlXxuaQnq9oknfH5TONVwAujXCFgAA2Ct/OKoXv21SjTcsh8XQZWVpGpi+99kGS4cM1/Ajj0pILTny64ohGXppfaO+bQpp3qZWnVOcss/p5QEgmSz7b5I84XBYv/zlL1VWVia3261BgwbpvvvuUzQajbUxTVMzZsxQUVGR3G63Jk6cqK+//rpDP4FAQLfccotyc3OVkpKiiy++WJs3bz7cLwcAgB7FH47qxfVtQcttM3T10Ix9Bq3DoTjVrosHpkmSVu7wa+k2X1LrAYB96dZh66GHHtLvf/97zZ49W+Xl5Xr44Yf1yCOP6PHHH4+1efjhhzVr1izNnj1by5YtU2Fhoc4++2w1NzfH2kydOlWvvfaaXnzxRS1evFgtLS268MILFYlEkvGyAADo9vzhqF5Y36ga366gNSRDhZ7uMSBmWKZTZw9IkSQtqvbq653+JFcEAJ3r1mHr448/1iWXXKILLrhAAwcO1A9+8ANNmjRJn332maS2s1qPPfaY7r77bl122WUaPXq0nn76aXm9Xj3//POSpMbGRs2ZM0ePPvqozjrrLB199NF67rnntGrVKr333nvJfHkAAHRL7UFrmy8iz66glRfnqd0P1bF5bo3Lc0mS/lbVoi2toSRXBAB76tZh65RTTtE///lPrV27VpL0xRdfaPHixTr//PMlSRUVFaqpqdGkSZNij3E6nZowYYKWLFkiSVq+fLlCoVCHNkVFRRo9enSsTWcCgYCampo6fAEA0NuFoqb+uqEpFrSu6oZBq90Z/VM0LMOhqCm9UdEsbzi6/wcBwGHUrcPWf/zHf+iqq67SiBEjZLfbdfTRR2vq1Km66qqrJEk1NTWSpIKCgg6PKygoiN1XU1Mjh8OhrKysvbbpzAMPPKCMjIzYV3FxcTxfGgAA3U4kauq1iiZtaQ3LaTV0ZTcOWpJkGIYuKE1VltOiplBUb21slmmayS4LAGK6ddh66aWX9Nxzz+n555/XihUr9PTTT+t//ud/9PTTT3do991ZiEzT3O/MRPtrc9ddd6mxsTH2tWnTpq6/EAAAujnTNPW3qhZtaArJZkg/HJSu/G4ctNo5rRZdWpYumyFVNIe0hAkzAHQj3Tps/fu//7t+8Ytf6Morr9SYMWN07bXX6vbbb9cDDzwgSSosLJSkPc5Q1dbWxs52FRYWKhgMqr6+fq9tOuN0OpWent7hCwCA3sg0Tc3f3KrV9QFZDOmyQekakGpPdlkHLN9t0znFqZKkD6u92tgUTHJFANCmW4ctr9cri6VjiVarNTb1e1lZmQoLCzV//vzY/cFgUIsWLdJJJ50kSTr22GNlt9s7tKmurtZXX30VawMAQF/2YY1XK+raZvS7qDRNg5I8vXtXjMlxaWxO20LLb1Vy/RaA7qFbjw+46KKL9N///d8qKSnRqFGj9Pnnn2vWrFm6/vrrJbUNH5w6dapmzpypoUOHaujQoZo5c6Y8Ho+uvvpqSVJGRoamTJmiadOmKScnR9nZ2Zo+fbrGjBmjs846K5kvDwCApFtW69OSmrahd5MGpGhkljPJFXXdWQNStaU1rDp/RP/Y1KLvDUxjwWMASdWtw9bjjz+uX/3qV7rxxhtVW1uroqIi3XDDDfqv//qvWJs777xTPp9PN954o+rr6zV+/HjNmzdPaWlpsTa/+c1vZLPZdPnll8vn8+nMM8/U3LlzZbVak/GyAADoFlbt8OufW1olSaf28+iYPHeSKzo0douhC0vT9MyaBq1pCOrr+oBGZ7uSXRaAPqxbh620tDQ99thjeuyxx/baxjAMzZgxQzNmzNhrG5fLpccff7zDYsgAAPRl6xuD+ntViyTpuDyXTiro2UGrXaHHppP7efRhtVfzN7eqJNWudAcfrgJIjm59zRYAAIi/ra0hvbGxSaak0dlOndk/pVcNtzuxwK0ij02BiKm/VbYwHTyApCFsAQDQh9QHIvrrhiaFotKgNLvOK0ntVUFLkixG23BCu0WqbAlp5Q5/sksC0EcRtgAA6CNaQ1G9tL5RvrCpQrdN3ytLl7WXBa122S6rJvRLkSQt3OJVczCS5IoA9EWELQAA+oBgxNRfNzSpIRhVhsOiHw5Ol8PaO4NWu2PyXG3DCaNt64gBwOFG2AIAoJeLmqbe2NikGm9YbquhKwZnKMXe+98CWAxD55akyiJpbWNQaxoCyS4JQB/T+3/TAgDQh5mmqXc3tejbppBshvSDwenKdvWd2fny3TaN3zXT4vxNrfJHWOwYwOFD2AIAoBdbXOPVlzsCMiRdUpam/in2ZJd02J1c6FGW06KWcFSLtnqTXQ6APoSwBQBAL/VFnV8f1fgkSZOKUzQ0w5nkipLDZjF0bnGqJOnzOr9qvOEkVwSgryBsAQDQC61vDOrdTW2LFp9U4NbRub1j0eKuKk1zaFRWW9ict4m1twAcHoQtAAB6md0XLR6T7dSp/TzJLqlbmNjfI4fF0FZvWKt2MlkGgMQjbAEA0IvsvmhxWZpd5/bCRYu7Ks1u1cmFbWf4Fm5tlT/MZBkAEouwBQBAL7H7osUFbqsu7cWLFnfVcXlu5Tit8oZNLa5hsgwAiUXYAgCgFwhGTL3cYdHijF6/aHFXWC2GzhqQIklavt2vWh+TZQBIHMIWAAA9XPuixdW7LVqc2gcWLe6qsnSHhmU4ZEpasKU12eUA6MX4TQwAQA/W1xct7qrT+6fIYkgVzSFtaAomuxwAvRRhCwCAHuyjGl+fX7S4K7KcVh2b65Ikvb+lVVGmggeQAIQtAAB6qK92+mOTPPTlRYu76uRCj1xWQ3X+iL7cwVTwAOKPsAUAQA9U2RzU36vaFi0en8+ixV3hsll0cmHbGmQfVLcqEGEqeADxRdgCAKCH2eEP69WKZkVNaUSmQxOLWLS4q47JdSnLaZE3bOqTbb5klwOglyFsAQDQg7SGovrLt00KREz1T7HpgtI0Fi0+BFaLoYlFbVPBf1rrU3MokuSKAPQmhC0AAHqIUNTUKxua1BiMKtNh0ffL0mW3ELQO1bAMh/qn2BQ2pSU1nN0CED+ELQAAegDTNPV2ZbO2esNyWQ39cHC6PKylFReGYWhCv7azW1/U+VUf4OwWgPjgtzQAAD3Agq1erWkIympIlw1KV47LluySepWSNLvK0uyKSlpc7U12OQB6CcIWAADd3Mo6vz6tbRvedn5JqkpSWUsrESbsunbr6/qAan3hJFcDoDfgYzEAALqxquaQ5m1qm+L91H4ejcp2db2vqirV1dXFq7QOysvLE9Lv4VTosWlEpkPfNAT1wVavfjA4PdklAejhCFsAAHRTDYGIXtvYpKikI7KcOqmg62tpVVVVaeTIkfJ6EztErqWlJaH9J9qp/Txa0xDU+qagNreENICziAAOAWELAIBuKBhpm3nQFzZV6LbpvJLUQ5riva6uTl6vV7+cPUelQ4bHsdI2SxfM05yH7pPf749734dTjsumI3Oc+mJHQItrvLpySEaySwLQgxG2AADoZkxJb1c2a7s/ohSbocsGpcVtivfSIcM1/Mij4tLX7irXrYl7n8lyUqFHq3YEtLE5pE0tIRVzdgtAFzFBBgAA3cwGpWtt479mHkx3WJNdUp+S4bDqyJy2a+M+qmFmQgBdR9gCAKAbGXXGhfrWyJQknVOcqv4pnFVJhhML3bJIsbNbANAVhC0AALqJsM2py389W5J0XJ4rdnYFhx9ntwDEA2ELAIBuIBQ11ZTRXw53irJNn87on5Lskvo8zm4BOFRMkAEAQJKZpqk1DUFFrXbt2FSh0wfYZTGKk11Wt5PItbxyc3NVUlLSYVv72a2VO/xaXO3VVUOZmRDAwelS2KqoqFBZWVm8awHQQyVyoVSp8zdBQG9S1RJWYzAqRaN6Zuo1uurlF5JdUreyo7ZGMgxdc801CXsOj8ej8vLyPX7XnFjo1pc7/KpsCWlLa4hr6AAclC6FrSFDhui0007TlClT9IMf/EAuF2PKgb7qcCyUurc3QUBvsNMf0ebWsCQprblGtRVrk1xR99PS2CiZpm7+9aMaO2583PuvXL9G9988RXV1dZ2e3RqV7dSqnQF9vM2nHwwibAE4cF0KW1988YX+9Kc/adq0abr55pt1xRVXaMqUKTr++OPjXR+Abi7RC6Xu600Q0NP5I1GtawxKkgo9VoVrm5NcUffWv2xwQtYI258TCtxatTOg9Y1BbfeFlefmKgwAB6ZLvy1Gjx6tWbNm6eGHH9Zbb72luXPn6pRTTtHQoUM1ZcoUXXvttcrLy4t3rQC6sUQtlAr0VtFd12mFTSnVbqgsza51yS4Kncpx2TQ806E1DUEt3ebTRQPTkl0SgB7ikGYjtNlsuvTSS/WXv/xFDz30kL799ltNnz5dAwYM0I9//GNVV1fHq04AAHqVjc0htYRM2QxpeIZDFsNIdknYhxMLPJKk1fUBNQQiSa4GQE9xSGHrs88+04033qh+/fpp1qxZmj59ur799lu9//772rJliy655JJ41QkAQK+x3RdWtbftDfvQDIdcNlZi6e4KPTaVpdllSvqk1pfscgD0EF0aRjhr1iw99dRTWrNmjc4//3w988wzOv/882WxtP2xKCsr05NPPqkRI0bEtVgAAHo6bziq9U1tazYNSLEp22VNckU4UCcWelTR3Kgvd/h1cqFHqXZCMoB961LY+t3vfqfrr79eP/nJT1RYWNhpm5KSEs2ZM+eQigMAoDeJRHetp2VK6Q6LSlKZaKEnKU6xaUCKTZtbw1pW69PpLDwNYD+69Ft+3br9X8LrcDg0efLkrnQPAECvtKEpJG/YlN3Sdp2WwXVaPYphGBpf4NbmDc1aucOvkwrdclo5uwVg77r0G+Kpp57SX//61z22//Wvf9XTTz99yEUBANDb1PrCqvW3Xac1PNMhh5Wg1RMNSXco22lVIGLqyx2BZJcDoJvrUth68MEHlZubu8f2/Px8zZw585CLAgCgN/GFo/p213Vaxak2ZTi4TqunMgxDx+e7JUnLtvsUNc0kVwSgO+tS2KqsrFRZWdke20tLS1VVVXXIRQEA0FtETVNrG3ddp2W3qDiF67R6ulHZTnlshpqCUa1pCCa7HADdWJfCVn5+vr788ss9tn/xxRfKyck55KIAAOgtqlrCsfW0hmXauU6rF7BbDB2T23Z265Nan0zObgHYiy6FrSuvvFK33nqrFixYoEgkokgkovfff1+33XabrrzyynjXCABAj9QQiGhLa1iSNCTDwWQKvcgxuS7ZDKnGG9amXfsYAL6rS2MZ7r//flVWVurMM8+UzdbWRTQa1Y9//GOu2QIAQFIw0jZ8UJIK3VblsJ5Wr+KxWzQmx6XP6/z6dJtPJan2ZJcEoBvqUthyOBx66aWX9Otf/1pffPGF3G63xowZo9LS0njXBwBAj2OaptY3BRWKSh6boYHpvBHvjcblufV5nV/rm4La6Y+wQDWAPRzSVbrDhg3TsGHD4lULAAC9QrU3ovpAVIakYRkOWblOq1fKdlk1ON2ub5tCWl7n09kDUpNdEoBupkthKxKJaO7cufrnP/+p2tpaRaPRDve///77cSkOAICepiUU1cbmtmney9LtSrEf/HVa5eXl8S4rIX1COi7PrW+bQlq1I6DT+nm4Lg9AB10KW7fddpvmzp2rCy64QKNHj2ZmJQAAJEWiptY2BGVKynZaVOg+uGFlO2prJMPQNddck5gCJbW0tCSs756uK4HUlJSifmqN2vX3L9arVHt+f3Nzc1VSUhKHCgH0NF0KWy+++KL+8pe/6Pzzz493PQAA9FgbmkPyRUw5LG2zDx7sh5EtjY2SaermXz+qsePGx7W2pQvmac5D98nv98e1397gUEPu8d+frEvv/h99tKlB37/0hD2mgvd4PCovLydwAX1QlyfIGDJkSLxrAQCgx9ruC6vWF5HUdp2W3dL1UR/9ywZr+JFHxamyNpXr1sS1v97kUEOuKUM7oxHllgzS7H+ukCPYGruvcv0a3X/zFNXV1RG2gD6oS2Fr2rRp+u1vf6vZs2czhBAA0Of5w1F929R2ndaAFJsynMxK1xMdSsitaAppqzcsS36Jhmc741sYgB6rS2Fr8eLFWrBggd555x2NGjVKdnvHKW1fffXVuBQHAEB3Z5qm1jaGFDGlNLtFJamHNNEveqh+Hqu2esNqCEblDUflsTFRBoAuhq3MzExdeuml8a4FAIAep6olrOZQVFZDGpZhZ8RHH+WyWZTttGhnIKpqb1iD0x3JLglAN9ClsPXUU0/Fuw4AAHqchkBEm1vDkqQh6Xa5OJvRp/Xz2LQzEFStL6LSVFO2Q7huD0Dv0OW/CuFwWO+9956efPJJNTc3S5K2bt3KlLIAgD4hGDG1tjEoSSpwW5XrZvhgX5fhsMhtNRQ1pe3+SLLLAdANdOkvQ2Vlpc4991xVVVUpEAjo7LPPVlpamh5++GH5/X79/ve/j3edAAB0G6aktY1BhaKSx2aoLN2+38eg9zMMQ4UemyqaQ6rxhg96nTUAvU+XzmzddtttOu6441RfXy+32x3bfumll+qf//xn3IoDAKA78nmy1RiMymJIwzMdsnKdFnbJd1tlkeQNm2oORZNdDoAk6/JshB999JEcjo4Xf5aWlmrLli1xKQwAgO5o4NEnyJuSK0kanG5n1jl0YLMYynVbVeuLqMbLUEKgr+vSX4hoNKpIZM9fIJs3b1ZaWtohFwUAQHcUlEVXznxSMgzluazK5zotdKKfp+3nos4fUdRgKCHQl3UpbJ199tl67LHHYrcNw1BLS4vuuecenX/++fGqDQCAbsM0TX2lHGUUFMkaDmgw12lhL1LtFqXaDZmS/O6MZJcDIIm69JHcb37zG51++uk64ogj5Pf7dfXVV2vdunXKzc3VCy+8EO8aAQBIumXb/aoz3AoF/MpsqZF1QGayS0I3Vui2aX0oJL87Q4aFoaZAX9Wlo7+oqEgrV67U9OnTdcMNN+joo4/Wgw8+qM8//1z5+flxLXDLli265pprlJOTI4/Ho6OOOkrLly+P3W+apmbMmKGioiK53W5NnDhRX3/9dYc+AoGAbrnlFuXm5iolJUUXX3yxNm/eHNc6AQC919bWkBZuaZUkvf0/v5QtEkhyRejuct1W2QwpanVo6AkTk10OgCTp8kctbrdb119/vWbPnq0nnnhCP/3pTzvMTBgP9fX1Ovnkk2W32/XOO+9o9erVevTRR5WZmRlr8/DDD2vWrFmaPXu2li1bpsLCQp199tmxtb8kaerUqXrttdf04osvavHixWppadGFF17Y6XVnAADsrjUU1WsVzYpKKjC9+vSVp5NdEnoAq2Eob9fU7+MuvTbJ1QBIli4NI3zmmWf2ef+Pf/zjLhXzXQ899JCKi4v11FNPxbYNHDgw9n/TNPXYY4/p7rvv1mWXXSZJevrpp1VQUKDnn39eN9xwgxobGzVnzhw9++yzOuussyRJzz33nIqLi/Xee+/pnHPOiUutAIDeJ2qaemNjs5pDUWU7rRrl35HsktCDFLptqvZGNPK0cxTQtmSXAyAJuhS2brvttg63Q6GQvF6vHA6HPB5P3MLWm2++qXPOOUc//OEPtWjRIvXv31833nijfvazn0mSKioqVFNTo0mTJsUe43Q6NWHCBC1ZskQ33HCDli9frlAo1KFNUVGRRo8erSVLluw1bAUCAQUC/xom0tTUFJfXBADoORZu9aqqJSSHxdBlZWmqKjeTXRJ6EI/dIlvIJ9nd2mqmJrscAEnQpWGE9fX1Hb5aWlq0Zs0anXLKKXGdIGPDhg363e9+p6FDh+of//iHfv7zn+vWW2+NnVmrqamRJBUUFHR4XEFBQey+mpoaORwOZWVl7bVNZx544AFlZGTEvoqLi+P2ugAA3d839QF9WuuTJJ1fkqpcpnlHF7h8DZKkzUqRaRLWgb4mbtPjDB06VA8++OAeZ70ORTQa1THHHKOZM2fq6KOP1g033KCf/exn+t3vftehnWEYHW6bprnHtu/aX5u77rpLjY2Nsa9NmzZ1/YUAAHqUbd6w/lbVdu3v+Hy3RmQ5k1wReiqnv1n+5ib5DLsqW0LJLgfAYRbXuUitVqu2bt0at/769eunI444osO2kSNHqqqqSpJUWFgoSXucoaqtrY2d7SosLFQwGFR9ff1e23TG6XQqPT29wxcAoPdrCUX1yoYmhaLSwDS7JhR5kl0SejBDpla++4ok6Ys6f5KrAXC4dWlMxJtvvtnhtmmaqq6u1uzZs3XyySfHpTBJOvnkk7VmzZoO29auXavS0lJJUllZmQoLCzV//nwdffTRkqRgMKhFixbpoYcekiQde+yxstvtmj9/vi6//HJJUnV1tb766is9/PDDcasVANDzhaKmXtnQpKZdE2J8b2CaLPsZKQHsz7LXntMJP/yJ1jYG5Q1H5bHFd92tqqoq1dXVxbXPdrm5uSopKUlI30Bf0KWw9b3vfa/DbcMwlJeXpzPOOEOPPvpoPOqSJN1+++066aSTNHPmTF1++eX69NNP9Yc//EF/+MMfYs87depUzZw5U0OHDtXQoUM1c+ZMeTweXX311ZKkjIwMTZkyRdOmTVNOTo6ys7M1ffp0jRkzJjY7IQAApmnq75XNqvaG5bIa+uHgdLni/KYYfdPWb75UmhlUsxz6amdAx+fHb6mcqqoqjRw5Ul6vN2597s7j8ai8vJzABXRRl8JWNBqNdx2dGjdunF577TXddddduu+++1RWVqbHHntMP/rRj2Jt7rzzTvl8Pt14442qr6/X+PHjNW/ePKWlpcXa/OY3v5HNZtPll18un8+nM888U3PnzpXVaj0srwMA0P19WO1VeUNQFkmXlqUpy8nfCMTPALWoXNn6codf4/Jc+722/EDV1dXJ6/Xql7PnqHTI8Lj02a5y/Rrdf/MU1dXVEbaALur2UytdeOGFuvDCC/d6v2EYmjFjhmbMmLHXNi6XS48//rgef/zxBFQIAOjpPtvu05JtbTMPnlOSqtI0R5IrQm9TqFatM7JV54+oxhdWP489rv2XDhmu4UceFdc+ARy6LoWtO+6444Dbzpo1qytPAQDAYbG6PqD3NrdKkk7t59HYHFeSK0JvZJepYZlOra4PaNWOQNzDFoDuqUth6/PPP9eKFSsUDoc1fHjbKeu1a9fKarXqmGOOibWL1ylyAAASoaIpqLcr26Z4PybXpZMK4nctDfBdY7Lbwtbq+oDO6J8im4X3SUBv16WwddFFFyktLU1PP/10bLHg+vp6/eQnP9Gpp56qadOmxbVIAADiraolpFcrmhQ1pZGZDp09IIUPCZFQpWl2pdktag5Ftb4xyPptQB/QpWmWHn30UT3wwAOxoCVJWVlZuv/+++M6GyEAAIlQ2RzUX79tVCgqlaXZdWFpGkELCWcxDI3ObgtYq3ay5hbQF3QpbDU1NWnbtm17bK+trVVzc/MhFwUAQKJsbA7qr9+2LVo8KM2u7w9Kl5XhXDhMxmS3XRO4oSmkltDhmd0ZQPJ0KWxdeuml+slPfqKXX35Zmzdv1ubNm/Xyyy9rypQpuuyyy+JdIwAAcVHRFNTL3zYpbEqD0+26bFA6183gsMp2WdU/xSZT0tec3QJ6vS5ds/X73/9e06dP1zXXXKNQKNTWkc2mKVOm6JFHHolrgQAAxMOXO/x6t6pFUUlD0h36XlkaQQtJcWS2S1taW7Rq1wLHDGEFeq8uhS2Px6MnnnhCjzzyiL799luZpqkhQ4YoJSUl3vUBAHBITNPU4hqvPqppW0friCynLihJZeggkmZ4lkPzN0t1/oiqvWEVpTANPNBbdWkYYbvq6mpVV1dr2LBhSklJkWma8aoLAIBDFo6a+ltVSyxonVTg1kWlBC0kl8tq0fDM9okyAkmuBkAidSls7dixQ2eeeaaGDRum888/X9XV1ZKkn/70p0z7DgDoFuoDET27tkFf7QzIkHRucapOK2J6d3QPY3bNSri6PqBwlA+rgd6qS2Hr9ttvl91uV1VVlTweT2z7FVdcoXfffTduxQEA0BXfNAQ095sGbfNF5LYaunxwuo7KdSW7LCCmNM2udLtFgYipdY3BZJcDIEG6dM3WvHnz9I9//EMDBgzosH3o0KGqrKyMS2EAABysQCSqhVu9+ryubZa3ASk2XTwwTekOa5IrAzoydq25tWSbT6t2+jWSBY6BXqlLYau1tbXDGa12dXV1cjr5ZQEAOPzWNQY0b1OrmnetXTQ+363TijyyMmwQ3dSYHJeWbPOpoimk5lBEaXY+FAB6my4NIzzttNP0zDPPxG4bhqFoNKpHHnlEp59+etyKAwBgfxqDEb1e0aRXNjSrORRVpsOiK4ek6/T+KQQtdGtZTqsGxNbcYqIMoDfq0pmtRx55RBMnTtRnn32mYDCoO++8U19//bV27typjz76KN41AgCwB28oqiXb2oYMRkzJkHR8vlun9PPIzmyD6CHG5Li0ubVFq3YENJ41t4Bep0th64gjjtCXX36p3/3ud7JarWptbdVll12mm266Sf369Yt3jQAAxDQFI/q8zq/l2/0K7prFrSTVrjP6p6jQ06U/a0DSjMh06L3N0o4Aa24BvdFB/1UKhUKaNGmSnnzySd17772JqAkAgA5M09RWb1if1fq0piGo6K7thW6bJhR5NDDNzhkB9EhOq0XDMpz6uj6gL3cECFtAL3PQYctut+urr77ijxoAIOF2+iNaXR/Q6vqAdgYise3FqTYdl+fWsAwHf4/Q443JaQtb3zQEdNaAFNkYBgv0Gl0ab/HjH/9Yc+bM0YMPPhjvegAAfVjUNLWlNawNTUF92xRUre9fActmSCOznDo2z81wQfQqpal2pdktag5FtaEpqGGZzOwM9BZd+msVDAb1xz/+UfPnz9dxxx2nlJSUDvfPmjUrLsUBAHq3SNRUjS+sTS0hbW4Ja1NrSIGIGbvfkFSWbtcRWU4NzXDIae3SJLpAt2YYho7IcuqTWp++rg8QtoBe5KDC1oYNGzRw4EB99dVXOuaYYyRJa9eu7dCG4RwAgL0JRkxtaQ1pU2tbuNraGlLY7NjGZTU0KN2hQel2DUp3yGMjYKH3aw9b6xuD8oejcvFzD/QKBxW2hg4dqurqai1YsECSdMUVV+j//b//p4KCgoQUBwDo2QKRaNsZq5aQqlpCqvGGY5NbtHNbDQ1ItWtAik3FqXYVemyy8MEdepny8vJ93m9KSlWhWuTQvC/XaYBa49IvgOQ6qLBlmh0/fnznnXfU2npgvwwAAL1fJGpqU0tIG5rbwtU2b1jfOXGldLtFxal2DUi1qTjFrhyXlVER6LV21NZIhqFrrrlmv21Pm3yLzrvtv/TWZ+X64w2XHtTztLS0dLVEAAl0SFcYfzd8AQD6nkAkqnWNQa1rDKqiKRRb+6pdpqMtXJWk2lWcalem05qkSoHDr6WxUTJN3fzrRzV23Ph9to1YbKqXNHjcKfr9vKWyRsP77X/pgnma89B98vv9caoYQDwdVNgyDGOPTx/5NBIA+p5I1NS3TUGtrg9ofWOww3VXKTZDg9MdKk1rC1fpDsIV0L9ssIYfedR+263aEVBTKKr0gcM1IHX/a25VrlsTh+oAJMpBDyO87rrr5HS2zZLj9/v185//fI/ZCF999dX4VQgA6DbqAxGtrPNr1U6/vLslrGynVSMyHRqS4VA/j40P4oAuynNb1RSKars/ckBhC0D3dlBha/LkyR1uH8j4YwBAz2aapiqaQ1pW61NFcyi2PdVm0RHZTh2R5VSBm+uugHjIdVm1oSkkb9hUayiqFDuzEgI92UGFraeeeipRdQAAuplI1NTq+oA+rfVpu/9fiwsPSrPrqFyXhmQ4mDUQiDObxVC206IdgbazW4QtoGc7pAkyAAC9TyRq6sudfn1c41NTqG2idrtFGpvj0nF5bia4ABIsz23TjkBQ231hlaYyLBfoyQhbAABJnYesFJuh4/LcOjrXxSKrwGGS5bTIakjBqNQYjPIBB9CDEbYAoI+Lmm3DBT+s9qox2BayUm0WnVDg1thcl+wWPlUHDieLYSjXZdU2X0Tb/RHCFtCDEbYAoI8yTVPrGoP6oNqrul3XZKXYDJ1Y6NFROS7ZCFlA0uS528LWDn9Eg9NNro8EeijCFgD0QRubg/pgq1dbvW2Lprqshk4ocOvYPDdnsoBuIN1ukcNiKBg1tTMQVa6Ls1tAT0TYAoA+ZGtrSB9Ue7Vx1xTudot0XJ5b4/Pde1yTVVVVpbq6uoTUkZubq5KSkoT0DfQGhmEoz23VltawtvvChC2ghyJsAUAfUOMN68PqVn3b1BayLIZ0dK5LJxZ4lNrJ1NJVVVUaOXKkvF5vQurxeDwqLy8ncAH7kOdqC1v1gahCUZOzzkAPRNgCgF6s1hfW4mqv1jYGJUmGpNHZTp1c6NnnRfd1dXXyer365ew5Kh0yPK41Va5fo/tvnqK6ujrCFrAPKXaLPDZD3rCpHf6ICj28bQN6Go5aAOiF6vxtIeubhmBs26istpCVfRDDkUqHDNfwI49KQIUADkSe26rK5rC2+whbQE/EUQsAvUi1N6RPtvm0piEoc9e2EZkOnVLoUa6bX/lAT5PnsqmyOaymUFT+SFQuK+vdAT0Jf3kBoIczTVMbmkL6tNanypZQbPvQjLaQVcCn4UCP5bQaSndY1BSMqs4X0YBUwhbQk/AXGAB6KH84qi93BvR5nU/1gbbFiC2SRmY5Nb7ArXzOZAG9Qp7LqqZgVNv9EQ1ItSe7HAAHgb/EANCDRE1TVc0hrdoZ0JqGgMK7xgo6rYaOzHbquHy3MhxMEQ30JjkuqzY0heQNm2oNRZXSyQyiALonwhYAdHOmaarGF9aa+qC+rg+oORSN3ZfnsuqYPJdGZbnksDItdLtErRFWXl4e9z6B/bFbDGU5LdoZiKrOHyFsAT0IYQsAuqFI1NTm1pDWNwa1pjGopuC/ApbTamhkplNjcpwq8thkGISs3SV6jTBJamlpSVjfQGfyXFbtDES13RdRSSrHPdBTELYAoBswTVN1/oiqWkKqaA6psjmo3U5gyW6RBqU7NDLTqSEZDtlY3HSvErlG2NIF8zTnofvk9/vj2i+wP1kuqyxNIQWipppDUaUzXBjoEQhbAJAE/nBUNb6warxhbW0Na1NLSL6I2aGNx2ZoULpDQzMcGpTukJ2AdVASsUZY5bo1ce0POFBWw1CO06rt/oi2+yOELaCHIGwBQILtHqzavxp2GxbYzmZI/VPsKk2za1C6QwVuK0OFAMTkudvCVp0vorI0UxZ+PwDdHmELAOKoPVht84ZVvY9gJUkZDosKPTb189hUnGpXodsmK2evAOxFpsMiu0UKRaXGYFRZTs5uAd0dYQsAumj3YFXjDavGF46td/Vd7cGq0G1r+9djk9vGjGIADpxhGMp1WVXtjWi7L0LYAnoAwhYAHADTNLUzENGW1rC2tIa0pTWsOn+k07YEKwCJkueyqdob0Y5ARJGouf8HAEgqwhYAdCJqmqrxhrWxORQLV/7Inm9sCFYADqdUuyGn1VAg0vYBEIDujbAFALu0hKKqaAqqojmkiqbgHrMD2gyp0GPTgBS7+qfaVOSxs7gogMPKMAzluaza3BrW9r2cXQfQfRC2APRZpmlqqzesdY1BbWgKqtbX8Y2L02KoNM2u4lS7BqTYlM8EFnFVXl7eo/oFuos8d1vYaghEJZs92eUA2AfCFoA+pT1gldcHtLYhqKZQxwktCj02DUqzqyzdoaIUm6xMrRx3O2prJMPQNddck9DnaWlpSWj/QLJ4bBal2Ay1hk3ZcoqSXQ6AfSBsAegTGgIRfV0f0Fc7/R1mDHRYDA1Ot2tIhkMD0xwMCzwMWhobJdPUzb9+VGPHjY97/0sXzNOch+6T3++Pe99Ad5Hrtqq1OSxbXv9klwJgHwhbAHqtiGlqXUNQn9f5VdkSim23W6ShGU6NyHSoLN0hO0MDk6J/2WANP/KouPdbuW5N3PsEups8l1WVzWFZM3KVUcDZLaC7ImwB6HWagxF9XufXFzv8ag3/a5KL0lS7Rmc7NTzTKYeVgAWg53JaLUq3W9QUimrsuZcluxwAe0HYAtBrVHtDWlbr1zf1AbUPFEyxGRqb49KROS5lsgAogF4kz23dFba+L0Uak10OgE4QtgD0aKZpqqolpI9qfKrabahgcapNx+a6NTTTwSQXAHqlHJdV6xsCKho+Wvp2RbLLAdAJwhaAHsk0TVU2h7S4xqvNrWFJksWQRmY6NS7frUIPv94A9G52i6FIQ61s2YVSel6yywHQCd6NAOhRTNPUxl0ha8uukGU1pLE5Lp1Q4Fa6g6GCAPqO8PbNbWErI0+macrgTD7QrRC2APQIpqRvG4P6qMarrd62kGUzpLG5Lp2Q71YaIQtAHxTZuU0Bb6ucnhQ1h6J84AR0M4QtAN2aKWnEqWfrExWoaUOTpLaQdXSuS+MLPEplXSwAfVk0otUL/qajL7hcdf4IYQvoZniXAqBbMk1TO/wRNWSVavJvn1eT4ZTdIh2f79b/NypbZw5IJWgBgKSV77wiSarzR2Sa5n5aAzicOLMFoFsxTVM7A1Ftagm1rZFldyngbdVwd0QXHTFQKQQsAOhg/acfSOGgQjaHGoJRZbHMBdBt8K4FQLdgmqbq/BGt3BHQNw1BtYZNWQzJ3bpDD194jIapgaAFAJ2IhsNS0w5J0nZfJMnVANhdjzqz9cADD+g///M/ddttt+mxxx6T1PYG7d5779Uf/vAH1dfXa/z48frf//1fjRo1Kva4QCCg6dOn64UXXpDP59OZZ56pJ554QgMGDEjSKwHQrj1kbW4NyxtuG/5iNaR+HpuKUmzasK1O3oadSa6y66qqqlRXV5eQvnNzc1VSUpKQvgH0MI3bpex+2hGIKGKarC8IdBM9JmwtW7ZMf/jDH3TkkUd22P7www9r1qxZmjt3roYNG6b7779fZ599ttasWaO0tDRJ0tSpU/XWW2/pxRdfVE5OjqZNm6YLL7xQy5cvl9XKqXYgGaKmqVpfRFtaw/JH/hWyinaFLJul579RqKqq0siRI+X1ehPSv8vl0ssvv6x+/frFve/y8vK49wkggXzNcloNBSKm6v0R5bp7zFs8oFfrEUdiS0uLfvSjH+n//u//dP/998e2m6apxx57THfffbcuu+wySdLTTz+tgoICPf/887rhhhvU2NioOXPm6Nlnn9VZZ50lSXruuedUXFys9957T+ecc05SXhPQV4Wjpmq8YW31hhWKtm2zGVK/FJuKPL0jZLWrq6uT1+vVL2fPUemQ4XHt+8tPl+jxe/5DF154YVz7/a6WlpaE9g8gfvJcVm1uDWs7YQvoNnrEkXjTTTfpggsu0FlnndUhbFVUVKimpkaTJk2KbXM6nZowYYKWLFmiG264QcuXL1coFOrQpqioSKNHj9aSJUv2GrYCgYACgUDsdlNTUwJeGdB3BCKmtraGVeMLK7prsiyHxVD/FJsK3FZZkxSyEjnMr/3sUOmQ4Rp+5FFx7bty3RrJNHXzrx/V2HHj49q3JC1dME9zHrpPfr8/7n0DSIz2sFUfiCoUNWXvRR9eAT1Vtw9bL774olasWKFly5btcV9NTY0kqaCgoMP2goICVVZWxto4HA5lZWXt0ab98Z154IEHdO+99x5q+UCfZpqmmkNRVXsj2uGPqH1CYo+tLWTluqyyJPG6gkQP82uXyLND/csGxz3ISbvCHIAexWO3yGMz5A23LZ1R6On2b/OAXq9bH4WbNm3Sbbfdpnnz5snlcu21nfGdN2umae6x7bv21+auu+7SHXfcEbvd1NSk4uLiA6wc6NtC0bZJL2q8/5r0QpLS7Rb1T7Epy2nZ7zH6XYm4hqi8vDxhw/wkzg4BOPzyXFZVtrQNJSRsAcnXrY/C5cuXq7a2Vscee2xsWyQS0QcffKDZs2drzZq2T15ramo6XCBeW1sbO9tVWFioYDCo+vr6Dme3amtrddJJJ+31uZ1Op5xOZ7xfEtBrmZJ2+iOq9YW1MxCNncWySMp1W9XPY+vSIsQ7amskw9A111wTz3I7yCnsz9khAL1CnrstbDUFowpETDmtDCUEkqlbh60zzzxTq1at6rDtJz/5iUaMGKH/+I//0KBBg1RYWKj58+fr6KOPliQFg0EtWrRIDz30kCTp2GOPld1u1/z583X55ZdLkqqrq/XVV1/p4YcfPrwvCOhlwlFTtXLrh/fO1s7cIdrREIzdl2IzlO+2Kd9tPaRJL1oaGxN2bRJnngD0Nk6rRel2i5pCUdX5w+qfYk92SUCf1q3DVlpamkaPHt1hW0pKinJycmLbp06dqpkzZ2ro0KEaOnSoZs6cKY/Ho6uvvlqSlJGRoSlTpmjatGnKyclRdna2pk+frjFjxsRmJwRw4JqCEW1oCunbpqAqm0MKGnk65qIrZEqyW6Q8V1vAivcCxIm4NokzTwB6ozy3VU2hqLb7IoQtIMm6ddg6EHfeead8Pp9uvPHG2KLG8+bNi62xJUm/+c1vZLPZdPnll8cWNZ47dy5rbAH7YZqmGoNRbWoJaVNrSJtbwtoZiHRo4zTDev+FOTr/vPM0asSwg74WCwAQXzkuqzY0hdQaNuUNR+WxxffDLwAHrseFrYULF3a4bRiGZsyYoRkzZuz1MS6XS48//rgef/zxxBYH9HCmaWq7P6JNLSFtbglpU2tYLe2LYe1iSCpKsWlwukOD0h3a8s2XuuN/fqlLzppI0AKAbsBuMZTptKg+0HZ2qzSNsAUkS48LWwDiJxI1Ve0Na3NrqC1gtYYViJgd2lgMqZ/HpuIUuwak2jUgxSbXbp+Sbj3cRQMA9ivPZVV9IKo6f0QlqTY+DAOShLAF9CGRqKmt3rA2NgdV1RJSdWtY4Y7ZKrbQ8IBUu4pT7OqXYmNhTADoYbKdVlmMkPwRUy0hU2kOfo8DyUDYAnox0zS1zRdRZXPbZBabWkP6zqhAeWyGBqTYVZza9pXvTu5CwwCAQ2e1GMpxWrXdH9F2f1hpDkeySwL6JMIW0MsEIlFtaAppXWNQFU1B+b4zLNBjM1SaaldpmkPFqTZlO60MLwGAXijX3Ra26vwRlaWZ/K4HkoCwBfQCwYipdY0Bra4PaGNzSLvnK4fFUHGqTaVpDg1MsyvPRbgCgL4g02GRzZBCUakhGFWWk1mYgcONsAX0UKZpamNzSF/tDGhtY6DD8MAsp0XDMpwakuFQUYpNVsIVAPQ5FsNQrtuqGm9Edb4IYQtIAsIW0MN4Q1F9udOvlXV+NQT/lbCynBYdkeXUyEyncjh7BQBQ26yENd6IdgQiGmSafPgGHGaELaCH2O4L69Nan1bXB2LDBJ1WQ6OynBqd7VQ/D1P7AgA6SrNb5LQYCkRN1QeiynVxdgs4nAhbQDe3qSWkpdu8+rYpFNvWz2PTUbkujcx0ymElYAEAOmcYhvLcVm1uDWu7L0zYAg4zwhbQTW1qCWlxtVeVLf8KWcMyHBpf4Fb/FHsSKwMA9CS5rrawVR+IKhw1ZWPtROCwIWwB3Uy1N6RFW73a2NwWsiyGdGS2S8fnu5XNJ5IAgIOUYrfIYzPkDZuq80dU6OHtH3C4cLQB3URjMKJFW71aXR+QJFkkHZnj0omFbmU4CFkAgK7Lc1lV2RLWdh9hCzicONqAJAtEovq4xqdl232xiS9GZTl1aj+PMpmmFwAQB3lumypbwmoKReULR+W2WZJdEtAnELaAJDFNU+UNQb2/pVUtuxbJKkm164z+KXzqCACIK6fVUKbDooZgVNt9EZWkEbaAw4F3dEAS1PnDmrepVVW7Jr/IdFh05oAUDUl3JGz69qqqKtXV1cW93/Ly8rj3CQCIv3y3VQ3BqGr9ERWnslwIcDgQtoDDKBw19fE2rz7e5lPUlGyGdGKhR+Pz3QmdHaqqqkojR46U1+tN2HO0tLQkrG8AwKHLdlllbQopEDHVFIwqg6HqQMIRtoDDZHNLSO9satEOf0SSNDjdrrMHpB6W67Lq6urk9Xr1y9lzVDpkeFz7XrpgnuY8dJ/8fn9c+wUAxJfVMJTrsmqbL6Jaf4SwBRwGhC0gwcJRU4u2tmrZ9rYw4rEZOntAqkZkJm7I4N6UDhmu4UceFdc+K9etiWt/AIDEyXe3ha06f0SD0kxZWXMLSCjCFpBANd6w3q5sVt2us1ljsp06o38Ks0ABAJIizW6Ry2rIHzG1IxBRvpu3gkAicYQBCRAxTX1c49OSGq+iklJshs4rSdOQDEeySwMA9GGGYSjfbVVVS1i1PsIWkGgcYUCc7fCH9XZli6q9YUnSiEyHJhWnysPZLABAN9AethqDUfnDUbn4+wQkDGELiBPTNLV8u18Lt7YqbLataXLOgFSNzDqwa7MSNTW7xPTsAIB/cVotynBY1BiMars/ouJUwhaQKIQtIA68oajermrWhqa2dbPK0uw6vyRVaY4Dm+npcEzNLjE9OwCgTb7bqsZgVLW+iAaksOYWkCiELeAQVTWH9GZls1pCUdkM6Yz+KTo613VQf7gSOTW7xPTsAICOcpxWfWuE5I+Yag5FlX6AHw4CODiELaCLoqapJTU+fVTjlSkpx2XVJQPTDuli40RMzS4xPTsAoCOrpW3NrVpfRNt8EcIWkCCELaALWkJRvbmxWVUtbcMGx2Q7dfaAVDmsDMMAAPQM+e62sLXDH9GgdFNWhhICcUfYAg5SRVNQb1U2yxs2ZbdI5xSnanS2K9llAQBwUNLtFjmthgIRUzv8TAMPJAJHFXCAIqapD6u9WrrNJ6ntE8FLBqYpx8VhBADoedrX3NrUEtZ21twCEoKjCjgAjcGI3tzYrC2tbWtnHZPr0hn9U2SzMOQCANBz5bvawlZDMKpAJCqnlWnggXgibAH7sa4xoL9VtsgfMeW0GDqvJFUjspzJLgsAgEPmslmUbreoKdQ2DTxrbgHxRdgC9iIcNbVwa6s+2942XXo/j02XDExTppMZmwAAvUe+2xoLW6y5BcQXYQvoRH0gojcqmlXjaxs2OC7PpYlFKbIybBAA0MvkuqyqaG5bc6sxGOVDRSCOCFvAd5TXB/ROVYuCUVMuq6ELS9M0JMOR7LIAAEiI9jW3tu1ac4uwBcQPYQvYJRQ19c/NrVq5o23Y4IAUmy4emMZCjwCAXq/QY9O2XWtuhaKm7IzkAOKCsAVIqvOH9UZFs7b7I5KkkwrcOqWfR5bvjFuvqqpSXV1d3J+/vLw87n0CAHCgUu0WpdgMtYZNbfdFVJTCW0QgHjiS0Oet2uHXvM0tCkUlj83QRaVpKkvfc9hgVVWVRo4cKa/Xm7BaWlpaEtY3AAD7UuCxaUNTSNt8YfXzMKoDiAfCFvqsYMTUPza16Ov6gCSpNNWuiwamKdXe+bS3dXV18nq9+uXsOSodMjyutSxdME9zHrpPfr8/rv0CAHCg8lxWbWwKyRs21RyKJrscoFcgbKFP2uYN642NzdoZiMiQdGo/j04ocO8xbLAzpUOGa/iRR8W1nsp1a+LaHwAAB8u2a6KMWn/bRBkADh1hC32KaZpaUefX+1taFTGlNLtFFw1MU0mqPdmlAQCQdAWetrBV548o02CBY+BQEbbQZ/jCUf29qkXrGoOSpMHpdl1QmiaPjT8mAABIbR9Cuq2GfBFTAVd6sssBejzCFvqEqpaQ3trYrOZQVFZDOr0oRcfmuWQcwLBBAAD6CsMwVOixtS1y7M5MdjlAj0fYQq8WNU19VOPVkhqfTEnZTqsuHpimQg8/+gAAdCbfbVVlS0gRm1MDjz4h2eUAPRrvONFrNQUjenNjsza3hiVJY7KdOntAqhxWzmYBALA3sYkyfBGN/8F1yS4H6NEIW+iV1jYE9PeqFvkjphwWQ+cUp2hUtivZZQEA0CP089hU64to9FkXKaDaZJcD9FiELfQq4aip97e0akVd23pVhR6bLhmYpiwnizMCAHCgUu0W2UI+ye7WVjM12eUAPRZhC71GnT+sNyqatd3ftjbI8fluTejnkdXCsEEAAA6Wy9egFrtbm5SqqGke0FqUADoibKHHM01TX+4M6L3NLQpFJY/N0IWlaRqU7kh2aQAA9FhOf7NqTZeUkaUNTSENyeDvKnCwWGAIPZo/EtWbG5v1TlVb0BqYZtf1I7IIWgAAHCJDpla89aIkaUWdL8nVAD0TYQs91tbWkJ76pkHlDUFZJE0s8uiKwelKtfNjDQBAPCz961zJNLWhKaSdu4bpAzhwDCNEj2Oapj6p9emDrV5FJWU4LLpkYJqKUuzJLg0AgF5lx6YNypVfdXJreZ1PZw9gsgzgYBC20KO0hKJ6u7JZG5tDkqSRmQ6dU5Iql7XtbFZVVZXq6uoS8tzl5eUJ6RcAgO6sRM2qk1urdgR0Wj+PnFZGkAAHirCFHmNDU1BvVzbLGzZlM6Szi1N1ZLZTxq7ZkaqqqjRy5Eh5vd6E1tHS0pLQ/gEA6E5y5FeOy6od/oi+3BHQuHx3sksCegzCFrq9SNTUomqvPq1tuzg3z2XVJWVpynV1/PGtq6uT1+vVL2fPUemQ4XGvY+mCeZrz0H3y+/1x7xsAgO7KkHRcnkv/2NSq5dt9Oi7PFfugE8C+EbbQrdUHInpzY7OqvWFJ0jG5Lp3RP0W2faydVTpkuIYfeVTca6lctybufQIA0BOMynJp4VavGoJRfcs08MABY9Atuq2vd/r11DcNqvaG5bIauqwsTZOKU/cZtAAAQPw5rIbG5rgkSZ9tZxp44EBxZgvdTjBiav7mFq3aGZAkDUix6eKBaUp3WJNcGQAAfdcxuS4tq/VpY3NI231h5bl5GwnsD2e20K3s9Ef0zNoGrdoZkCHp5EK3rh6aQdACACDJMp1WDd01fLD9OmoA+0bYQrfxTUNAc9c0qM4fUYrN0FVDMnRqvxRZuAgXAIBuYXxB20yEX9cH1BxikWNgfwhbSLqIaer9La16vaJZwaip4lSbfjIiSyVpLFIMAEB30j/FrgEpNkVNaXkts/MC+0PYQlK1hKJ6YV1jbDjC+Hy3rhqSoVQ7P5oAAHRHx+9aZ+vzHX4FItEkVwN0b1zZiKSpagnpjYomtYZNOS2Gzi9N1fBMZ7LLAgAA+zA0w6Fsp1U7AxF9sSMQC18A9sTpAxx2pmnqs+0+vbCuUa1hU3kuqyYPzyRoAQDQAxiGEQtYn9X6FDHNJFcEdF+ELRxWEdPUvM2tem9zq0xJo7Kc+vHwTGW7mG0QAICeYnS2Uyk2Q02hqMrrA8kuB+i2GEaIw8Yfjuq1imZVtoQk09QwNahoZ7NW7YxP/+Xl5fHpCAAA7JPNYujYPLc+qPbqk20+jcpyymD2YGAPhC0cFjv9Eb28oUk7AxEFva168T9vUPkH/0jIc7W0tCSkXwAA8C/H5Lq0dJtP2/0RrWsMahiXAwB76NZh64EHHtCrr76qb775Rm63WyeddJIeeughDR8+PNbGNE3de++9+sMf/qD6+nqNHz9e//u//6tRo0bF2gQCAU2fPl0vvPCCfD6fzjzzTD3xxBMaMGBAMl5Wn7OxOajXK5rlj5hymWH99icX6Ke33aHS//xVXJ9n6YJ5mvPQffL7mYoWAIBEc9ksOjbPpY+3+bSkxqehGQ7ObgHf0a3D1qJFi3TTTTdp3LhxCofDuvvuuzVp0iStXr1aKSkpkqSHH35Ys2bN0ty5czVs2DDdf//9Ovvss7VmzRqlpaVJkqZOnaq33npLL774onJycjRt2jRdeOGFWr58uaxWrhVKpJV1fs3b1KKopCKPTUNbN6tm3dcqHTJcw488Kq7PVbluTVz7AwAA+zYuz63PtvtU4wurojmkQemOZJcEdCvdOmy9++67HW4/9dRTys/P1/Lly3XaaafJNE099thjuvvuu3XZZZdJkp5++mkVFBTo+eef1w033KDGxkbNmTNHzz77rM466yxJ0nPPPafi4mK99957Oueccw776+oLTNPUwq1efbJr/awjspw6vyRVX65kPQ4AAHoLj92io3JcWrbdr49qvCpLs3N2C9hNtw5b39XY2ChJys7OliRVVFSopqZGkyZNirVxOp2aMGGClixZohtuuEHLly9XKBTq0KaoqEijR4/WkiVL9hq2AoGAAoF/za7T1NSUiJfUZVVVVaqrq0tI37m5uSopKeny4yOmqb9XtujrXbMTnVLo0cmFbn75AgDQC40v8GhFnV9bWsOqagmpNI2zW0C7HhO2TNPUHXfcoVNOOUWjR4+WJNXU1EiSCgoKOrQtKChQZWVlrI3D4VBWVtYebdof35kHHnhA9957bzxfQtxUVVVp5MiR8nq9Cenf4/GovLy8S4ErGDH1WkWTKppDMiSdV5KqI3Nc8S8SAAB0C6l2i8bmuLSizq8lNT7CFrCbHhO2br75Zn355ZdavHjxHvd994yJaZr7PYuyvzZ33XWX7rjjjtjtpqYmFRcXH2TViVFXVyev16tfzp6j0iHD9/+Ag1C5fo3uv3mK6urqDjps+cJR/eXbJlV7w7JbpO8NTNfgDH7hAgDQ240vcGvlDr8qW0La3BLSgFR7sksCuoUeEbZuueUWvfnmm/rggw86zCBYWFgoqe3sVb9+/WLba2trY2e7CgsLFQwGVV9f3+HsVm1trU466aS9PqfT6ZTT2b2nME3EJBNd1RKK6qX1jdruj8htNfTDwekqSuEXLQAAfUGGw6ox2U59sSOgD6q9umpIOpcPAOrmYcs0Td1yyy167bXXtHDhQpWVlXW4v6ysTIWFhZo/f76OPvpoSVIwGNSiRYv00EMPSZKOPfZY2e12zZ8/X5dffrkkqbq6Wl999ZUefvjhw/uCepCDWSDYJ6uWK19ewy6nGdbR4VrVrKlUZ4M0WXgYAIDe6aRCj77aGVBVS0iVzSENZGZCoHuHrZtuuknPP/+83njjDaWlpcWuscrIyJDb3TbhwtSpUzVz5kwNHTpUQ4cO1cyZM+XxeHT11VfH2k6ZMkXTpk1TTk6OsrOzNX36dI0ZMyY2OyH+ZUdtjWQYuuaaaw6ofU7xIP30968os59dO7dU6o8//77qt1Tu93EsPAwAQO+S4bDqqFyXlm/3a1G1V6XMTAh077D1u9/9TpI0ceLEDtufeuopXXfddZKkO++8Uz6fTzfeeGNsUeN58+bF1tiSpN/85jey2Wy6/PLLY4saz507lzW2OtHS2CiZpm7+9aMaO278PttGrHY1ZpYoarXJGg5osDOsh+f8eZ+PYeFhAAB6r5MKPPpyh1/V3rDWNwU1NKN7X5IBJFq3Dlumae63jWEYmjFjhmbMmLHXNi6XS48//rgef/zxOFbXu/UvG7zP68F84ahW7QwoGpU8NkOj8jLkGJC5335ZeBgAgN4rxW7RsXluLd3m0wdbvRqS7uDsFvo0S7ILQM/j3RW0Qu1BK8sph5VfpAAAQBqf75bTYmi7P6Ly+mCyywGSirCFg+ILR/XVbkFrdDZBCwAA/IvbZtHxBW5J0oc1rYpE9z9SCeitCFs4YP5IVF/tDHYIWnYLQQsAAHR0XJ5LHpuh+kBUn9dxnTb6LsIWDkggYurrnUEFo6bc1rahgwQtAADQGafVolP7eSRJi2u88oejSa4ISA7CFvYrFDX19c6A/BFTTquhUQwdBAAA+zE2x6Vcl1X+iKkl23zJLgdICsIW9im8K2j5IqYcFkOjsxxyErQAAMB+WAxDpxelSJKWb/epIRBJckXA4UfYwl5FTVNrGoJqDZuyW6RR2Q65bPzIAACAAzMo3a6BaXZFTGnh1tZklwMcdrxzxl6tawypIRiVxZBGZjnlIWgBAICDYBiGzujfdnbrm4agNreEklwRcHjx7hmdKxioOn9EhqQRmQ6l2flRAQAABy/fbdPYHKckad7mFkVNpoJH38E7aOzh1GtvlHL6S5KGZNiV5bQmuSIAANCTTeiXIqfVUK0vwlTw6FMIW+jAljdA599+ryRpYJpN+W5bkisCAAA9ncdu0YRdU8F/UO1Va4ip4NE3ELYQUx+IyDHkqLYbO7aof4o9qfUAAIDe46hclwrcVgUiJpNloM8gbEGS1ByK6puGoAyLRZ///a/Sto3JLgkAAPQiFsPQOcWpkqRVOwNMloE+gbAF+SNRldcHFDWlcH2tXplxW7JLAgAAvVBRij02WcY/NrUowmQZ6OUIW31cOGqqvD6oUFRKsRkKrFmmSJhPmgAAQGJMKEqR22pouz+iT7b5kl0OkFCErT7MNE2tbQjKu2vR4pFZTinC6u4AACBxPDaLzhzQtvbWRzVe7fCHk1wRkDiErT6sojmk+mBUFrUFLafVSHZJAACgDxiV5dTgdLsipvT3KtbeQu9F2Oqjqr1hVXvbzmINY9FiAABwGBm7JstwWAxtaQ1rBWtvoZfiHXYfVB+IaENT23VZpak25bhYtBgAABxe6Q6rJha1rb21aGurGgJcyoDeh7DVx3hDUa1pCEqS8l1W9U9h0WIAAJAcR+e6NCDFplBU+ltVM8MJ0esQtvqQYMTU6oagIqaUbrdocIZdhsF1WgAAIDkMw9AFpWmyW6RNLWF9WsvshOhdCFt9RNQ09U1DUIGIKZfV0IgshywELQAAkGRZTqvOGtC22PEH1V7VeJmdEL0HYasPME1T6xpDag5FZTWkkVkO2S0ELQAA0D0cme3UsAyHoqb0VmWzQlGGE6J3IGz1AZtaw6rzR2RIGpHpkMfGbgcAAN2HYRg6tyRVKTZDO/wRLdjSmuySgLhgdoRebrsvrE0tbafjB6Xblelk5kEAAHDgysvLE9Z3bm6uSkpKJLUtdnxBaZr+8m2TVtT5VZpm1/BMZ8KeGzgcCFu9WFMwonWNbVO8F3lsKvSwuwEAwIHZUVsjGYauueaahD2Hx+NReXl5LHANSndoXJ5Ly7b79ffKFuW7bcrig2L0YLz77qX84ai+aQjKlJTttGhgGrsaAAAcuJbGRsk0dfOvH9XYcePj3n/l+jW6/+Ypqquri4UtSZrYP0VbvWFtaQ3r9YomXTssUzauNUcPxTvwXigcNVXeEFQoKqXYDA3LcDDFOwAA6JL+ZYM1/MijDtvzWQ1DlwxM01NrGrTNF9F7m1t1bknqYXt+IJ6YKaGXMU1TaxqC8oZN2S3SyCynrHwaBAAAepB0h1UXl6ZJklbu8GvVDn+SKwK6hrDVy1Q0h9QQjMqitqDltBK0AABAz1OW7tDJhW5J0rubWrSlNZTkioCDR9jqRba2hlXtjUiShmU6lGZn9wIAgJ7rlEKPhmY4FDGlVzc0qSkYSXZJwEHh3XgvscMfUUVz2yc+pak25biYuQcAAPRshmHootI05bmsag2bemVDEwseo0chbPUCLaGo1jYGJUkFbqv6pzDvCQAA6B0cVkPfH5Qut83QNl9Ef6tslmkSuNAzELZ6uEAkqtX1AUVNKdNh0aB0OzMPAgCAXiXTadVlZemyGNI3DUEt2OpNdknAASFs9WBRw6LV9W1TvHtshoZnOmQhaAEAgF6oONWu83dNAf9prU+f1vqSXBGwf4StHspitao5vSg2xfsRWQ4W/AMAAL3a6GyXJhZ5JEnvb2nV6p2BJFcE7BthqwcyJV38Hw8q5EzZbYp3diUAAOj9xue7dVyeS5L0dlWzKpqCSa4I2DveofdAlUrT+B9cJ5kmU7wDAIA+xTAMndk/RSMzHYqa0isbmlTVzBpc6J54l97DbGkNaa0yJUkpLduZ4h0AAPQ5hmHogtI0DU63K2xKf93QqE0tBC50P4StHqbIY9MgNenjl+bI5atPdjkAAABJYbMYurQsXWVpdoWi0l+/bdKWVgIXuhfCVg9jGIaGqFFvPvQLMR0GAADoy2wWQ5cNSldpql3BqKm/rG/SZs5woRshbAEAAKDHslvaFj0uTrUpEDX10reNTJqBboOwBQAAgB7NYTV0+eAMDWofUrihSd80MC08ks+W7AIAAADQd5WXl8etr0GSWpWjbUrRGxVNChSnaWyuK279AweLsAUAAIDDbkdtjWQYuuaaa+Lar2Gx6NK7H9W4S6/RO5ta1BCM6LR+HhkGV7vj8CNsAQAA4LBraWyUTFM3//pRjR03Pq59V65fo3/+4X905r9N18fbfKoPRHRBaZrsFgIXDi/CFgAAAJKmf9lgDT/yqLj3e//NU3Tbz36i1ZYcfdMQVFOwUZcNSleqnSkLcPjw0wYAAIBeqUitunJwhlxWQ1u9YT31Tb2qmBoehxFhCwAAAL1WSZpdk4dnKs9lVWvY1AvrGvXJNq9M00x2aegDCFsAAADo1bKcVv14eKZGZTllSlqw1atXK5rlDUeTXRp6OcIWAAAAej27xdCFpamaNCBFFkNa1xjUnPJ6fdvIAshIHMIWAAAA+gTDMHRMnls/Hpap3F3DCv+6oUnzNrUoGGFYIeKPsAUAAIA+pdBj0+ThmTo2r23B4xV1fv2xvF7rOcuFOCNsAQAAoM+xWwydPSBVVwxOV7rDoqZQVC9vaNLrFU1qCXEtF+KDsAUAAIA+qyzdoZ+OyNLx+W4Zkr5pCOoPq+u1pMarUJShhTg0hC0AAAD0aQ6roTP6p2jy8Ez189gUjJr6oNqr/1tdr692+pkmHl1G2AIAAADUdi3Xj4dl6KLSVKXb24YWvl3ZojnfNKi8PqAooQsHyZbsAgAAAIDuwjAMjcp2aVimU5/V+rS01qc6f0RvbGxWjtOqEwrcOiLLKavFSHap6AEIWwAAAMB32C2GTiz06Ohcl5bX+bWs1qcdgYj+VtWihVtbdXSuW0fnupRiZ6AY9o6wBQAAAOyFy2bRyYUeHZfn0ortfi2v86slFNXiGq8+3ubV0AyHxmS7VJZul8XgbBc6ImwBAAAA++G0WnRioUfHF7i1piGoz2p92uoN65uGoL5pCCrVZtER2U6NyHSon8cmg+AFEbYAAADQS5WXlyes74m5uXIWF+nLnX6t3hlQSziqT2t9+rTWp3S7RcMyHRqS4dCAFLtsXN/VZxG2AAAA0KvsqK2RDEPXXHNNwp7D4/GovLxcZ5eU6IyiFK1vCuqb+oDWNwXVFIrqs+1+fbbdL7tFKk11qCzdruJUu/JcVs569SGELQAAAPQqLY2Nkmnq5l8/qrHjxse9/8r1a3T/zVNUV1enkpISWS2Ghmc6NTzTqVDUVEVTUGsbg6poCqo1bGp9U1Drm4KSJJfV0IBUu/p5bCpw21TosSmVSTZ6LcIWAAAAeqX+ZYM1/MijEtb/voYpFknqJ6lZdtXJrXo51SCn/BGL1jcGtb4xGGvrMCNKU1DpCipNQQ3ITNXIgQNkZ/hhj9enwtYTTzyhRx55RNXV1Ro1apQee+wxnXrqqckuCwAAAD1IV4cpWmw2FQ0brYFHn6CikUeqaPgY5Q0cqqDVqh1ya4fckqQvG6W/f7FDaXaLMp0WZTmsynJalem0Kt1hUardolSbhbW+eoA+E7ZeeuklTZ06VU888YROPvlkPfnkkzrvvPO0evVqlZSUJLs8AAAA9BDxHKZo7vhWYZtTYbtLYZtT3rCpoCxyp2WoORRVcyiqTQp3+li3zVCqbVf4slvksVnkshpy2Qy5rBa5rYZcu7Y5rYZsFkM2Q1wzdhj1mbA1a9YsTZkyRT/96U8lSY899pj+8Y9/6He/+50eeOCBJFcHAACAniYRwxTXfLlSPzv3FD39wksaMOwI+WSTVzZ5ZZdXNgVkVUBWmYYhX9iULxzRdn/koJ7DKlMOm0V2oy2A2S1tizjbdn1ZDckiyWIYshja9WXI0L/+b9nVpgNDampsktfr3etzGzIP9lvSwYB0l04cMuCQ+jic+kTYCgaDWr58uX7xi1902D5p0iQtWbKk08cEAgEFAoHY7cbGRklSU1NT4go9QC0tLZKktatWytfaGte+K79dK0mqKP9aKW53XPtOdP/Unpz+qT05/VN7cvqn9uT0T+3J6Z/ak9P/18s/kSRNvuqKfbZzZ2QpNSdPaTkFSsvJV1puvjwZWXKlZciVliFPeqZcqelyp2XIlZ4hh8vT4fHxfQf5XYmb8OPPf3lO/33tRSouLk7YcxyI9kxgmvsOj4a5vxa9wNatW9W/f3999NFHOumkk2LbZ86cqaefflpr1qzZ4zEzZszQvffeezjLBAAAANCDbNq0SQMG7P1MW584s9Xuu+NTTdPc65jVu+66S3fccUfsdjQa1c6dO5WTk8M41yRpampScXGxNm3apPT09GSXg+9g/3Rf7Jvujf3TvbF/ui/2TffW2/ePaZpqbm5WUVHRPtv1ibCVm5srq9WqmpqaDttra2tVUFDQ6WOcTqecTmeHbZmZmYkqEQchPT29Vx60vQX7p/ti33Rv7J/ujf3TfbFvurfevH8yMjL226ZPrKDmcDh07LHHav78+R22z58/v8OwQgAAAACIlz5xZkuS7rjjDl177bU67rjjdOKJJ+oPf/iDqqqq9POf/zzZpQEAAADohfpM2Lriiiu0Y8cO3Xfffaqurtbo0aP197//XaWlpckuDQfI6XTqnnvu2WN4J7oH9k/3xb7p3tg/3Rv7p/ti33Rv7J82fWI2QgAAAAA43PrENVsAAAAAcLgRtgAAAAAgAQhbAAAAAJAAhC0AAAAASADCFrq9GTNmyDCMDl+FhYXJLqtP+uCDD3TRRRepqKhIhmHo9ddf73C/aZqaMWOGioqK5Ha7NXHiRH399dfJKbYP2t/+ue666/Y4lk444YTkFNvHPPDAAxo3bpzS0tKUn5+v733ve1qzZk2HNhw/yXMg+4fjJzl+97vf6cgjj4wtjHviiSfqnXfeid3PcZNc+9s/HDeELfQQo0aNUnV1dexr1apVyS6pT2ptbdXYsWM1e/bsTu9/+OGHNWvWLM2ePVvLli1TYWGhzj77bDU3Nx/mSvum/e0fSTr33HM7HEt///vfD2OFfdeiRYt00003aenSpZo/f77C4bAmTZqk1tbWWBuOn+Q5kP0jcfwkw4ABA/Tggw/qs88+02effaYzzjhDl1xySSxQcdwk1/72j8RxIxPo5u655x5z7NixyS4D3yHJfO2112K3o9GoWVhYaD744IOxbX6/38zIyDB///vfJ6HCvu27+8c0TXPy5MnmJZdckpR60FFtba0pyVy0aJFpmhw/3c13949pcvx0J1lZWeYf//hHjptuqn3/mCbHjWmaJme20COsW7dORUVFKisr05VXXqkNGzYkuyR8R0VFhWpqajRp0qTYNqfTqQkTJmjJkiVJrAy7W7hwofLz8zVs2DD97Gc/U21tbbJL6pMaGxslSdnZ2ZI4frqb7+6fdhw/yRWJRPTiiy+qtbVVJ554IsdNN/Pd/dOurx83tmQXAOzP+PHj9cwzz2jYsGHatm2b7r//fp100kn6+uuvlZOTk+zysEtNTY0kqaCgoMP2goICVVZWJqMkfMd5552nH/7whyotLVVFRYV+9atf6YwzztDy5cvldDqTXV6fYZqm7rjjDp1yyikaPXq0JI6f7qSz/SNx/CTTqlWrdOKJJ8rv9ys1NVWvvfaajjjiiFig4rhJrr3tH4njRiJsoQc477zzYv8fM2aMTjzxRA0ePFhPP/207rjjjiRWhs4YhtHhtmmae2xDclxxxRWx/48ePVrHHXecSktL9be//U2XXXZZEivrW26++WZ9+eWXWrx48R73cfwk3972D8dP8gwfPlwrV65UQ0ODXnnlFU2ePFmLFi2K3c9xk1x72z9HHHEEx42YIAM9UEpKisaMGaN169YluxTspn2GyPZP6NvV1tbu8akjuod+/fqptLSUY+kwuuWWW/Tmm29qwYIFGjBgQGw7x0/3sLf90xmOn8PH4XBoyJAhOu644/TAAw9o7Nix+u1vf8tx003sbf90pi8eN4Qt9DiBQEDl5eXq169fskvBbsrKylRYWKj58+fHtgWDQS1atEgnnXRSEivD3uzYsUObNm3iWDoMTNPUzTffrFdffVXvv/++ysrKOtzP8ZNc+9s/neH4SR7TNBUIBDhuuqn2/dOZvnjcMIwQ3d706dN10UUXqaSkRLW1tbr//vvV1NSkyZMnJ7u0PqelpUXr16+P3a6oqNDKlSuVnZ2tkpISTZ06VTNnztTQoUM1dOhQzZw5Ux6PR1dffXUSq+479rV/srOzNWPGDH3/+99Xv379tHHjRv3nf/6ncnNzdemllyax6r7hpptu0vPPP6833nhDaWlpsU/iMzIy5Ha7ZRgGx08S7W//tLS0cPwkyX/+53/qvPPOU3FxsZqbm/Xiiy9q4cKFevfddzluuoF97R+Om12SNg8icICuuOIKs1+/fqbdbjeLiorMyy67zPz666+TXVaftGDBAlPSHl+TJ082TbNt+up77rnHLCwsNJ1Op3naaaeZq1atSm7Rfci+9o/X6zUnTZpk5uXlmXa73SwpKTEnT55sVlVVJbvsPqGz/SLJfOqpp2JtOH6SZ3/7h+Mnea6//nqztLTUdDgcZl5ennnmmWea8+bNi93PcZNc+9o/HDdtDNM0zcMZ7gAAAACgL+CaLQAAAABIAMIWAAAAACQAYQsAAAAAEoCwBQAAAAAJQNgCAAAAgAQgbAEAAABAAhC2AAAAACABCFsAAAAAkACELQAA9mLgwIF67LHHkl0GAKCHImwBALqt3//+90pLS1M4HI5ta2lpkd1u16mnntqh7YcffijDMLR27drDXeZhNXfuXGVmZia7DADAASBsAQC6rdNPP10tLS367LPPYts+/PBDFRYWatmyZfJ6vbHtCxcuVFFRkYYNG3ZQzxGJRBSNRuNWMwAA7QhbAIBua/jw4SoqKtLChQtj2xYuXKhLLrlEgwcP1pIlSzpsP/3001VfX68f//jHysrKksfj0Xnnnad169bF2rWfGXr77bd1xBFHyOl0qrKyUrW1tbrooovkdrtVVlamP//5z3vU09DQoH/7t39TQUGBXC6XRo8erbfffjt2/yuvvKJRo0bJ6XRq4MCBevTRRzs83jAMvf766x22ZWZmau7cuZKkjRs3yjAMvfrqqzr99NPl8Xg0duxYffzxx7HX+JOf/ESNjY0yDEOGYWjGjBld/O4CABKNsAUA6NYmTpyoBQsWxG4vWLBAEydO1IQJE2Lbg8GgPv74Y51++um67rrr9Nlnn+nNN9/Uxx9/LNM0df755ysUCsX68Hq9euCBB/THP/5RX3/9tfLz83Xddddp48aNev/99/Xyyy/riSeeUG1tbewx0WhU5513npYsWaLnnntOq1ev1oMPPiir1SpJWr58uS6//HJdeeWVWrVqlWbMmKFf/epXsSB1MO6++25Nnz5dK1eu1LBhw3TVVVcpHA7rpJNO0mOPPab09HRVV1erurpa06dP7+J3FgCQaLZkFwAAwL5MnDhRt99+u8LhsHw+nz7//HOddtppikQi+n//7/9JkpYuXSqfz6dTTjlFP/3pT/XRRx/ppJNOkiT9+c9/VnFxsV5//XX98Ic/lCSFQiE98cQTGjt2rCRp7dq1euedd7R06VKNHz9ekjRnzhyNHDkyVsd7772nTz/9VOXl5bGhioMGDYrdP2vWLJ155pn61a9+JUkaNmyYVq9erUceeUTXXXfdQb3m6dOn64ILLpAk3XvvvRo1apTWr1+vESNGKCMjQ4ZhqLCw8GC/lQCAw4wzWwCAbu30009Xa2urli1bpg8//FDDhg1Tfn6+JkyYoGXLlqm1tVULFy5USUmJ1qxZI5vNFgtMkpSTk6Phw4ervLw8ts3hcOjII4+M3S4vL5fNZtNxxx0X2zZixIgOE1GsXLlSAwYM2Os1YeXl5Tr55JM7bDv55JO1bt06RSKRg3rNu9fWr18/Sepwlg0A0DNwZgsA0K0NGTJEAwYM0IIFC1RfX68JEyZIkgoLC1VWVqaPPvpICxYs0BlnnCHTNDvtwzRNGYYRu+12uzvcbn/c7tu+y+1277PO7z7H7v22M4z/v527B2kkisIw/FlokT6mkAEhGskgKRQLLTJeK4tAwBQhYmlCesXSQjshXTqLkC4Itv4ggRSDGFDRMrGwEWwUBANaBLLFssPOLmHNwrguvE83Z+6d4nYf584Z+q328/XGH4aHh317JDHEAwD+Q3S2AABfnjFGjUZDjUZDi4uLXt1xHJ2enuri4kLGGNm2rW63q2az6a15fn5Wu932XQn8VTweV7fb9U09bLVaenl58Z4TiYQeHh76jpa3bVuu6/pq5+fnisVi3n9d4XBYj4+P3vu7uzvfRMWPGBkZGbhTBgD4NwhbAIAvzxgj13V1c3Pjdbak72Frf39f7+/vMsZocnJS6XRa+Xxeruvq9vZWa2trGhsbUzqd7vv9qakpLS8vK5/Pq9ls6urqSuvr675uluM4SiaTymQyOjs70/39vY6Pj3VyciJJ2tjYUL1e1+7urtrttqrVqsrlsm+AxdLSksrlsq6vr3V5ealisejrYn3E+Pi4Op2O6vW6np6eBg5rAIDPQ9gCAHx5xhi9vb1pYmJCkUjEqzuOo9fXV0WjUVmWJUmqVCqanZ1VKpXS/Py8er2ejo6O/hhqKpWKLMuS4zhaWVlRoVDQ6Oiob83h4aHm5uaUy+Vk27a2tra8LtPMzIwODg5Uq9U0PT2t7e1t7ezs+IZjlEolWZalZDKp1dVVbW5uKhQKDXQWCwsLKhaLymazCofD2tvbG2g/AODzDPX6XXAHAAAAAPw1OlsAAAAAEADCFgAAAAAEgLAFAAAAAAEgbAEAAABAAAhbAAAAABAAwhYAAAAABICwBQAAAAABIGwBAAAAQAAIWwAAAAAQAMIWAAAAAASAsAUAAAAAAfgGMwE2gcWWP00AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_vis = train_data.copy()\n",
    "train_vis[\"word_count\"] = train_vis[\"text\"].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "sns.histplot(train_vis[\"word_count\"], bins = 30, kde = True, color = \"skyblue\")\n",
    "\n",
    "plt.title(\"Wordcount Distribution\", fontsize = 14)\n",
    "plt.xlabel(\"Wordcount\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987db500-970c-467e-bb36-410380f383b1",
   "metadata": {},
   "source": [
    "> Here, I plotted the word count distribution of the data.  \n",
    "> There are some entries with fewer than five words, and since one of them typically represents the airline's username, such samples may not be informative enough for the model to learn sentiment effectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea133159-8888-4b42-b3b0-9fee7d89d455",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with <5 words: 387\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9692</th>\n",
       "      <td>@USAirways follow/dm please</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7003</th>\n",
       "      <td>@JetBlue *fights air*</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4809</th>\n",
       "      <td>@SouthwestAir yes, please #companionpass</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12685</th>\n",
       "      <td>@AmericanAir amen!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2829</th>\n",
       "      <td>@united exactly</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8535</th>\n",
       "      <td>@JetBlue Aw okay thanks</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>@VirginAmerica delayed to10.30!!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8270</th>\n",
       "      <td>@JetBlue Just sent it</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5657</th>\n",
       "      <td>@SouthwestAir I would.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1081</th>\n",
       "      <td>@united Definitely will!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7102</th>\n",
       "      <td>@JetBlue sounds good!!!💙💙💙💙</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>@SouthwestAir I DM'd you</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5691</th>\n",
       "      <td>@SouthwestAir Jackpot!  #legroom http://t.co/Z...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9290</th>\n",
       "      <td>@USAirways ok thanks</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>@united thank you!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11860</th>\n",
       "      <td>@AmericanAir thanks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2952</th>\n",
       "      <td>@united thnx!</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8288</th>\n",
       "      <td>@JetBlue thanks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8881</th>\n",
       "      <td>@JetBlue Thank you!</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3216</th>\n",
       "      <td>@united sent DM's</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  word_count\n",
       "9692                         @USAirways follow/dm please           3\n",
       "7003                               @JetBlue *fights air*           3\n",
       "4809            @SouthwestAir yes, please #companionpass           4\n",
       "12685                                 @AmericanAir amen!           2\n",
       "2829                                     @united exactly           2\n",
       "8535                             @JetBlue Aw okay thanks           4\n",
       "370                     @VirginAmerica delayed to10.30!!           3\n",
       "8270                               @JetBlue Just sent it           4\n",
       "5657                              @SouthwestAir I would.           3\n",
       "1081                            @united Definitely will!           3\n",
       "7102                         @JetBlue sounds good!!!💙💙💙💙           3\n",
       "5313                            @SouthwestAir I DM'd you           4\n",
       "5691   @SouthwestAir Jackpot!  #legroom http://t.co/Z...           4\n",
       "9290                                @USAirways ok thanks           3\n",
       "1168                                  @united thank you!           3\n",
       "11860                                @AmericanAir thanks           2\n",
       "2952                                       @united thnx!           2\n",
       "8288                                     @JetBlue thanks           2\n",
       "8881                                 @JetBlue Thank you!           3\n",
       "3216                                   @united sent DM's           3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "short_sentences = train_vis[train_vis[\"word_count\"] < 5]\n",
    "\n",
    "print(f\"Data with <5 words: {len(short_sentences)}\")\n",
    "display(short_sentences[[\"text\", \"word_count\"]].head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f7284f-32dc-4f40-a393-48aa9326b740",
   "metadata": {},
   "source": [
    "> Here, I displayed several samples with fewer than five words.  \n",
    "> As expected, these short texts do not convey any meaningful sentiment toward the airline, so I plan to remove them during preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45634214-c929-4c77-9725-19c15e803749",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **PREPROCESSING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0f40d06a-02f6-41f3-bd47-89f82eb9b7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. @JetBlue ruining vacations left and right. Who would have thought an airline can Cancelled Flight tickets without telling the buyer\n",
      "\n",
      "2. @AmericanAir  upon entering plane to 2 @USAirways stewardesses: \"can I have some water?\" \"no we don't do that. please take your seat\"\n",
      "\n",
      "3. @united Thank you for that. Am I able to claim any interim expenses or is the cost of the stuff up on me?\n",
      "\n",
      "4. @AmericanAir Thanks! Bleh, disconnected! Let's try this again!!\n",
      "\n",
      "5. @JetBlue 1472, FLL to LGA. This is getting old. 4th @JetBlue flight in 2.5 weeks, 4th significant delay.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(train_data[\"text\"].iloc[0:5], 1):\n",
    "    print(f\"{i}. {text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5ff2f5c6-3442-4f4c-8dcf-b023186b798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. @united assistance with what, the attitude of your staff no matter which airport we are at?\n",
      "\n",
      "2. @SouthwestAir your gate agent re-routed an impossible itinerary and we had to find a new airline to get us home. Super bummed about this\n",
      "\n",
      "3. @SouthwestAir I did but it only shows one flight one way. When I try to go to the home page and book roundtrip there's nothing available :(\n",
      "\n",
      "4. @VirginAmerica flight 404 delayed 2 hours in LA due to mechanical problems. Handle like pros but you could have tossed us a free drink.\n",
      "\n",
      "5. @SouthwestAir what does relay concerns really mean &amp; how/why do u keep letting people on flights with bags larger than u state are allowabl?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, text in enumerate(train_data[\"text\"].iloc[-6:-1], 1):\n",
    "    print(f\"{i}. {text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7f2d2d-34af-453c-b2fe-e3b8a3a90c20",
   "metadata": {},
   "source": [
    "> Here, I displayed several samples from the data to identify what kind of cleaning is required.  \n",
    "> From these examples, I decided to remove the @Airline mentions, as they do not convey any sentiment information, and to remove punctuations since the objective is sentiment analysis rather than syntactic or question-based understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8f5f7543-0593-428b-95d5-ed7470d63c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    s = str(text).lower()\n",
    "    s = re.sub(r'@\\w+', \" \", s)\n",
    "    s = re.sub(r'[^a-z\\s]+', \" \", s)\n",
    "    s = re.sub(r'\\s+', \" \", s).strip()\n",
    "    tokens = word_tokenize(s)\n",
    "    tokens = [w for w in tokens if w not in stop_words and len(w) > 1]\n",
    "\n",
    "    return \" \".join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0b9b3875-ec0c-4cfb-929b-f741e20f31cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_1 = train_data.copy()\n",
    "train_data_1[\"text\"] = train_data_1[\"text\"].apply(preprocess_text)\n",
    "\n",
    "train_data_1 = train_data_1[train_data_1[\"text\"].str.split().str.len() >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2622a2a8-4467-4ea8-8c41-b73ed16f77cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_1 = test_data.copy()\n",
    "test_data_1[\"text\"] = test_data_1[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1fde730-482a-4469-903c-00ba673e1d03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8356</th>\n",
       "      <td>ruining vacations left right would thought air...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13186</th>\n",
       "      <td>upon entering plane stewardesses water please ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>thank able claim interim expenses cost stuff</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12392</th>\n",
       "      <td>thanks bleh disconnected let try</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>fll lga getting old th flight weeks th signifi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "8356   ruining vacations left right would thought air...          negative\n",
       "13186  upon entering plane stewardesses water please ...          negative\n",
       "560         thank able claim interim expenses cost stuff          positive\n",
       "12392                   thanks bleh disconnected let try          negative\n",
       "8438   fll lga getting old th flight weeks th signifi...          negative"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ac29aa1a-eedc-4d8c-b5f9-8e13991c8450",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text_2(text):\n",
    "    s = str(text).lower()\n",
    "    s = re.sub(r'@\\w+', \" \", s)\n",
    "    s = re.sub(r'[^a-z\\s]+', \" \", s)\n",
    "    s = re.sub(r'\\s+', \" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52770b0-bac0-4e90-9175-01d3d98ec5e5",
   "metadata": {},
   "source": [
    "> This second preprocessing function is used for Word2Vec, GloVe, and FastText models, as these embeddings can leverage stopwords to better capture sentence structure and contextual meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f96f1585-94f6-47ee-afc2-2f9b423ddad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_2 = train_data.copy()\n",
    "train_data_2[\"text\"] = train_data_2[\"text\"].apply(preprocess_text_2)\n",
    "\n",
    "train_data_2 = train_data_2[train_data_2[\"text\"].str.split().str.len() >= 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0ef73145-6a7e-4b6f-90fd-45350f3440a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_2 = test_data.copy()\n",
    "test_data_2[\"text\"] = test_data_2[\"text\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b1c161b-67ff-468f-be8d-205952316516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8356</th>\n",
       "      <td>ruining vacations left and right who would hav...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13186</th>\n",
       "      <td>upon entering plane to stewardesses can i have...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>thank you for that am i able to claim any inte...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12392</th>\n",
       "      <td>thanks bleh disconnected let s try this again</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8438</th>\n",
       "      <td>fll to lga this is getting old th flight in we...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text airline_sentiment\n",
       "8356   ruining vacations left and right who would hav...          negative\n",
       "13186  upon entering plane to stewardesses can i have...          negative\n",
       "560    thank you for that am i able to claim any inte...          positive\n",
       "12392      thanks bleh disconnected let s try this again          negative\n",
       "8438   fll to lga this is getting old th flight in we...          negative"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac1fdcc-5f59-42a7-8652-a057e9b87fec",
   "metadata": {},
   "source": [
    "> The data has been fully preprocessed and is now ready for vectorization and model training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d67dac5-7a5e-46fd-988f-377f38668dd1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **TEXT REPRESENTATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27238914-f8f2-4e16-87b8-e80e4d6940f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = train_data_1[\"text\"]\n",
    "y_train_1 = train_data_1[\"airline_sentiment\"]\n",
    "X_train_2 = train_data_2[\"text\"].apply(lambda x: x.split())\n",
    "y_train_2 = train_data_2[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1a33d2e1-220f-49d7-a2a0-19a5ef258864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8356     ruining vacations left right would thought air...\n",
       "13186    upon entering plane stewardesses water please ...\n",
       "560           thank able claim interim expenses cost stuff\n",
       "12392                     thanks bleh disconnected let try\n",
       "8438     fll lga getting old th flight weeks th signifi...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3d84c1f9-22d0-48e5-80f1-2c145eb5e223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8356     [ruining, vacations, left, and, right, who, wo...\n",
       "13186    [upon, entering, plane, to, stewardesses, can,...\n",
       "560      [thank, you, for, that, am, i, able, to, claim...\n",
       "12392    [thanks, bleh, disconnected, let, s, try, this...\n",
       "8438     [fll, to, lga, this, is, getting, old, th, fli...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7bba2a14-d693-40c2-9300-32f7bb81d2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_1 = test_data_1[\"text\"]\n",
    "y_test_1 = test_data_1[\"airline_sentiment\"]\n",
    "X_test_2 = test_data_2[\"text\"].apply(lambda x: x.split())\n",
    "y_test_2 = test_data_2[\"airline_sentiment\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e8a270-63f2-4702-b53b-454d1365eade",
   "metadata": {},
   "source": [
    "> Here, I split the data into X (**text**) and y (the target variable, **airline_sentiment**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba77e3d0-25ea-4381-94fe-3eb25be75edd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **BAG OF WORDS (COUNTVECTORIZER)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7fabfe-0750-4863-bada-6dcc375e7ca7",
   "metadata": {},
   "source": [
    "> The first vectorization method I used was the classic Bag of Words approach with CountVectorizer, which represents each tweet as a vector based on the frequency of its words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4a73c17-46d3-4565-b547-d8c3dd63c7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count of uniques or vocabularies:  7000\n",
      "Example vocabularies:  ['ruining', 'vacations', 'left', 'right', 'would', 'thought', 'airline', 'cancelled', 'flight', 'tickets']\n",
      "Example vector: [0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "bow = CountVectorizer(max_features = 7000)\n",
    "X_train_BOW = bow.fit_transform(X_train_1)\n",
    "X_test_BOW = bow.transform(X_test_1)\n",
    "print(\"Count of uniques or vocabularies: \", len(bow.vocabulary_))\n",
    "print(\"Example vocabularies: \", list(bow.vocabulary_.keys())[:10])\n",
    "print(\"Example vector:\", X_train_BOW[0].toarray()[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd597d4-757c-4fce-8c65-2707a00cd4d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **TF-IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42574d20-c571-4a9c-8ec2-6902aeaf9567",
   "metadata": {},
   "source": [
    "> The second vectorization method I applied was the TF-IDF Vectorizer, as it can better highlight important words by giving higher weights to terms that are frequent in a tweet but rare across the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ace0c9b6-92e2-4da2-a931-00ca85a7160a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (10338, 7000)\n",
      "Count of uniques or vocabularies:  7000\n",
      "Example vocabularies:  ['ruining', 'vacations', 'left', 'right', 'would', 'thought', 'airline', 'cancelled', 'flight', 'tickets']\n",
      "Example vector: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 7000, ngram_range=(1,2))\n",
    "X_train_TFIDF = tfidf.fit_transform(X_train_1)\n",
    "X_test_TFIDF = tfidf.transform(X_test_1)\n",
    "print(\"Shape: \", X_train_TFIDF.shape)\n",
    "print(\"Count of uniques or vocabularies: \", len(tfidf.vocabulary_))\n",
    "print(\"Example vocabularies: \", list(tfidf.vocabulary_.keys())[:10])\n",
    "print(\"Example vector:\", X_train_TFIDF[0].toarray()[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc984575-b3ac-4677-b7b4-357d01a54a05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **WORD2VEC**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be738e1d-d7fd-4e48-b19c-218508b896ca",
   "metadata": {},
   "source": [
    "> Here, I used Word2Vec as the third vectorization method, since it can capture semantic relationships and similarities between words, unlike BoW or TF-IDF that rely solely on frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "105cc3ed-4f08-48ec-aaf6-3e6accf3c6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training W2V...\n"
     ]
    }
   ],
   "source": [
    "print(\"Training W2V...\")\n",
    "w2v = Word2Vec(sentences = X_train_2, vector_size = 100, window = 7, min_count = 2, workers = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c352041f-b481-4aaa-bd76-60b40ce92037",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vector(tokens, model):\n",
    "    vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "df78b87f-3783-4c28-bc8e-9a6147ca84e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (11110, 100)\n",
      "Count of uniques or vocabularies:  5111\n",
      "Example vocabularies:  ['to', 'i', 'the', 'a', 'you', 'for', 'flight', 'on', 'and', 't']\n",
      "Example vector: [ 0.02360349  0.33995602  0.23368981 -0.15756534  0.017655   -0.7057472\n",
      "  0.31090978  0.83498174 -0.34400615 -0.24324204]\n"
     ]
    }
   ],
   "source": [
    "X_train_W2V = np.array([average_vector(t, w2v) for t in X_train_2])\n",
    "X_test_W2V = np.array([average_vector(t, w2v) for t in X_test_2])\n",
    "print(\"Shape: \", X_train_W2V.shape)\n",
    "print(\"Count of uniques or vocabularies: \", len(w2v.wv))\n",
    "print(\"Example vocabularies: \", list(w2v.wv.key_to_index.keys())[:10])\n",
    "print(\"Example vector:\", X_train_W2V[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3213e6-3fa9-4c28-bc8d-8c8de9065c08",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **GLOVE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34798e98-6607-459b-b52a-272c31f729e7",
   "metadata": {},
   "source": [
    "> The fourth representation used is GloVe, another word embedding model similar to Word2Vec, but trained using global word co-occurrence statistics instead of local context prediction.  \n",
    "> I also used the pretrained **glove-twitter-100** embeddings from Gensim, which were trained and better match the domain of my data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ad1db911-ad57-4fe4-86b8-30409e85e363",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = api.load(\"glove-twitter-100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f94e2b1-c614-44b4-baf3-838cf02c2f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(tokens):\n",
    "    words = [w for w in tokens if w in glove]\n",
    "    if not words:\n",
    "        return np.zeros(glove.vector_size)\n",
    "    return np.mean([glove[w] for w in words], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aeab6ee6-6a0d-4f24-9a63-6c1ddb93b9e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (11110, 100)\n",
      "Count of uniques or vocabularies:  1193514\n",
      "Example vocabularies:  ['<user>', '.', ':', 'rt', ',', '<repeat>', '<hashtag>', '<number>', '<url>', '!']\n",
      "Example vector: [ 0.05308282  0.22147179  0.1539059   0.01443494 -0.03866816 -0.00721848\n",
      "  0.10360511  0.04060584  0.0597218  -0.05518379]\n"
     ]
    }
   ],
   "source": [
    "X_train_glove = np.array([get_vector(t) for t in X_train_2])\n",
    "X_test_glove = np.array([get_vector(t) for t in X_test_2])\n",
    "print(\"Shape: \", X_train_glove.shape)\n",
    "print(\"Count of uniques or vocabularies: \", len(glove.key_to_index))\n",
    "print(\"Example vocabularies: \", list(glove.key_to_index.keys())[:10])\n",
    "print(\"Example vector:\", X_train_glove[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7eb27b-b427-44a8-8e06-26c21887c72f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **FASTTEXT**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8622f-eb4f-438f-a8b8-66f9d92a4864",
   "metadata": {},
   "source": [
    "> The last representation I used is FastText, an improved embedding method compared to Word2Vec and GloVe, as it can generate representations for out-of-vocabulary (OOV) words by learning from subword information.  \n",
    "> I used the pretrained **fasttext-wiki-news-subwords-300** embeddings, which already capture general English semantics while remaining flexible enough to adapt to noisy tweet data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0815d27c-0364-4ea1-81e3-615fbc1eee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftext = api.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b960366-becd-48f0-a99c-00be7946d8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_vector_f(tokens, model):\n",
    "    vectors = []\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vectors.append(model[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "68a86f67-e97f-4e8d-9154-afe53d33541a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape:  (11110, 300)\n",
      "Count of uniques or vocabularies:  999999\n",
      "Example vocabularies:  [',', 'the', '.', 'and', 'of', 'to', 'in', 'a', '\"', ':']\n",
      "Example vector: [ 0.05308282  0.22147179  0.1539059   0.01443494 -0.03866816 -0.00721848\n",
      "  0.10360511  0.04060584  0.0597218  -0.05518379]\n"
     ]
    }
   ],
   "source": [
    "X_train_FT = np.array([average_vector_f(t, ftext) for t in X_train_2])\n",
    "X_test_FT = np.array([average_vector_f(t, ftext) for t in X_test_2])\n",
    "print(\"Shape: \", X_train_FT.shape)\n",
    "print(\"Count of uniques or vocabularies: \", len(ftext))\n",
    "print(\"Example vocabularies: \", list(ftext.key_to_index.keys())[:10])\n",
    "print(\"Example vector:\", X_train_glove[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7915f4b-3305-4188-8ee0-e965fbd6bbe4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **MODEL TRAINING, EVALUATION, AND FINE TUNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ea8413-4acd-44e7-bec2-1eaa03119009",
   "metadata": {},
   "source": [
    "> As the baseline model for this sentiment analysis, I used a Random Forest classifier.  \n",
    "> This model was chosen because it provides strong baseline performance even on noisy and high-dimensional data such as text features.  \n",
    "> The Random Forest can handle sparse inputs from Bag of Words and TF-IDF representations effectively, while being relatively robust to overfitting.  \n",
    "> Random Forest was also applied on top of Word2Vec, GloVe, and FastText embeddings to maintain model consistency across representations.  \n",
    "> Since these embeddings produce dense numerical vectors, Random Forest can still learn non-linear decision boundaries from them, making it suitable as a fair baseline for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3e691515-2908-4178-be05-b35aca391e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators = 100, max_depth = 10, min_samples_split = 10, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198b8a4-c5cd-45b0-b35f-4f24d4012376",
   "metadata": {},
   "source": [
    "> I also created a **results_df** dataframe to store all evaluation metrics from the models, making it easier to compare their performance later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "179165db-8f66-4c5f-9ea0-e6bdd6de9f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns = [\n",
    "    \"Model\", \"Description\", \"Average Type\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\", \"F1 Negative\", \"F1 Neutral\", \"F1 Positive\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5a9d33d2-dd44-4bf6-b19c-8e7eb2ed4501",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_result(model_name, description, y_true, y_pred, used_smote = False):\n",
    "    avg_type = \"macro\" if used_smote else \"weighted\"\n",
    "    f1_per_class = f1_score(y_true, y_pred, average = None, zero_division = 0)\n",
    "    f1_negative, f1_neutral, f1_positive = f1_per_class\n",
    "    \n",
    "    results_df.loc[len(results_df)] = {\n",
    "        \"Model\": model_name,\n",
    "        \"Description\": description,\n",
    "        \"Average Type\": avg_type,\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, average = avg_type, zero_division = 0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, average = avg_type, zero_division = 0),\n",
    "        \"F1 Score\": f1_score(y_true, y_pred, average = avg_type, zero_division = 0),\n",
    "        \"F1 Negative\": f1_negative,\n",
    "        \"F1 Neutral\": f1_neutral,\n",
    "        \"F1 Positive\": f1_positive\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d581dcf7-2df0-4fdf-84a6-fcd54c380df8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ab8b7126-aa99-41b7-9c34-62dbf69ffd96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      1.00      0.77      1816\n",
      "     neutral       0.00      0.00      0.00       609\n",
      "    positive       0.00      0.00      0.00       456\n",
      "\n",
      "    accuracy                           0.63      2881\n",
      "   macro avg       0.21      0.33      0.26      2881\n",
      "weighted avg       0.40      0.63      0.49      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_BOW, y_train_1)\n",
    "y_pred_BOW = model.predict(X_test_BOW)\n",
    "print(classification_report(y_test_1, y_pred_BOW))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390132bc-5893-4e78-9e15-9545fad3e6eb",
   "metadata": {},
   "source": [
    "> Based on the classification report, the overall model accuracy is around 63%, indicating a relatively weak start.  \n",
    "> The macro and weighted averages of precision, recall, and F1 scores are all below 50%, suggesting that the model fails to generalize well across sentiment classes.  \n",
    "> Moreover, the precision, recall, and F1 scores for both neutral and positive sentiments are 0, meaning that the model completely failed to identify any samples from these classes.  \n",
    "> This shows a heavy bias toward the dominant negative class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c92c0bae-533d-4479-ab1b-607d009edfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 1\", \n",
    "           \"Bag of Words\",\n",
    "           y_test_1,\n",
    "           y_pred_BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a280ee-94c8-4956-9ce4-2fa40af2a198",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b4909f9a-8c04-4a3c-80e8-9e33eccf3cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      1.00      0.77      1816\n",
      "     neutral       0.92      0.02      0.04       609\n",
      "    positive       0.00      0.00      0.00       456\n",
      "\n",
      "    accuracy                           0.63      2881\n",
      "   macro avg       0.52      0.34      0.27      2881\n",
      "weighted avg       0.59      0.63      0.50      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_TFIDF, y_train_1)\n",
    "y_pred_TFIDF = model.predict(X_test_TFIDF)\n",
    "print(classification_report(y_test_1, y_pred_TFIDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33357142-ab64-47a4-bc5b-6fd18c7da890",
   "metadata": {},
   "source": [
    "> Based on the classification report, even though the overall accuracy and the macro and weighted F1 scores remain relatively similar to the previous model, the precision for the neutral sentiment significantly increased to 92%.  \n",
    "> This indicates that the TF-IDF representation helps the model better distinguish neutral tweets, even if its recall is still very low. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78b86167-e88d-40dd-9f0c-7d5269db0a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 2\", \n",
    "           \"TFIDF\",\n",
    "           y_test_1,\n",
    "           y_pred_TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76809eb6-aa8b-48b0-ac42-0b8265e73ab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **WORD2VEC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8974e4a2-e9e9-446b-b183-2de01a2fa3eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.72      0.78      0.75      1816\n",
      "     neutral       0.37      0.45      0.40       609\n",
      "    positive       0.60      0.20      0.30       456\n",
      "\n",
      "    accuracy                           0.62      2881\n",
      "   macro avg       0.56      0.48      0.49      2881\n",
      "weighted avg       0.63      0.62      0.61      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_W2V, y_train_2)\n",
    "y_pred_W2V = model.predict(X_test_W2V)\n",
    "print(classification_report(y_test_2, y_pred_W2V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e7bf2c-3236-4698-a797-f463d7b2d3ee",
   "metadata": {},
   "source": [
    "> The third model shows a more balanced trade-off between precision and recall across all sentiment classes.  \n",
    "> Although the overall performance is still relatively weak, it demonstrates a clear improvement compared to the previous two models.  \n",
    "> In particular, the weighted F1 score increased by around 10% compared to the TF-IDF model, indicating that this representation helps the model generalize better across different sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "234f1e3c-18eb-435a-8aec-91854fea2010",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 3\", \n",
    "           \"Word2Vec\",\n",
    "           y_test_2,\n",
    "           y_pred_W2V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20c5cb9-47b6-4428-8fb7-1196d7a92de6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **GLOVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d50f1ec7-9fad-4d15-b7ce-8aff119de6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.94      0.83      1816\n",
      "     neutral       0.58      0.29      0.39       609\n",
      "    positive       0.72      0.44      0.55       456\n",
      "\n",
      "    accuracy                           0.73      2881\n",
      "   macro avg       0.68      0.56      0.59      2881\n",
      "weighted avg       0.71      0.73      0.69      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_glove, y_train_2)\n",
    "y_pred_glove = model.predict(X_test_glove)\n",
    "print(classification_report(y_test_2, y_pred_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a13a266-005c-40ad-b133-2c8267f1a2cb",
   "metadata": {},
   "source": [
    "> The fourth model shows a significant improvement in overall accuracy, positive sentiment prediction, and weighted F1 score.  \n",
    "> This indicates that using GloVe as the text representation provides a more meaningful and semantically rich encoding compared to the previous methods.  \n",
    "> The model now captures sentiment cues more effectively, especially for positive tweets, although there is still room for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "997e8817-073b-4097-b1d1-901b67cafa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 4\", \n",
    "           \"GloVe\",\n",
    "           y_test_2,\n",
    "           y_pred_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea05b3c0-c822-437c-912a-4e1a05748c38",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **FASTTEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e89ad007-ef3d-4ce5-b64b-cab6042ddaf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.93      0.83      1816\n",
      "     neutral       0.53      0.26      0.35       609\n",
      "    positive       0.73      0.46      0.57       456\n",
      "\n",
      "    accuracy                           0.72      2881\n",
      "   macro avg       0.67      0.55      0.58      2881\n",
      "weighted avg       0.69      0.72      0.68      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_FT, y_train_2)\n",
    "y_pred_FT = model.predict(X_test_FT)\n",
    "print(classification_report(y_test_2, y_pred_FT))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b08d48d-53ff-4262-8b09-bb0ffd329b2f",
   "metadata": {},
   "source": [
    "> The fifth model, which uses FastText embeddings, performs relatively similar to the previous GloVe-based model.  \n",
    "> The overall accuracy and weighted F1 score remain consistent at around 72% and 0.68 respectively, showing that both embeddings capture sentiment-related information effectively.  \n",
    "> However, FastText does not show a clear advantage in this data, possibly because the tweet corpus is relatively clean and contains few out-of-vocabulary words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9b4e477f-905d-449d-9d09-37240e49fba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 5\", \n",
    "           \"FastText\",\n",
    "           y_test_2,\n",
    "           y_pred_FT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84cfd7ca-2542-4859-a9c7-53411024b346",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **FINE TUNING**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6ce5d2-aafa-42f8-8919-c4f3e2403a49",
   "metadata": {},
   "source": [
    "> In order to fit the data better, I performed fine-tuning for all models to determine the optimal configuration for each text representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "75fb3d7f-04ef-44cb-9392-f42dd8ddc59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyparameters = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [10, 20, 30],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6412a1-da71-41e0-a263-f2cdd8f6dbeb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bd677f0-cc05-439d-a820-b2a9c18308a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  0.5878750903069417\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1_weighted\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_BOW, y_train_1)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eb6a864b-f8cb-4b52-af26-b8fe0eec7030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.65      1.00      0.79      1816\n",
      "     neutral       0.84      0.06      0.12       609\n",
      "    positive       0.96      0.11      0.20       456\n",
      "\n",
      "    accuracy                           0.66      2881\n",
      "   macro avg       0.82      0.39      0.37      2881\n",
      "weighted avg       0.74      0.66      0.55      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_BOW_model = grid_search.best_estimator_\n",
    "ft_BOW_model.fit(X_train_BOW, y_train_1)\n",
    "y_pred_FT_BOW = ft_BOW_model.predict(X_test_BOW)\n",
    "print(classification_report(y_test_1, y_pred_FT_BOW))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f794a4-9948-41db-994a-6f7228ea7b2d",
   "metadata": {},
   "source": [
    "> After fine-tuning, the BOW-based model shows a clear improvement, particularly for the neutral and positive sentiments.  \n",
    "> Both classes now achieve precision scores above 70%, although their recall values remain relatively low.  \n",
    "> This suggests that the model can now identify these sentiments more accurately when it does predict them, but it still fails to detect most of their occurrences.\n",
    "> The optimal configuration: ```{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}``` fits the data better, leading to a modest overall accuracy improvement to 66%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "74fbf4cf-e07e-4639-9cba-af5dd0811be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 6\", \n",
    "           \"Bag of Words + Fine Tuning\",\n",
    "           y_test_1,\n",
    "           y_pred_FT_BOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e569bccb-04e6-4925-a148-edcf9b153209",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "520bbefe-562b-4572-9371-5838d80da772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 42}\n",
      "Best score :  0.599328225560468\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1_weighted\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_TFIDF, y_train_1)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "213d9b54-9bf0-41a6-b3f5-60ea4ef56da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.63      1.00      0.77      1816\n",
      "     neutral       0.00      0.00      0.00       609\n",
      "    positive       0.00      0.00      0.00       456\n",
      "\n",
      "    accuracy                           0.63      2881\n",
      "   macro avg       0.21      0.33      0.26      2881\n",
      "weighted avg       0.40      0.63      0.49      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_TFIDF_model = grid_search.best_estimator_\n",
    "ft_TFIDF_model.fit(X_train_TFIDF, y_train_1)\n",
    "y_pred_FT_TFIDF = ft_BOW_model.predict(X_test_TFIDF)\n",
    "print(classification_report(y_test_1, y_pred_FT_TFIDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f4ddb-35d9-497b-bce9-875771c5deb0",
   "metadata": {},
   "source": [
    "> After fine-tuning, the TF-IDF-based model experienced a notable performance drop.  \n",
    "> While accuracy remains the same, both macro and weighted F1 scores decline significantly, suggesting that the tuned hyperparameters led to stronger overfitting toward the dominant negative class.  \n",
    "> This result highlights that fine-tuning does not always guarantee improvement, especially when dealing with sparse and imbalanced text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3191a648-e7b2-432b-ab98-a0340a708b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 7\", \n",
    "           \"TFIDF + Fine Tuning\",\n",
    "           y_test_1,\n",
    "           y_pred_FT_TFIDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bcbac8a-ff2e-440c-aef9-1857d0e63293",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **WORD2VEC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9ab83f49-5a0c-4b3c-9a48-1bc9ce3fa93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 42}\n",
      "Best score :  0.6504460871267509\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1_weighted\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_W2V, y_train_2)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ae0c1b0c-e363-4090-9aa0-a4adc020cdbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.74      0.73      0.73      1816\n",
      "     neutral       0.36      0.50      0.42       609\n",
      "    positive       0.52      0.26      0.34       456\n",
      "\n",
      "    accuracy                           0.61      2881\n",
      "   macro avg       0.54      0.50      0.50      2881\n",
      "weighted avg       0.62      0.61      0.60      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_W2V_model = grid_search.best_estimator_\n",
    "ft_W2V_model.fit(X_train_W2V, y_train_2)\n",
    "y_pred_FT_W2V = ft_W2V_model.predict(X_test_W2V)\n",
    "print(classification_report(y_test_2, y_pred_FT_W2V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3775f89-29ab-4f94-9ff5-13a053df102f",
   "metadata": {},
   "source": [
    "> After fine-tuning, the W2V-based model shows only a slight decrease in overall performance, with accuracy dropping marginally from 62% to 61%.  \n",
    "> However, there is no significant improvement across any sentiment class.  \n",
    "> This suggests that the fine-tuning parameters did not meaningfully affect model generalization, likely because averaging Word2Vec embeddings already provides a stable but limited feature representation that the classifier cannot further optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68b18a95-13d1-49a3-b6e6-7f02c6e64a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 8\", \n",
    "           \"Word2Vec + Fine Tuning\",\n",
    "           y_test_2,\n",
    "           y_pred_FT_W2V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27609ebf-893d-48c6-9806-c183880aef86",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **GLOVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "28ab9071-ecde-40ea-b07d-ce783b9bdcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 42}\n",
      "Best score :  0.7173314783826835\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1_weighted\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_glove, y_train_2)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "63b151f5-02b0-4b16-b597-e0e0dcab33cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.84      1816\n",
      "     neutral       0.52      0.50      0.51       609\n",
      "    positive       0.71      0.58      0.64       456\n",
      "\n",
      "    accuracy                           0.74      2881\n",
      "   macro avg       0.68      0.65      0.66      2881\n",
      "weighted avg       0.74      0.74      0.74      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_glove_model = grid_search.best_estimator_\n",
    "ft_glove_model.fit(X_train_glove, y_train_2)\n",
    "y_pred_FT_glove = ft_glove_model.predict(X_test_glove)\n",
    "print(classification_report(y_test_2, y_pred_FT_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d4b473-b3b4-482b-bf18-1a2a6a3324cd",
   "metadata": {},
   "source": [
    "> The fine-tuned GloVe-based model demonstrates a more stable and balanced performance across sentiment classes.  \n",
    "> The neutral and positive sentiments show noticeable improvements in both recall and F1-score, while the negative class remains consistently strong.  \n",
    "> This indicates that the tuned configuration: ```{'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 200, 'random_state': 42}``` successfully improved the model's generalization, allowing it to better capture the semantic distinctions encoded in GloVe embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6f0ceb35-2d86-43e3-9628-2c9e6a4491e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 9\", \n",
    "           \"GloVe + Fine Tuning\",\n",
    "           y_test_2,\n",
    "           y_pred_FT_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796dbee2-eb65-4429-8dba-885af0c5fc82",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **FASTTEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9416b123-3f23-4fb6-a9fa-73963a4b49a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 30, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  0.6913384540549303\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1_weighted\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_FT, y_train_2)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "879e4632-0c7d-4c76-84fa-a424d0f64417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.84      0.82      1816\n",
      "     neutral       0.47      0.44      0.46       609\n",
      "    positive       0.67      0.58      0.62       456\n",
      "\n",
      "    accuracy                           0.71      2881\n",
      "   macro avg       0.64      0.62      0.63      2881\n",
      "weighted avg       0.71      0.71      0.71      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_ftext_model = grid_search.best_estimator_\n",
    "ft_ftext_model.fit(X_train_FT, y_train_2)\n",
    "y_pred_FT_ftext = ft_ftext_model.predict(X_test_FT)\n",
    "print(classification_report(y_test_2, y_pred_FT_ftext))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f3f97-0f23-49de-8d93-d4a2286e8463",
   "metadata": {},
   "source": [
    "> After fine-tuning, the FastText-based model maintains a consistent performance with only minor changes compared to its baseline.  \n",
    "> While the accuracy remains stable at around 71%, the F1-scores for the neutral and positive classes show moderate improvements, indicating slightly better balance across sentiments.  \n",
    "> However, the overall gain is less pronounced than that of the GloVe-based model, consistent with the baseline comparison, suggesting that FastText's subword-level representations provide limited additional benefit for this data, which contains relatively few out-of-vocabulary or misspelled words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a3524d24-8b3a-403d-872d-575f870dbdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 10\", \n",
    "           \"FastText + Fine Tuning\",\n",
    "           y_test_2,\n",
    "           y_pred_FT_ftext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52670aa8-65cd-4df4-af87-f57549d02d52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **AFTER IMBALANCE DATA HANDLING: SMOTE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bad3cb5-870a-4eff-9e90-2b4163919470",
   "metadata": {},
   "source": [
    "> To handle the class imbalance, I used SMOTE (Synthetic Minority Oversampling Technique) to generate synthetic samples for the minority classes.  \n",
    "> Unlike random oversampling, SMOTE creates new examples based on existing ones, reducing the risk of overfitting while helping the model generalize better.  \n",
    "> I didn’t use undersampling because cutting down the negative tweets to match the smaller classes would remove too much useful information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dae52479-d8e1-466f-af06-516378e689a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99b80536-0735-4818-91a1-c76d5d308c4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {'negative': 6901, 'neutral': 1971, 'positive': 1466}\n",
      "After SMOTE: {'negative': 6901, 'positive': 6901, 'neutral': 6901}\n"
     ]
    }
   ],
   "source": [
    "X_train_BOW_b, y_train_BOW_b = smote.fit_resample(X_train_BOW, y_train_1)\n",
    "print(\"Before SMOTE:\", y_train_1.value_counts().to_dict())\n",
    "print(\"After SMOTE:\",  pd.Series(y_train_BOW_b).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d2e2c0e5-90d4-4708-959a-18fb83b8cfbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {'negative': 6901, 'neutral': 1971, 'positive': 1466}\n",
      "After SMOTE: {'negative': 6901, 'positive': 6901, 'neutral': 6901}\n"
     ]
    }
   ],
   "source": [
    "X_train_TFIDF_b, y_train_TFIDF_b = smote.fit_resample(X_train_TFIDF, y_train_1)\n",
    "print(\"Before SMOTE:\", y_train_1.value_counts().to_dict())\n",
    "print(\"After SMOTE:\",  pd.Series(y_train_TFIDF_b).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "76ea31c3-19c3-4c91-b7cb-265832268bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {'negative': 7176, 'neutral': 2277, 'positive': 1657}\n",
      "After SMOTE: {'negative': 7176, 'positive': 7176, 'neutral': 7176}\n"
     ]
    }
   ],
   "source": [
    "X_train_W2V_b, y_train_W2V_b = smote.fit_resample(X_train_W2V, y_train_2)\n",
    "print(\"Before SMOTE:\", y_train_2.value_counts().to_dict())\n",
    "print(\"After SMOTE:\",  pd.Series(y_train_W2V_b).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3a43afc3-fc22-42c2-a1d6-2e51f7466558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {'negative': 7176, 'neutral': 2277, 'positive': 1657}\n",
      "After SMOTE: {'negative': 7176, 'positive': 7176, 'neutral': 7176}\n"
     ]
    }
   ],
   "source": [
    "X_train_glove_b, y_train_glove_b = smote.fit_resample(X_train_glove, y_train_2)\n",
    "print(\"Before SMOTE:\", y_train_2.value_counts().to_dict())\n",
    "print(\"After SMOTE:\",  pd.Series(y_train_glove_b).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "26c69f20-f91e-4efd-8e12-ab8aa392ee7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: {'negative': 7176, 'neutral': 2277, 'positive': 1657}\n",
      "After SMOTE: {'negative': 7176, 'positive': 7176, 'neutral': 7176}\n"
     ]
    }
   ],
   "source": [
    "X_train_ftext_b, y_train_ftext_b = smote.fit_resample(X_train_FT, y_train_2)\n",
    "print(\"Before SMOTE:\", y_train_2.value_counts().to_dict())\n",
    "print(\"After SMOTE:\",  pd.Series(y_train_ftext_b).value_counts().to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f91523e-9ac2-4122-b96b-6aec84e4a12a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **MODELING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c4136996-fe3a-4cc9-86a8-e313211dc759",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_b = RandomForestClassifier(n_estimators = 100, max_depth = 10, min_samples_split = 10, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18657e8-e0c0-4c91-b1a8-7a7b8f5c2833",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0be68a89-aa74-4407-bbb1-62832340628c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78      1816\n",
      "     neutral       0.43      0.60      0.50       609\n",
      "    positive       0.60      0.60      0.60       456\n",
      "\n",
      "    accuracy                           0.68      2881\n",
      "   macro avg       0.62      0.64      0.63      2881\n",
      "weighted avg       0.71      0.68      0.69      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_BOW_b, y_train_BOW_b)\n",
    "y_pred_BOW_b = model.predict(X_test_BOW)\n",
    "print(classification_report(y_test_1, y_pred_BOW_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1419f20-79ce-467f-a07b-8faae1d84bd1",
   "metadata": {},
   "source": [
    "> The BOW-based model with SMOTE demonstrates a substantial improvement in performance across all sentiment classes. The accuracy increases to 68%, and both macro and weighted F1 scores rise notably compared to the imbalanced versions.  \n",
    "> The neutral and positive classes, which previously had near-zero recall and F1 scores, now achieve around 0.50-0.60, indicating that the model can finally recognize minority sentiments more effectively.  \n",
    "> This suggests that oversampling through SMOTE successfully mitigated the class imbalance problem and allowed the model to generalize better across sentiment categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3eeb0757-529d-49a9-81a1-e0e6dada2e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 11\", \n",
    "           \"Bag of Words + SMOTE\",\n",
    "           y_test_1,\n",
    "           y_pred_BOW_b,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10074494-a277-4228-afdf-5632deb11ffd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **TFIDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "3ee49fe9-8cab-4163-8275-2749b5b0f672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.75      0.79      1816\n",
      "     neutral       0.45      0.57      0.50       609\n",
      "    positive       0.66      0.67      0.67       456\n",
      "\n",
      "    accuracy                           0.70      2881\n",
      "   macro avg       0.64      0.66      0.65      2881\n",
      "weighted avg       0.72      0.70      0.71      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_TFIDF_b, y_train_TFIDF_b)\n",
    "y_pred_TFIDF_b = model.predict(X_test_TFIDF)\n",
    "print(classification_report(y_test_1, y_pred_TFIDF_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fe3040-6ede-4b1f-92d7-556e128e1f70",
   "metadata": {},
   "source": [
    "> The TF-IDF-based model with SMOTE shows a remarkable improvement across all sentiment classes.  \n",
    "> The overall accuracy increases to 70%, and both macro and weighted F1-scores rise to around 0.65-0.71, representing a significant boost in generalization compared to the imbalanced versions.  \n",
    "> The neutral and positive sentiments, which previously had almost zero recall and F1-scores, now achieve balanced precision-recall values around 0.5-0.7.  \n",
    "> This indicates that SMOTE effectively mitigated the class imbalance issue, enabling the model to learn and predict minority sentiments more reliably without severely compromising the performance on the dominant negative class.  \n",
    "> Moreover, this model also outperforms the BOW-based model with SMOTE, achieving slightly higher accuracy and F1-scores, particularly for the positive sentiment.  \n",
    "> This suggests that TF-IDF's ability to weight less frequent, sentiment-bearing terms contributes to better discrimination across sentiment categories once data balance is restored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b460a252-82a9-4d0b-9454-0695ff8d13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 12\", \n",
    "           \"TFIDF + SMOTE\",\n",
    "           y_test_1,\n",
    "           y_pred_TFIDF_b,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a88be6-cce9-40ba-8ef7-9a7257e549be",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **WORD2VEC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3988d217-200a-4d88-8cd7-58620a77df94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.53      1816\n",
      "     neutral       0.33      0.64      0.43       609\n",
      "    positive       0.30      0.56      0.39       456\n",
      "\n",
      "    accuracy                           0.47      2881\n",
      "   macro avg       0.49      0.53      0.45      2881\n",
      "weighted avg       0.65      0.47      0.49      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_W2V_b, y_train_W2V_b)\n",
    "y_pred_W2V_b = model.predict(X_test_W2V)\n",
    "print(classification_report(y_test_2, y_pred_W2V_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ee0fca-bfe3-43d7-a7a2-95d393276613",
   "metadata": {},
   "source": [
    "> While the recall for neutral and positive classes increases moderately compared to the previous Word2Vec-based models, the overall accuracy drops from 62% to 47%, and the F1-scores become less stable across classes.  \n",
    "> This indicates that SMOTE disrupts the embedding space learned by Word2Vec, leading to distorted feature distributions that hinder the classifier's ability to generalize.  \n",
    "> Unlike sparse representations such as BoW or TF-IDF, where oversampling simply duplicates count-based vectors, oversampling dense embeddings can break the semantic structure that Word2Vec encodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "096962c5-ac8b-4577-8d9c-b879dacb0a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 13\", \n",
    "           \"Word2Vec + SMOTE\",\n",
    "           y_test_2,\n",
    "           y_pred_W2V_b,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9039f169-a93d-4409-8450-babc05ea14fc",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **GLOVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "364bb7e9-013c-41b8-9356-5180915ca45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.89      0.84      1816\n",
      "     neutral       0.53      0.35      0.42       609\n",
      "    positive       0.69      0.68      0.68       456\n",
      "\n",
      "    accuracy                           0.74      2881\n",
      "   macro avg       0.67      0.64      0.65      2881\n",
      "weighted avg       0.72      0.74      0.72      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_glove_b, y_train_glove_b)\n",
    "y_pred_glove_b = model.predict(X_test_glove)\n",
    "print(classification_report(y_test_2, y_pred_glove_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62185cf2-0e3d-48a0-bd43-9c172108a2a8",
   "metadata": {},
   "source": [
    "> When SMOTE is applied, the GloVe-based model maintains this high level of performance (accuracy 74%, macro F1 0.65), suggesting that GloVe embeddings are inherently robust to class imbalance.  \n",
    "> Unlike Word2Vec, SMOTE does not distort GloVe's global semantic space, and the model retains balanced precision-recall behavior across all sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "adba98a1-e948-4b2d-b1ec-349a2281d37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 14\", \n",
    "           \"GloVe + SMOTE\",\n",
    "           y_test_2,\n",
    "           y_pred_glove_b,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcb947-2517-487c-b3ef-4213694d2dd8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **FASTTEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "84acacdc-8593-4b0a-92de-6c23fd7a5760",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.86      0.82      1816\n",
      "     neutral       0.50      0.31      0.38       609\n",
      "    positive       0.61      0.73      0.66       456\n",
      "\n",
      "    accuracy                           0.72      2881\n",
      "   macro avg       0.63      0.63      0.62      2881\n",
      "weighted avg       0.70      0.72      0.70      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train_ftext_b, y_train_ftext_b)\n",
    "y_pred_ftext_b = model.predict(X_test_FT)\n",
    "print(classification_report(y_test_2, y_pred_ftext_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe1dc9a-c51e-43db-9efe-d8b612ef59be",
   "metadata": {},
   "source": [
    "> The FastText-based model with SMOTE maintains its overall stability (accuracy 72%, macro F1 0.69) but does not exhibit substantial enhancement.  \n",
    "> The positive class benefits the most from oversampling, while the neutral class remains challenging.  \n",
    "> These results indicate that FastText is resilient to imbalance but yields limited additional gains once the embeddings already encode subword-level semantics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "1dc6975a-ff75-4a70-b657-7cb498df333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 15\", \n",
    "           \"FastText + SMOTE\",\n",
    "           y_test_2,\n",
    "           y_pred_ftext_b,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f21349-f4d4-43a4-9f2b-427f131c51ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **FINE TUNING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "471bd0ea-330d-4a7e-a4b5-96ca539586cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyparameters = {\n",
    "    \"n_estimators\": [100, 200],\n",
    "    \"max_depth\": [10, 20, 30],\n",
    "    \"min_samples_split\": [10, 20, 30],\n",
    "    \"random_state\": [42]\n",
    "}\n",
    "\n",
    "cv_strategy = StratifiedKFold(n_splits = 10, shuffle = True, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79cd6c6-42d1-4c49-b7d5-b9689dffefee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **BOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e9909f1c-0488-4241-9b6a-2a6a175ac28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  nan\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_BOW_b, y_train_BOW_b)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "235ecb78-4c01-45e9-9148-e770d61ed0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.84      0.73      0.78      1816\n",
      "     neutral       0.43      0.60      0.50       609\n",
      "    positive       0.60      0.60      0.60       456\n",
      "\n",
      "    accuracy                           0.68      2881\n",
      "   macro avg       0.62      0.64      0.63      2881\n",
      "weighted avg       0.71      0.68      0.69      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_BOW_model = grid_search.best_estimator_\n",
    "ft_BOW_model.fit(X_train_BOW_b, y_train_BOW_b)\n",
    "y_pred_FT_BOW = ft_BOW_model.predict(X_test_BOW)\n",
    "print(classification_report(y_test_1, y_pred_FT_BOW))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbf088c-fbcb-4a9b-890c-9b38789615e7",
   "metadata": {},
   "source": [
    "> After fine-tuning the BOW-based model on the SMOTE-balanced data, the overall performance remains identical to the baseline configuration.  \n",
    "> The accuracy (0.68) and macro F1-score (0.63) show no further improvement, indicating that the initial parameter setup was already optimal under the balanced condition.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5e4da605-91dc-477a-9b7a-93e6c7d0807d",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 16\", \n",
    "           \"Bag of Words + SMOTE + Fine Tuning\",\n",
    "           y_test_1,\n",
    "           y_pred_FT_BOW,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ddfe8-1d9a-40bd-9a0f-dc5fa2837381",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **TF-IDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "5200565a-01ed-4147-95e7-e4730f1e3892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  nan\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_TFIDF_b, y_train_TFIDF_b)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2579e6cc-17be-4843-92e4-e4df8386f61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.83      0.75      0.79      1816\n",
      "     neutral       0.45      0.57      0.50       609\n",
      "    positive       0.66      0.67      0.67       456\n",
      "\n",
      "    accuracy                           0.70      2881\n",
      "   macro avg       0.64      0.66      0.65      2881\n",
      "weighted avg       0.72      0.70      0.71      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_TFIDF_model = grid_search.best_estimator_\n",
    "ft_TFIDF_model.fit(X_train_TFIDF_b, y_train_TFIDF_b)\n",
    "y_pred_FT_TFIDF = ft_TFIDF_model.predict(X_test_TFIDF)\n",
    "print(classification_report(y_test_1, y_pred_FT_TFIDF))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e6c697-b49c-41df-92f3-4e2cfc408c22",
   "metadata": {},
   "source": [
    "> After fine-tuning the TF-IDF-based model on the SMOTE-balanced data, the performance also remains identical to the SMOTE baseline configuration.  \n",
    "> The accuracy (0.70) and macro F1-score (0.65) show no further improvement, indicating that the baseline parameter setup was already optimal once the class imbalance had been addressed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "3cacdbe3-a32c-4587-8313-af282d6b7cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 17\", \n",
    "           \"TFIDF + SMOTE + Fine Tuning\",\n",
    "           y_test_1,\n",
    "           y_pred_FT_TFIDF,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c6a6e8-a602-4480-a56f-923e02e38eca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **WORD2VEC**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4260987d-c109-4b83-af04-ce27a0a1e4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  nan\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_W2V_b, y_train_W2V_b)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "9813a6d0-8b9d-4dbd-97b0-34bffa12566e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.85      0.38      0.53      1816\n",
      "     neutral       0.33      0.64      0.43       609\n",
      "    positive       0.30      0.56      0.39       456\n",
      "\n",
      "    accuracy                           0.47      2881\n",
      "   macro avg       0.49      0.53      0.45      2881\n",
      "weighted avg       0.65      0.47      0.49      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_W2V_model = grid_search.best_estimator_\n",
    "ft_W2V_model.fit(X_train_W2V_b, y_train_W2V_b)\n",
    "y_pred_FT_W2V = ft_W2V_model.predict(X_test_W2V)\n",
    "print(classification_report(y_test_2, y_pred_FT_W2V))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a932eb-5a7f-46f3-9d77-e2e1a5cad725",
   "metadata": {},
   "source": [
    "> After fine-tuning the Word2Vec model on the SMOTE-balanced data, the performance remains completely unchanged.  \n",
    "> Both the accuracy (0.47) and macro F1-score (0.45) are identical to the SMOTE baseline, indicating that hyperparameter adjustments had no effect on improving generalization.  \n",
    "> This outcome confirms that the decline in performance originates from the incompatibility between SMOTE and dense Word2Vec embeddings, rather than from suboptimal parameter configurations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a7aca6e9-8ebd-430e-9dfd-b31b4cb5d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 18\", \n",
    "           \"Word2Vec + SMOTE + Fine Tuning\",\n",
    "           y_test_2,\n",
    "           y_pred_FT_W2V,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81422da4-1ba1-4fbc-81cd-bedd44b454af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **GLOVE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "bc406bba-5187-4bcf-9a7e-af9fe2537ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  nan\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_glove_b, y_train_glove_b)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "42c0e199-ff0f-4700-9b60-70a6b5f0bce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.89      0.84      1816\n",
      "     neutral       0.53      0.35      0.42       609\n",
      "    positive       0.69      0.68      0.68       456\n",
      "\n",
      "    accuracy                           0.74      2881\n",
      "   macro avg       0.67      0.64      0.65      2881\n",
      "weighted avg       0.72      0.74      0.72      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_glove_model = grid_search.best_estimator_\n",
    "ft_glove_model.fit(X_train_glove_b, y_train_glove_b)\n",
    "y_pred_FT_glove = ft_glove_model.predict(X_test_glove)\n",
    "print(classification_report(y_test_2, y_pred_FT_glove))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747e6471-0980-42ff-bffd-2a45c4b7a530",
   "metadata": {},
   "source": [
    "> After fine-tuning the GloVe-based model on the SMOTE-balanced data, the performance remains the same as the baseline.  \n",
    "> The accuracy (0.74) and macro F1-score (0.65) show no further improvement, which means the baseline configuration was already optimal once the data imbalance was handled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "54508095-797a-4b82-9c29-b02437901f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 19\", \n",
    "           \"GloVe + SMOTE + Fine Tuning\",\n",
    "           y_test_2,\n",
    "           y_pred_FT_glove,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6eeda7-d3fa-4fbd-a35c-5b5250460696",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### **FASTTEXT**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d40bbf1b-3203-4a0b-9e2c-13e6b46ddbf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 18 candidates, totalling 180 fits\n",
      "Best parameter :  {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 100, 'random_state': 42}\n",
      "Best score :  nan\n"
     ]
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator = model, \n",
    "                           param_grid = hyparameters,\n",
    "                           scoring = \"f1\", \n",
    "                           cv = cv_strategy, \n",
    "                           n_jobs = -1, \n",
    "                           verbose = 2)\n",
    "\n",
    "grid_search.fit(X_train_ftext_b, y_train_ftext_b)\n",
    "\n",
    "print(\"Best parameter : \", grid_search.best_params_)\n",
    "print(\"Best score : \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "73da4f4e-91fd-4a0f-885c-6472dea06952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.86      0.82      1816\n",
      "     neutral       0.50      0.31      0.38       609\n",
      "    positive       0.61      0.73      0.66       456\n",
      "\n",
      "    accuracy                           0.72      2881\n",
      "   macro avg       0.63      0.63      0.62      2881\n",
      "weighted avg       0.70      0.72      0.70      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ft_ftext_model = grid_search.best_estimator_\n",
    "ft_ftext_model.fit(X_train_ftext_b, y_train_ftext_b)\n",
    "y_pred_FT_ftext = ft_ftext_model.predict(X_test_FT)\n",
    "print(classification_report(y_test_2, y_pred_FT_ftext))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87941ea-987b-483f-bf7d-393a4556f6c3",
   "metadata": {},
   "source": [
    "> After fine-tuning the FastText-based model on the SMOTE-balanced data, the results remain unchanged from the baseline configuration. The accuracy (0.72) and macro F1-score (0.62) show no further improvement, indicating that the baseline setup was already optimal once the data was balanced. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f8afa664-ba35-4c66-8b9f-c00fee7d7df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_result(\"Model 20\", \n",
    "           \"FastText + SMOTE + Fine Tuning\",\n",
    "           y_test_2,\n",
    "           y_pred_FT_ftext,\n",
    "           used_smote = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeef3d6-6e89-4ba8-b75e-a6b08f8b56db",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### **FINAL EVALUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e2eade54-6349-4436-a46b-222bdfb4ada8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Average Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>GloVe + Fine Tuning</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.735769</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.837520</td>\n",
       "      <td>0.508816</td>\n",
       "      <td>0.641737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Model 10</td>\n",
       "      <td>FastText + Fine Tuning</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.712947</td>\n",
       "      <td>0.705577</td>\n",
       "      <td>0.712947</td>\n",
       "      <td>0.708190</td>\n",
       "      <td>0.815092</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.619552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>GloVe</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.725095</td>\n",
       "      <td>0.706944</td>\n",
       "      <td>0.725095</td>\n",
       "      <td>0.692416</td>\n",
       "      <td>0.831553</td>\n",
       "      <td>0.386813</td>\n",
       "      <td>0.546448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model 5</td>\n",
       "      <td>FastText</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.717459</td>\n",
       "      <td>0.694933</td>\n",
       "      <td>0.717459</td>\n",
       "      <td>0.684659</td>\n",
       "      <td>0.825706</td>\n",
       "      <td>0.353458</td>\n",
       "      <td>0.565276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Model 12</td>\n",
       "      <td>TFIDF + SMOTE</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.698022</td>\n",
       "      <td>0.644560</td>\n",
       "      <td>0.663790</td>\n",
       "      <td>0.650975</td>\n",
       "      <td>0.785177</td>\n",
       "      <td>0.502527</td>\n",
       "      <td>0.665222</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model             Description Average Type  Accuracy  Precision  \\\n",
       "8    Model 9     GloVe + Fine Tuning     weighted  0.741409   0.735769   \n",
       "9   Model 10  FastText + Fine Tuning     weighted  0.712947   0.705577   \n",
       "3    Model 4                   GloVe     weighted  0.725095   0.706944   \n",
       "4    Model 5                FastText     weighted  0.717459   0.694933   \n",
       "11  Model 12           TFIDF + SMOTE        macro  0.698022   0.644560   \n",
       "\n",
       "      Recall  F1 Score  F1 Negative  F1 Neutral  F1 Positive  \n",
       "8   0.741409  0.737049     0.837520    0.508816     0.641737  \n",
       "9   0.712947  0.708190     0.815092    0.455782     0.619552  \n",
       "3   0.725095  0.692416     0.831553    0.386813     0.546448  \n",
       "4   0.717459  0.684659     0.825706    0.353458     0.565276  \n",
       "11  0.663790  0.650975     0.785177    0.502527     0.665222  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = \"F1 Score\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f0b6757-6c97-42b0-935f-4af7c2882caa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Average Type</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Neutral</th>\n",
       "      <th>F1 Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Model 9</td>\n",
       "      <td>GloVe + Fine Tuning</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.735769</td>\n",
       "      <td>0.741409</td>\n",
       "      <td>0.737049</td>\n",
       "      <td>0.837520</td>\n",
       "      <td>0.508816</td>\n",
       "      <td>0.641737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Model 19</td>\n",
       "      <td>GloVe + SMOTE + Fine Tuning</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.739674</td>\n",
       "      <td>0.672040</td>\n",
       "      <td>0.636524</td>\n",
       "      <td>0.646629</td>\n",
       "      <td>0.835883</td>\n",
       "      <td>0.420319</td>\n",
       "      <td>0.683685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Model 14</td>\n",
       "      <td>GloVe + SMOTE</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.739674</td>\n",
       "      <td>0.672040</td>\n",
       "      <td>0.636524</td>\n",
       "      <td>0.646629</td>\n",
       "      <td>0.835883</td>\n",
       "      <td>0.420319</td>\n",
       "      <td>0.683685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model 4</td>\n",
       "      <td>GloVe</td>\n",
       "      <td>weighted</td>\n",
       "      <td>0.725095</td>\n",
       "      <td>0.706944</td>\n",
       "      <td>0.725095</td>\n",
       "      <td>0.692416</td>\n",
       "      <td>0.831553</td>\n",
       "      <td>0.386813</td>\n",
       "      <td>0.546448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Model 20</td>\n",
       "      <td>FastText + SMOTE + Fine Tuning</td>\n",
       "      <td>macro</td>\n",
       "      <td>0.719195</td>\n",
       "      <td>0.633714</td>\n",
       "      <td>0.629555</td>\n",
       "      <td>0.622120</td>\n",
       "      <td>0.822005</td>\n",
       "      <td>0.379695</td>\n",
       "      <td>0.664659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model                     Description Average Type  Accuracy  \\\n",
       "8    Model 9             GloVe + Fine Tuning     weighted  0.741409   \n",
       "18  Model 19     GloVe + SMOTE + Fine Tuning        macro  0.739674   \n",
       "13  Model 14                   GloVe + SMOTE        macro  0.739674   \n",
       "3    Model 4                           GloVe     weighted  0.725095   \n",
       "19  Model 20  FastText + SMOTE + Fine Tuning        macro  0.719195   \n",
       "\n",
       "    Precision    Recall  F1 Score  F1 Negative  F1 Neutral  F1 Positive  \n",
       "8    0.735769  0.741409  0.737049     0.837520    0.508816     0.641737  \n",
       "18   0.672040  0.636524  0.646629     0.835883    0.420319     0.683685  \n",
       "13   0.672040  0.636524  0.646629     0.835883    0.420319     0.683685  \n",
       "3    0.706944  0.725095  0.692416     0.831553    0.386813     0.546448  \n",
       "19   0.633714  0.629555  0.622120     0.822005    0.379695     0.664659  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by = \"Accuracy\", ascending = False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18a6353-4fb3-445d-9049-4a7f60d7eae2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **BEST MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3ef97d23-eaea-45d8-88fe-647a62999dd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.86      0.84      1816\n",
      "     neutral       0.52      0.50      0.51       609\n",
      "    positive       0.71      0.58      0.64       456\n",
      "\n",
      "    accuracy                           0.74      2881\n",
      "   macro avg       0.68      0.65      0.66      2881\n",
      "weighted avg       0.74      0.74      0.74      2881\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_model = RandomForestClassifier(n_estimators = 200, max_depth = 30, min_samples_split = 10, random_state = 42)\n",
    "best_model.fit(X_train_glove, y_train_2)\n",
    "y_pred_glove = best_model.predict(X_test_glove)\n",
    "print(classification_report(y_test_2, y_pred_glove))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "981ab1e1-1f86-400e-94df-83205cabd0be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjgAAAHFCAYAAAD/kYOsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjYsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvq6yFwwAAAAlwSFlzAAAPYQAAD2EBqD+naQAAeE5JREFUeJzt3XdYFFfbBvB76X1pAqI0FREVe4NEQQGxa4wVGxF7IaioMcaWKCiJJWqssWDXJGJMYsNG7CKKlagxqBhB1CBNOvP9wct8rsBKx13vn9delztzZvaZ2V14eM45MxJBEAQQERERKRGV6g6AiIiIqKIxwSEiIiKlwwSHiIiIlA4THCIiIlI6THCIiIhI6TDBISIiIqXDBIeIiIiUDhMcIiIiUjpMcIiIiEjpMMGpQDdu3MBnn30GOzs7aGlpQU9PDy1atEBwcDD++++/Sn3ta9euwdXVFVKpFBKJBCtWrKjw15BIJJg/f36F7/ddtm7dColEAolEgtOnTxdaLwgC6tWrB4lEAjc3tzK9xpo1a7B169ZSbXP69OliY6oqycnJWLx4Mdq2bQtDQ0Ooq6vD3NwcXbp0wa5du5CZmSm2ffjwISQSSamPc8qUKZBIJPjrr7+KbTN79mxIJBJcvXq1rIciw93dHePGjROfF5zroh79+vUDUPWfz/nz5xcb05uPsn4mK1NJzlXB5+XNh4GBAZo2bYoVK1YgNze30uIr7ffR1tZW7rnetm2b3J8hZVXwGSgLHx8f2Nrais+zs7NRt27dSvnZ/aFSq+4AlMXGjRsxYcIEODg4YPr06WjYsCGys7Nx5coVrFu3DhcuXEBoaGilvf7IkSORlpaGPXv2wMjISOaLU1EuXLiA2rVrV/h+S0pfXx+bNm0q9EMsPDwcDx48gL6+fpn3vWbNGpiamsLHx6fE27Ro0QIXLlxAw4YNy/y65XH//n106dIFCQkJGDNmDGbPng0jIyPExcXh6NGjGDlyJKKjo/HNN9+U63V8fX2xYsUKbN68GcHBwYXW5+XlYdu2bWjWrBlatGhRrtcCgF9//RXnzp3Dtm3bCq0LDAxEx44dZZaZmJgAqPrP56hRo9ClSxfxeVxcHPr27YvJkyfD29tbXG5gYFBlMVWGN4/n1atXOHjwIKZMmYLY2FgsXbq0Ul6zLN9HfX19/Pnnn3jw4AHq1q0rs27z5s0wMDBAcnJyBUdacdTV1TF37lxMmTIFw4YNEz/XVA4Cldv58+cFVVVVoUuXLkJGRkah9ZmZmcKvv/5aqTGoqakJ48ePr9TXqC5btmwRAAijRo0StLW1haSkJJn1Q4cOFZydnYVGjRoJrq6uZXqN0myblZUlZGdnl+l1Kkp2drbQsGFDwdDQULhz506RbR4+fCiEhoaKz2NiYgQAwpYtW0r9em3atBEsLCyKPO7Dhw8LAIRVq1aVer/FvdagQYNklp06dUoAIPz0008V8hqVoeD8fvvtt9UdyjsBEObNmye3jbzjad++vVCzZs1Kiq5030dBEAQbGxuha9euQu3atYUvv/xSZt3ff/8tSCQSYfTo0QIA4dSpUxUW57x584Sy/hodMWKEYGNjI7MsMzNTMDY2FhYtWlQB0RG7qCpAYGAgJBIJNmzYAE1NzULrNTQ00KtXL/F5Xl4egoOD0aBBA2hqasLMzAzDhw/HkydPZLZzc3ND48aNERERgfbt20NHRwd16tTB4sWLkZeXB+D/u29ycnKwdu1asQwLFF8+Ldjm4cOH4rKTJ0/Czc0NJiYm0NbWhrW1NT799FO8fv1abFNUWfvWrVvo3bs3jIyMoKWlhWbNmiEkJESmTUH3wu7duzF79mxYWlrCwMAAHh4euHv3bslOMoDBgwcDAHbv3i0uS0pKwi+//IKRI0cWuc2CBQvQtm1bGBsbw8DAAC1atMCmTZsgvHGPWVtbW9y+fRvh4eHi+SuogBXEvn37dkybNg21atWCpqYm/v7770JdVC9evICVlRVcXFyQnZ0t7v/OnTvQ1dXFsGHDSnys7xIaGoo7d+5g9uzZcHR0LLKNjY0N+vTp8859nT17Fu7u7tDX14eOjg5cXFzwxx9/yLTx9fVFfHw8Dh8+XGj7LVu2QFNTE0OGDAGQ320WEBAAOzs7aGhooFatWvD390daWto7Y7l27RouX75cpnP19uez4HN+6tQpjB8/HqampjAxMUHfvn3x9OnTQtvv3bsXzs7O0NXVhZ6eHry8vHDt2rVSx/Gmor5rQNHdmyX5vhco6TlOTk7G6NGjYWJiAj09PXTp0gX37t0r1zEBgFQqhbq6eqHlJTmH//zzDwYNGgRLS0toamrC3Nwc7u7uiIqKAiD/+yiPiooKhg8fjpCQEJnztXnzZlhZWcHDw6PI7Q4ePAhnZ2fo6OhAX18fnp6euHDhQqF2f/zxB5o1awZNTU3Y2dnhu+++K3J/giBgzZo1aNasGbS1tWFkZIR+/frhn3/+eecxaGhoYODAgdiwYYPMzygqGyY45ZSbm4uTJ0+iZcuWsLKyKtE248ePx8yZM+Hp6YmDBw/im2++wZEjR+Di4oIXL17ItI2Pj8eQIUMwdOhQHDx4EF27dsWsWbOwY8cOAED37t3FL2O/fv1w4cKFIr+c8jx8+BDdu3eHhoYGNm/ejCNHjmDx4sXQ1dVFVlZWsdvdvXsXLi4uuH37NlauXIn9+/ejYcOG8PHxKbIr48svv8SjR4/w448/YsOGDbh//z569uxZ4r58AwMD9OvXD5s3bxaX7d69GyoqKhg4cGCxxzZ27Fjs27cP+/fvF7sQ3uy2CQ0NRZ06ddC8eXPx/L3dnThr1iw8fvwY69atw2+//QYzM7NCr2Vqaoo9e/YgIiICM2fOBAC8fv0a/fv3h7W1NdatW1ei4yyJsLAwAJBJnMsiPDwcnTp1QlJSEjZt2oTdu3dDX18fPXv2xN69e8V2gwcPho6Ojsy5B4DExET8+uuv+OSTT2BkZITXr1/D1dUVISEh8PPzw+HDhzFz5kxs3boVvXr1eucP7d9//x2qqqro0KFDkevz8vKQk5Mj83iXUaNGQV1dHbt27UJwcDBOnz6NoUOHyrQJDAzE4MGD0bBhQ+zbtw/bt29HSkoK2rdvjzt37rzzNSrKu77vAEp8jgVBQJ8+fcTkPDQ0FO3atUPXrl1LFdOb5/zly5fiz4i3k9CSnsNu3bohMjISwcHBCAsLw9q1a9G8eXO8evUKQMm+j8UZOXIknj59iqNHjwLI//kcEhICHx8fqKgU/nW3a9cu9O7dGwYGBti9ezc2bdqExMREuLm54ezZs2K7EydOoHfv3tDX18eePXvw7bffYt++fdiyZUuhfY4dOxb+/v7w8PDAgQMHsGbNGty+fRsuLi549uzZO4/Bzc0Njx49wq1bt0p0zCRHdZaPlEF8fLwAoFBJvTjR0dECAGHChAkyyy9duiQAkCmvurq6CgCES5cuybRt2LCh4OXlJbMMgDBx4kSZZcWVTwu6fGJiYgRBEISff/5ZACBERUXJjR1vlbUHDRokaGpqCo8fP5Zp17VrV0FHR0d49eqVIAj/373QrVs3mXb79u0TAAgXLlyQ+7oF8UZERIj7unXrliAIgtC6dWvBx8dHEIR3l7Vzc3OF7Oxs4euvvxZMTEyEvLw8cV1x2xa8XocOHYpd93bJe8mSJQIAITQ0VBgxYoSgra0t3LhxQ+4xllaXLl0EAIW6RPPy8oTs7GzxkZOTI64rqouqXbt2gpmZmZCSkiIuy8nJERo3bizUrl1b5hyNGDFCUFdXF549eyYuW7VqlQBACAsLEwRBEIKCggQVFRUhIiJCJq6Cz9ihQ4fkHlfXrl2FBg0aFFpecK6Lety/f18QhMKfz4LPzdvfteDgYAGAEBcXJwiCIDx+/FhQU1MTJk+eLNMuJSVFsLCwEAYMGCA35gJFdem8/V17+3je/OyU9Pte0nNc0HX4/fffy7RbtGhRqbqoinr4+PjIfLZKeg5fvHghABBWrFgh97XL0kXVvXt3QRDyz2O/fv0EQRCEP/74Q5BIJEJMTIzw008/yZzz3NxcwdLSUnBychJyc3NlYjYzMxNcXFzEZW3bthUsLS2F9PR0cVlycrJgbGws8zP2woULAgBh6dKlMvHFxsYK2trawowZM8RlRXVRCYIg3L9/XwAgrF27tsTHT0VjBaeKnTp1CgAKDZ5r06YNHB0dceLECZnlFhYWaNOmjcyyJk2a4NGjRxUWU7NmzaChoYExY8YgJCSkRKVUIL9by93dvVDlysfHB69fvy5USXq72tCkSRMAKNWxuLq6om7duti8eTNu3ryJiIiIYrunCmL08PCAVCqFqqqqOJDv5cuXSEhIKPHrfvrppyVuO336dHTv3h2DBw9GSEgIVq1aBScnp3du93ZlQihDifr777+Hurq6+GjatGmxbdPS0nDp0iX069cPenp64nJVVVUMGzYMT548kelC9PX1RXZ2NrZv3y4u27JlC2xsbODu7g4gvwLTuHFjNGvWTOZYvLy8SjSD5enTp0VWxwosWbIEERERMo93VU7f9bk7evQocnJyMHz4cJmYtbS04OrqKsYsCEKpq0elVZLve0nPccHPmoKuwwJvDoAuic8//1w816dOnUJgYCD27dsndhkDJT+HxsbGqFu3Lr799lssW7YM165dK9T9Vl4jR47EwYMH8fLlS2zatAkdO3Yssovr7t27ePr0KYYNGyZT3dHT08Onn36Kixcv4vXr10hLS0NERAT69u0LLS0tsV1BpfNNv//+OyQSCYYOHSpzHiwsLNC0adMSzeAq+Pz/+++/ZTsBJGKCU06mpqbQ0dFBTExMidq/fPkSAFCzZs1C6ywtLcX1BYoaSa+pqYn09PQyRFu0unXr4vjx4zAzM8PEiRNRt25d1K1bF99//73c7V6+fFnscRSsf9Pbx1IwXqk0xyKRSPDZZ59hx44dWLduHerXr4/27dsX2fby5cvo3LkzgPxZbufOnUNERARmz55d6tct6jjlxejj44OMjAxYWFiUaDzJw4cPZRITdXV1hIeHF9ve2toaQOHk0NvbW/xl9K4ZTYmJiRAEocTvYfv27VG/fn2xLH/jxg1cvXoVn332mTjW69mzZ7hx40ahY9HX14cgCIW6YN+Wnp4u80vkbXXq1EGrVq1kHkWNe3vTuz53Bd0GrVu3LhT33r17xZjDw8MLrX97bE15leT7XtJz/PLlS6ipqRXap4WFRaliql27tniu3dzcMGvWLMyZMwc//fST2BVU0nMokUhw4sQJeHl5ITg4GC1atECNGjXg5+eHlJSUUsVVnH79+kFLSwvLly/Hb7/9Bl9f3yLbvetncV5eHhITE5GYmIi8vLwiz9vby549ewZBEGBubl7oPFy8ePGdn38A4ue/In/Gf6g4TbycVFVV4e7ujsOHD+PJkyfvnKZa8MMmLi6uUNunT5/C1NS0wmIr+KJkZmbK/BIo6kvWvn17tG/fHrm5ubhy5QpWrVoFf39/mJubY9CgQUXu38TEBHFxcYWWFwzgrMhjeZOPjw/mzp2LdevWYdGiRcW227NnD9TV1fH777/L/NI8cOBAqV+zNNe6iIuLw8SJE9GsWTPcvn0bAQEBWLlypdxtLC0tERERIbPMwcGh2Paenp7YsGEDDh48iICAAHG5mZmZ+Begvr6+zHVw3mZkZAQVFZVSvYcjR47EF198gcuXL2PXrl1QUVGRqUaamppCW1u70FidN9fLY2pqWunXjCrqNQHg559/ho2NTbHtWrZsWeg9KkgEi/Pmd/BNJflFV5ySnmMTExNx3MybSU58fHyZX7tAQRXs+vXr8PLyKvE5BPIHv2/atAkAcO/ePezbtw/z589HVlZWhYxT09HRwaBBgxAUFAQDAwP07du3yHZv/ix+29OnT6GiogIjIyMIggCJRFLkeXt7mampKSQSCc6cOVNk4v2uZByA+PmvrJ+fHxJWcCrArFmzIAgCRo8eXeSg3OzsbPz2228AgE6dOgGAzKBBAIiIiEB0dLRY6q8IBWXZGzduyCwviKUoqqqqaNu2LX744QcAkHvhNnd3d5w8ebLQjJRt27ZBR0cH7dq1K2Pk8tWqVQvTp09Hz549MWLEiGLbSSQSqKmpQVVVVVyWnp4u08VSoKKqYrm5uRg8eDAkEgkOHz6MoKAgrFq1Cvv375e7nYaGRqHKhLzr+nzyySdo2LAhAgMD5V6ATx5dXV20bdsW+/fvlzn2vLw87NixA7Vr10b9+vVlthkxYgTU1NSwfv167Ny5E+7u7jK/0Hr06IEHDx7AxMSk0PG0atXqnbNhGjRoUOIu0ori5eUFNTU1PHjwoMiYW7VqBSA/YXx7uYaGhtx9F/cdPHjwYJnjLek5Lrhe0M6dO2W237VrV5lfu0DBjKeCZLqk5/Bt9evXx1dffQUnJyeZnzXl/T6OHz8ePXv2xNy5c4utCDo4OKBWrVrYtWuXTHdwWloafvnlF3Fmla6uLtq0aYP9+/cjIyNDbJeSklLoZ2mPHj0gCAL+/fffIs9BSbqqCz7/1XV9LWXCCk4FcHZ2xtq1azFhwgS0bNkS48ePR6NGjZCdnY1r165hw4YNaNy4MXr27AkHBweMGTMGq1atgoqKCrp27YqHDx9izpw5sLKywpQpUyosrm7dusHY2Bi+vr74+uuvoaamhq1btyI2Nlam3bp163Dy5El0794d1tbWyMjIEP86LG5qJQDMmzcPv//+Ozp27Ii5c+fC2NgYO3fuxB9//IHg4GBIpdIKO5a3LV68+J1tunfvjmXLlsHb2xtjxozBy5cv8d133xX5V5STkxP27NmDvXv3ok6dOtDS0irRD6O3zZs3D2fOnMGxY8dgYWGBadOmITw8HL6+vmjevDns7OxKvc+iqKqq4sCBA/Dy8kKbNm0wevRouLm5wcjICK9evcKlS5dw/fr1YqeQFwgKCoKnpyc6duyIgIAAaGhoYM2aNbh16xZ2795dqHJlYWGBbt26YcuWLRAEoVD539/fH7/88gs6dOiAKVOmoEmTJsjLy8Pjx49x7NgxTJs2DW3bti02Hjc3N2zevBn37t0rlFxVFltbW3z99deYPXs2/vnnH3Tp0gVGRkZ49uwZLl++DF1dXSxYsKBM+27dujUcHBwQEBCAnJwcGBkZITQ0VGaGTmmV9Bx37twZHTp0wIwZM5CWloZWrVrh3LlzRSb48jx+/BgXL14EkP/L/8KFCwgKCoKNjY1YHSnpObxx4wYmTZqE/v37w97eHhoaGjh58iRu3LiBL774QnzN8n4fmzVr9s5KrYqKCoKDgzFkyBD06NEDY8eORWZmJr799lu8evVK5mfMN998gy5dusDT0xPTpk1Dbm4ulixZAl1dXZmK40cffYQxY8bgs88+w5UrV9ChQwfo6uoiLi4OZ8+ehZOTE8aPHy83rosXL8qdSUilUE2Dm5VSVFSUMGLECMHa2lrQ0NAQdHV1hebNmwtz584VEhISxHa5ubnCkiVLhPr16wvq6uqCqampMHToUCE2NlZmf66urkKjRo0KvU5Ro+9RxCwqQRCEy5cvCy4uLoKurq5Qq1YtYd68ecKPP/4oM7PjwoULwieffCLY2NgImpqagomJieDq6iocPHiw0Gu8PfPi5s2bQs+ePQWpVCpoaGgITZs2LXQhueIu0lbSC8+9OYtKnqJmXmzevFlwcHAQNDU1hTp16ghBQUHCpk2bCs1sefjwodC5c2dBX19fACCeX3kXmHt7JsyxY8cEFRWVQufo5cuXgrW1tdC6dWshMzNT7jGUVlJSkhAYGCi0bt1aMDAwENTU1AQzMzPB09NT+OGHH4S0tDSxbXHn+8yZM0KnTp0EXV1dQVtbW2jXrp3w22+/Ffuav/76qwBAMDY2LvLClqmpqcJXX30lODg4CBoaGoJUKhWcnJyEKVOmCPHx8e88Hj09PSE4OFhmeUku9Pf257O4z01xs98OHDggdOzYUTAwMBA0NTUFGxsboV+/fsLx48flxlyguAvj3bt3T+jcubNgYGAg1KhRQ5g8ebLwxx9/FDmLqqTf95Ke41evXgkjR44UDA0NBR0dHcHT01P466+/yjyLSktLS6hfv77g7+8vzkJ707vO4bNnzwQfHx+hQYMGgq6urqCnpyc0adJEWL58ucysrOK+j8V5cxZVcd6eRfVmzG3bthW0tLQEXV1dwd3dXTh37lyh7Q8ePCg0adJE0NDQEKytrYXFixcXO1N18+bNQtu2bcXvVN26dYXhw4cLV65cEdsUN4uqffv2Qs+ePeUeC5WMRBB4NSEien9MnjwZJ06cwO3bt8t8nx8iRfTgwQPY29vj6NGj8PT0rO5wFB4THCJ6rzx79gz169fHpk2bxBtpEn0IPvvsMzx58kS8kCeVDwcZE9F7xdzcHDt37uQ0Wfqg5OTkoG7duuIEDyo/VnCIiIhI6bCCQ0REREqHCQ4REREpHSY4REREpHR4ob/3SF5eHp4+fQp9fX1OjyUiUkCCICAlJQWWlpYyN/GsaBkZGUVeOb+0NDQ05N7/TZExwXmPPH369J13RiYiovdfbGzsO+9NWFYZGRnQluoCWeW/E7uFhQViYmKUMslhgvMeEe899LE5oMbeQ2V3dzevdfEhMdQsfKdwUj4pySmoZ1tf7r3kyisrKys/ufnYAlArR7U/R0D82XhkZWUxwaHKJXZLqakwwfkA6BtU3g9Aev8YaBpUdwhUhapkmIF6OX9XSMpfAXqfMcEhIiJSRCoo31QhJf87mgkOERGRIpJI8h/l2V6JKXn+RkRERB8iVnCIiIgUlXIXYcqFCQ4REZEiYheVXOyiIiIiIqXDCg4REZEi4iwquZjgEBERKSJ2Ucml5PkbERERfYhYwSEiIlJEEpRvFpVyF3CY4BARESkkFUn+ozzbKzF2UREREZHSYQWHiIhIEbGLSi4mOERERIqIs6jkYoJDRESkiFjBkYtjcIiIiEjpsIJDRESkiDiLSi4mOERERIqIXVRysYuKiIiIlA4rOERERIqIs6jkYoJDRESkiDgGRy52UREREZHSYQWHiIhIEXGQsVxMcIiIiBSRBOUcg1NhkbyX2EVFRERESocVHCIiIkWl5FWY8mCCQ0REpIg4i0ouJjhERESKiIOM5eIYHCIiIlI6rOAQEREpIl7JWC4mOERERIpIBeXrh1HyPhwlPzwiIiL6ELGCQ0REpIjYRSUXKzhERESKSFIBj1L4888/0bNnT1haWkIikeDAgQPFth07diwkEglWrFghszwzMxOTJ0+GqakpdHV10atXLzx58kSmTWJiIoYNGwapVAqpVIphw4bh1atXpQsWTHCIiIioBNLS0tC0aVOsXr1abrsDBw7g0qVLsLS0LLTO398foaGh2LNnD86ePYvU1FT06NEDubm5Yhtvb29ERUXhyJEjOHLkCKKiojBs2LBSx8suKiIiIkVUxV1UXbt2RdeuXeW2+ffffzFp0iQcPXoU3bt3l1mXlJSETZs2Yfv27fDw8AAA7NixA1ZWVjh+/Di8vLwQHR2NI0eO4OLFi2jbti0AYOPGjXB2dsbdu3fh4OBQ4nhZwSEiIlJEKhXwAJCcnCzzyMzMLFM4eXl5GDZsGKZPn45GjRoVWh8ZGYns7Gx07txZXGZpaYnGjRvj/PnzAIALFy5AKpWKyQ0AtGvXDlKpVGxTUkxwiIiIPmBWVlbieBepVIqgoKAy7WfJkiVQU1ODn59fkevj4+OhoaEBIyMjmeXm5uaIj48X25iZmRXa1szMTGxTUuyiIiIiUkQV1EUVGxsLAwMDcbGmpmapdxUZGYnvv/8eV69ehaSUMQmCILNNUdu/3aYkWMEhIiJSRBU0i8rAwEDmUZYE58yZM0hISIC1tTXU1NSgpqaGR48eYdq0abC1tQUAWFhYICsrC4mJiTLbJiQkwNzcXGzz7NmzQvt//vy52KakmOAQEREpooK7iZfnUUGGDRuGGzduICoqSnxYWlpi+vTpOHr0KACgZcuWUFdXR1hYmLhdXFwcbt26BRcXFwCAs7MzkpKScPnyZbHNpUuXkJSUJLYpKXZRERER0Tulpqbi77//Fp/HxMQgKioKxsbGsLa2homJiUx7dXV1WFhYiDOfpFIpfH19MW3aNJiYmMDY2BgBAQFwcnISZ1U5OjqiS5cuGD16NNavXw8AGDNmDHr06FGqGVQAExwiIiLFVMXTxK9cuYKOHTuKz6dOnQoAGDFiBLZu3VqifSxfvhxqamoYMGAA0tPT4e7ujq1bt0JVVVVss3PnTvj5+YmzrXr16vXOa+8URSIIglDqrahSJCcnQyqVAm41ATX2Hiq7p7+WbsojKTYjTdPqDoGqQHJyMsyNayIpKUlm4G5Fv4ZUKgXGOgIaqu/eoDhZucD66EqNtTrxtygREREpHXZRERERKSRJqadOv0ko7c2oFAwTHCIiIgUkkZQvwYFEAmUeo8IuKiIiIlI6rOAQEREpoPJOooIESl3BYYJDRESkgFTK2UUlSCTIq8B43jfsoiIiIiKlwwoOERGRAqqIQcbKjAkOERGRAmKCIx+7qIoxf/58NGvWrLrDUBgfNW6Fn+evwz87zyD9yD30dPaQWb9h2mKkH7kn8whfvq/Qfto6NsPhxSF4cSAKcT9fwdHg7dDSyL+zbfsmbQrto+DRsr5TlRwnFbbq523oOm0k7Ad6wGl4N3wWOBN/P3kk0+bQhdMYPM8fjYZ2hWVvF9z6516h/Xw6eyIse7vIPMZ9O6eqDoPKYMPvu9B6XE+Y9W0Os77N4eo/AEcjwotsO+n7OdDuUh+rQrdWbZBKrCDBKc9DmbGCg/wPSWhoKPr06SMuCwgIwOTJk6svKAWjq6WDmzF/YXvYfuyZU/Q9Q45G/Imxy74Qn2dlZ8usb+vYDL8u3ITv9q7H1LXfICs7G03qNECekD8M7uKda7AdLHs32bnD/dGpuTMi792s4COikrpw6xp8un2KZvaOyMnNxZId6zF4vj/CV++CjpY2AOB1RjpaOzZBj486YfoPi4vd15DOvTDde7T4vCC5pfdTLVMLfDNyGupa2gAAdhwPRf8FE3Bx9QE0tLUX2x08H4aIu9dR08SsukKlDxATnGLo6elBT0+vusNQGMeu/IljV/6U2yYrOwvPEl8Uuz54zJdY8+s2fLdvg7jswdP/rwRk52TLbK+mqobu7Tph3W87yhE5ldeu+ctlni/3mw2n4d1x48FfaNeoOQCgX8euAIDYZ3Fy96WtqQUzIxO5bej90b1dJ5nnC3ymYuPvu3H5rygxwfn3RTymrPkavy3cjE/mjqmOMJVWRUwTV2bV2kXl5uYGPz8/zJgxA8bGxrCwsMD8+fPF9UlJSRgzZgzMzMxgYGCATp064fr16zL7WLhwIczMzKCvr49Ro0bhiy++kOlaioiIgKenJ0xNTSGVSuHq6oqrV6+K621tbQEAn3zyCSQSifj8zS6qo0ePQktLC69evZJ5bT8/P7i6uorPz58/jw4dOkBbWxtWVlbw8/NDWlpauc+TsmjfpA0e7bmAGz8exQ+fL0QNqbG4robUGG0cm+H5q/9watkePNx9HseCd8ClUcti99ejXSeYGhhhx7H9VRE+lVDy6/zPvKFe6W/etz/8GBoN7Qq3SUOwYMsqpL7m90dR5ObmYt/p35GW+RptHfMT27y8PPh+OwNT+o2SqehQxWAXlXzVPgYnJCQEurq6uHTpEoKDg/H1118jLCwMgiCge/fuiI+Px6FDhxAZGYkWLVrA3d0d//33H4D8W6ovWrQIS5YsQWRkJKytrbF27VqZ/aekpGDEiBE4c+YMLl68CHt7e3Tr1g0pKSkA8hMgANiyZQvi4uLE52/y8PCAoaEhfvnlF3FZbm4u9u3bhyFDhgAAbt68CS8vL/Tt2xc3btzA3r17cfbsWUyaNKlSzpuiORbxJz4LDkDXmcPxxcbFaFnfCYeXbIOGujoAwK6mFQBg9tBJ2Hx4H3p/5Yuov2/jUFCIWP5+2wiv/giLPIsnL+Kr7DhIPkEQMH/TSrRp2BQNbOqWatu+rp2xZtoC/LJoNfwH+ODQ+dPwXfxlJUVKFeVWzF2Y9mkGac/G8Fs1D3vn/ABHm3oAgKX7NkBNVRUTew+v5ijpQ1TtXVRNmjTBvHnzAAD29vZYvXo1Tpw4AVVVVdy8eRMJCQnQ1Mzvh//uu+9w4MAB/PzzzxgzZgxWrVoFX19ffPbZZwCAuXPn4tixY0hNTRX336mTbAl1/fr1MDIyQnh4OHr06IEaNWoAAAwNDWFhYVFkjKqqqhg4cCB27doFX19fAMCJEyeQmJiI/v37AwC+/fZbeHt7w9/fXzyWlStXwtXVFWvXroWWllah/WZmZiIzM1N8npycXOrzpyh+/vOQ+P87j+7j6v1buBtyCl3bdMSv545BRZKfa286tBfbw/IrMtcfRMOtuTNGePXD3C1LZfZXy9Qcni0/xtDAz6vuIOidvly/FNGP/saBoHWl3nZI597i/xvY1EUdSyt0mTYSNx7cRZO6DhUZJlWg+rXtcGnNr3iVmowDZ49i9NKZOBa8E+lZGfjh1204vzpU6SsF1YWzqOSr9gpOkyZNZJ7XrFkTCQkJiIyMRGpqKkxMTMTxMHp6eoiJicGDBw8AAHfv3kWbNm1ktn/7eUJCAsaNG4f69etDKpVCKpUiNTUVjx8/LlWcQ4YMwenTp/H06VMA+dWjbt26wcjICAAQGRmJrVu3ysTq5eWFvLw8xMTEFLnPoKAgMSapVAorK6tSxaTI4v97jscJT1Hvf9WZuP+eAwCiH/8t0+7u439gVaNmoe2Hdf4UL1Ne4feLJys/WCqR2RuW4djls/h54WpYmpZ/MKlTXQeoq6kh5mlsBURHlUVDXQN1LW3Qsr4TvhkZACe7BvjhQAjO3bqChFcvUX+YG/S6OUKvmyMeJ/yLLzYuhsPwjtUdtlKQVMA/ZVbtFRz1/3VRFJBIJMjLy0NeXh5q1qyJ06dPF9rG0NBQpv2bBEH2zho+Pj54/vw5VqxYARsbG2hqasLZ2RlZWVmlirNNmzaoW7cu9uzZg/HjxyM0NBRbtmwR1+fl5WHs2LHw8/MrtK21tXWR+5w1axamTp0qPk9OTv5gkhxjfUPUrlFTTGwePXuCpy+eoX5tO5l29WrZFjl4ebjnp9h1/ABycnOqJF4qniAImL1hGY5cDMfPi36Atbllhez37uN/kJ2TA3NjDjpWJAIEZGZnwdu9Nzo1l5312HP2SHi798Zwz0+rKTr6kFR7glOcFi1aID4+HmpqauLA37c5ODjg8uXLGDZsmLjsypUrMm3OnDmDNWvWoFu3bgCA2NhYvHghO5NHXV0dubm574zJ29sbO3fuRO3ataGiooLu3bvLxHv79m3Uq1evpIcITU1NsftN0elq6ciMlbG1qI0mdRyRmPIK/6Uk4auhk3Hg3FHE/fccNua18LXPVLxMSsTB82HiNst//hFfDfPDzX/+wvUH0Rjq+QkcrOrAe5HsdH23Zs6wq2mFrUd/rrLjo+J9uf47hP4Zhi1fLoGetg4SEl8CAPR19KD9v893Ykoy/n0ej2f/5X/3HvybX0E1MzKBmZEJHsY9wf7wY3Bv6QxjA0Pci43Bgi2r0LhOfbRu0KToF6ZqN3fLUnRu3QFWpjWRkp6Gn8L/wJ83LuPgwk0wMTCCiYGRTHt1VXWYG9VAfas61RSxcmEXlXzvbYLj4eEBZ2dn9OnTB0uWLIGDgwOePn2KQ4cOoU+fPmjVqhUmT56M0aNHo1WrVnBxccHevXtx48YN1Knz/1+eevXqYfv27WjVqhWSk5Mxffp0aGtry7yWra0tTpw4gY8++giamppit9PbhgwZggULFmDRokXo16+fzLiamTNnol27dpg4cSJGjx4NXV1dREdHIywsDKtWraqck/QeaVG/MY4F//907eCx+YNDt4fth9+qeWhkVx/eHn1gqKuP+P+eI/zGJQwL9Edq+v/Pkll9IARaGpoIHvsljPSluPnPX+jx5WeIiZPtovDx6ocLtyNxN/ZB1RwcyRVyOBRA/oX63rTcbzYGuuf/EXDs8hlMWblIXDf+u7kAgKmDRiJg8Cioq6nj7I0r2PT7PqSlp8PS1AzurVwwdZAvVFVVq+hIqLQSEl/CN3gG4hMTINXRR2M7BxxcuAnuLT6q7tA+CJwmLt97m+BIJBIcOnQIs2fPxsiRI/H8+XNYWFigQ4cOMDc3B5CfcPzzzz8ICAhARkYGBgwYAB8fH1y+fFncz+bNmzFmzBg0b94c1tbWCAwMREBAgMxrLV26FFOnTsXGjRtRq1YtPHz4sMiY7O3t0bp1a0RERGDFihUy65o0aYLw8HDMnj0b7du3hyAIqFu3LgYOHFih5+V9debGZWh3qV/s+l6zfUu0n+/2bZC5Dk5RfJZMK1VsVLme/nr+nW0GuncXk52i1Kphjv2BayoyLKoC66YGlqr93W2nKikSosIkwtuDVhScp6cnLCwssH379uoOpdSSk5MhlUoBt5qAWrWP/6ZKVpLEgJSHkaZpdYdAVSA5ORnmxjWRlJQEA4PSXwuqpK8hlUohndYSEs2y1ymEzBwkLY2s1Fir03tbwSmJ169fY926dfDy8oKqqip2796N48ePIyws7N0bExERKTCOwZFPoROcgm6shQsXIjMzEw4ODvjll1/g4eHx7o2JiIgUGBMc+RQ6wdHW1sbx48erOwwiIiJ6zyh0gkNERPTBKucsKkG5CzhMcIiIiBRRebuolP0WGpyqQ0REREqHFRwiIiIFxAqOfExwiIiIFJAE5UxwlPxSxuyiIiIiIqXDCg4REZECYheVfExwiIiIFFB5b7ap5PkNu6iIiIhI+bCCQ0REpIDYRSUfExwiIiIFxARHPiY4RERECkhFIoEKB+EUi2NwiIiISOkwwSEiIlJABbOoyvMojT///BM9e/aEpaUlJBIJDhw4IK7Lzs7GzJkz4eTkBF1dXVhaWmL48OF4+vSpzD4yMzMxefJkmJqaQldXF7169cKTJ09k2iQmJmLYsGGQSqWQSqUYNmwYXr16VerzwwSHiIhIARWMwSnPozTS0tLQtGlTrF69utC6169f4+rVq5gzZw6uXr2K/fv34969e+jVq5dMO39/f4SGhmLPnj04e/YsUlNT0aNHD+Tm5optvL29ERUVhSNHjuDIkSOIiorCsGHDSn1+OAaHiIiI3qlr167o2rVrkeukUinCwsJklq1atQpt2rTB48ePYW1tjaSkJGzatAnbt2+Hh4cHAGDHjh2wsrLC8ePH4eXlhejoaBw5cgQXL15E27ZtAQAbN26Es7Mz7t69CwcHhxLHywoOERGRApJUwL/KlJSUBIlEAkNDQwBAZGQksrOz0blzZ7GNpaUlGjdujPPnzwMALly4AKlUKiY3ANCuXTtIpVKxTUmxgkNERKSAKmqaeHJyssxyTU1NaGpqliu2jIwMfPHFF/D29oaBgQEAID4+HhoaGjAyMpJpa25ujvj4eLGNmZlZof2ZmZmJbUqKFRwiIqIPmJWVlTigVyqVIigoqFz7y87OxqBBg5CXl4c1a9a8s70gCDKJWlFJ29ttSoIVHCIiIgVUURWc2NhYscoCoFzVm+zsbAwYMAAxMTE4efKkzH4tLCyQlZWFxMREmSpOQkICXFxcxDbPnj0rtN/nz5/D3Ny8VLGwgkNERKSAKmqauIGBgcyjrAlOQXJz//59HD9+HCYmJjLrW7ZsCXV1dZnByHFxcbh165aY4Dg7OyMpKQmXL18W21y6dAlJSUlim5JiBYeIiIjeKTU1FX///bf4PCYmBlFRUTA2NoalpSX69euHq1ev4vfff0dubq44ZsbY2BgaGhqQSqXw9fXFtGnTYGJiAmNjYwQEBMDJyUmcVeXo6IguXbpg9OjRWL9+PQBgzJgx6NGjR6lmUAFMcIiIiBRSVd+L6sqVK+jYsaP4fOrUqQCAESNGYP78+Th48CAAoFmzZjLbnTp1Cm5ubgCA5cuXQ01NDQMGDEB6ejrc3d2xdetWqKqqiu137twJPz8/cbZVr169irz2zrswwSEiIlJAVZ3guLm5QRCEYtfLW1dAS0sLq1atwqpVq4ptY2xsjB07dpQqtqIwwSEiIlJE5UxweLNNIiIiIgXDCg4REZECKssNM9/eXpkxwSEiIlJAVT0GR9Gwi4qIiIiUDis4RERECii/i6o8FZwKDOY9xASHiIhIAbGLSj52UREREZHSYQWHiIhIAUlQzllUFRbJ+4kJDhERkQJiF5V87KIiIiIipcMKDhERkQJiBUc+JjhEREQKiAmOfExwiIiIFBBv1SAfx+AQERGR0mEFh4iISAGxi0o+JjhERESKiH1UcrGLioiIiJQOKzhEREQKiF1U8jHBISIiUkDsoZKPXVRERESkdFjBISIiUkDsopKPCQ4REZECYoIjH7uoiIiISOmwgkNERKSAWMGRjwkOERGRAuIsKvmY4BARESkgVnDk4xgcIiIiUjqs4LyH7uw6An0D/eoOgypZSnZydYdAVUhf3bC6Q6AqkJOXU3UvVs4KjrL3UTHBISIiUkDsopKPXVRERESkdFjBISIiUkCs4MjHBIeIiEgBcZq4fOyiIiIiIqXDCg4REZECkqCcXVRQ7hIOExwiIiIFxDE48rGLioiIiJQOKzhEREQKiBUc+VjBISIiUkAFs6jK8yiNP//8Ez179oSlpSUkEgkOHDggs14QBMyfPx+WlpbQ1taGm5sbbt++LdMmMzMTkydPhqmpKXR1ddGrVy88efJEpk1iYiKGDRsGqVQKqVSKYcOG4dWrV6U+P0xwiIiIFFBBBac8j9JIS0tD06ZNsXr16iLXBwcHY9myZVi9ejUiIiJgYWEBT09PpKSkiG38/f0RGhqKPXv24OzZs0hNTUWPHj2Qm5srtvH29kZUVBSOHDmCI0eOICoqCsOGDSv1+WEXFREREb1T165d0bVr1yLXCYKAFStWYPbs2ejbty8AICQkBObm5ti1axfGjh2LpKQkbNq0Cdu3b4eHhwcAYMeOHbCyssLx48fh5eWF6OhoHDlyBBcvXkTbtm0BABs3boSzszPu3r0LBweHEsfLCg4REZEikqCcfVT5u0lOTpZ5ZGZmljqUmJgYxMfHo3PnzuIyTU1NuLq64vz58wCAyMhIZGdny7SxtLRE48aNxTYXLlyAVCoVkxsAaNeuHaRSqdimpJjgEBERKaCK6qKysrISx7tIpVIEBQWVOpb4+HgAgLm5ucxyc3NzcV18fDw0NDRgZGQkt42ZmVmh/ZuZmYltSopdVERERB+w2NhYGBgYiM81NTXLvK+3x/UIgvDOsT5vtymqfUn28zZWcIiIiBSQiqT8DwAwMDCQeZQlwbGwsACAQlWWhIQEsapjYWGBrKwsJCYmym3z7NmzQvt//vx5oerQuzDBISIiUkBVPYtKHjs7O1hYWCAsLExclpWVhfDwcLi4uAAAWrZsCXV1dZk2cXFxuHXrltjG2dkZSUlJuHz5stjm0qVLSEpKEtuUFLuoiIiI6J1SU1Px999/i89jYmIQFRUFY2NjWFtbw9/fH4GBgbC3t4e9vT0CAwOho6MDb29vAIBUKoWvry+mTZsGExMTGBsbIyAgAE5OTuKsKkdHR3Tp0gWjR4/G+vXrAQBjxoxBjx49SjWDCmCCQ0REpJBUJBKolKMKU9ptr1y5go4dO4rPp06dCgAYMWIEtm7dihkzZiA9PR0TJkxAYmIi2rZti2PHjkFfX1/cZvny5VBTU8OAAQOQnp4Od3d3bN26FaqqqmKbnTt3ws/PT5xt1atXr2KvvSOPRBAEodRbUaVITk6GVCrFnafXoW+g/+4NSKG9zkmr7hCoClnqWFd3CFQFkpOTUcvUCklJSTIDdyv6NaRSKTrt8IaajkaZ95PzOgsnh+6q1FirEys4RERECkgF5RtIq+yDcJX9+IiIiOgDxAoOERGRApKUcwyOst9NnAkOERGRAirvVG9lT3DYRUVERERKhxUcIiIiBVTV08QVDRMcIiIiBcQuKvnYRUVERERKhxUcIiIiBcTr4MhXogRn5cqVJd6hn59fmYMhIiKikuEYHPlKlOAsX768RDuTSCRMcIiIiKjalSjBiYmJqew4iIiIqBQ4yFi+MnfBZWVl4e7du8jJyanIeIiIiKgECrqoyvNQZqVOcF6/fg1fX1/o6OigUaNGePz4MYD8sTeLFy+u8ACJiIioMEkFPJRZqROcWbNm4fr16zh9+jS0tLTE5R4eHti7d2+FBkdERERUFqWeJn7gwAHs3bsX7dq1k+m/a9iwIR48eFChwREREVHROItKvlInOM+fP4eZmVmh5WlpaUo/YImIiOh9oYJyJjhK3klV6i6q1q1b448//hCfFyQ1GzduhLOzc8VFRkRERFRGpa7gBAUFoUuXLrhz5w5ycnLw/fff4/bt27hw4QLCw8MrI0YiIiJ6C6eJy1fqCo6LiwvOnTuH169fo27dujh27BjMzc1x4cIFtGzZsjJiJCIiordIyjlFXNkTnDLdi8rJyQkhISEVHQsRERFRhShTgpObm4vQ0FBER0dDIpHA0dERvXv3hpoa791JRERUFcp7LRvlrt+UIcG5desWevfujfj4eDg4OAAA7t27hxo1auDgwYNwcnKq8CCJiIhIFqeJy1fqMTijRo1Co0aN8OTJE1y9ehVXr15FbGwsmjRpgjFjxlRGjERERESlUuoKzvXr13HlyhUYGRmJy4yMjLBo0SK0bt26QoMjIiKiorGCI1+pKzgODg549uxZoeUJCQmoV69ehQRFRERE8kkk/z9VvGyP6j6CylWiCk5ycrL4/8DAQPj5+WH+/Plo164dAODixYv4+uuvsWTJksqJkoiIiGSwgiNfiRIcQ0NDmfnygiBgwIAB4jJBEAAAPXv2RG5ubiWESURERFRyJUpwTp06VdlxEBERUSlwmrh8JUpwXF1dKzsOIiIiKgV2UclX5ivzvX79Go8fP0ZWVpbM8iZNmpQ7KCIiIqLyKHWC8/z5c3z22Wc4fPhwkes5BoeIiKjysYIjX6mnifv7+yMxMREXL16EtrY2jhw5gpCQENjb2+PgwYOVESMRERG9pXxTxHmzzUJOnjyJX3/9Fa1bt4aKigpsbGzg6ekJAwMDBAUFoXv37pURJxEREVGJlbqCk5aWBjMzMwCAsbExnj9/DiD/DuNXr16t2OiIiIioSCoV8FBmpa7gODg44O7du7C1tUWzZs2wfv162NraYt26dahZs2ZlxEgKZvXP23H44p948OQRtDQ10dKhMb4cMR51a1mLbZbt3oyDZ0/g6YsEaKipwamuA2YMHY3m9RuJbb5Y8y3OXL+CZ4kvoKuljZYNnPDl8HGoV9umOg6LirHr6O/YffR3/Ps8AQBgb2WNCf2GwLVF/q1bBEHA6n07sPf4YSSnpaJpPQfMHT0R9la24j7mrv8e529EISHxJXS0tNG8viMChvmibi2r6jgkKqFGPh54nPC00PLR3Qdj2cQ5CNyxGj//eRj/Po+Hhro6mtVriLnDP0frBk2rIVolVN5uJiXvopIIBVfpK6GdO3ciOzsbPj4+uHbtGry8vPDy5UtoaGhg69atGDhwYGXFqnBsbW3h7+8Pf3//ErVPTk6GVCrFnafXoW+gX7nBVaKhC6ah18fuaGrviNzcXATv3IC/Hv2Dk6u2Q0dLGwAQGh4GU0MjWJtbIiMrEz8e3Is/zp/GmbW7YSLNv8/ZzqMHUbe2NWqZmuNVajKW7dmCOzH3cX79PqiqqlbnIVaI1zlp1R1ChTh55SJUVVRgbWEJADhw+jg2HfwZod+uhr2VLTaE7sO6/XuweOJU2FrWxtqfdyMi+iaOrPwReto6AIC9YYdQp5YVaprWQFJqClbt24G/Hv6DEz9sVYr3GgAsdazf3UjBPE/6D3lvTCy58+g+es0ehUOLt6J9kzbYd+p31DA0hq2FFTKyMrA6dBsOnD2KqE1HUENqXI2RV57k5GTUMrVCUlISDAwMKu01pFIpxh6aBE1dzTLvJzMtE+u7ra7UWKtTqStUQ4YMgY+PDwCgefPmePjwISIiIhAbG6vwyY2bm1uJkxEq3o55SzHAvRscrO3Q0K4elk6ehX+fP8ONB3fFNp+4eqJ901awsbCEg7Ud5o6cjJTXaYh++EBsM8SrF9o1agYr85r5FZ4ho/D0RQJiE+Kr47CoGJ1atYNrizaws6wNO8vamOLtAx0tLUTd+wuCIGDbH6EY13cQOrf7GPWtbbFk8jRkZGbi9zP/fwHRgZ7d0LqhE2qbWaBRHXv4DxqBuBfP8e/zwve9o/dHDakxzI1riI8jl8NRp6YVPnbKr94N6NgDHZu7wK6mFRxt7BE0ZiaSX6fidszdd+yZSqJgFlV5HqWRk5ODr776CnZ2dtDW1kadOnXw9ddfIy8vT2wjCALmz58PS0tLaGtrw83NDbdv35bZT2ZmJiZPngxTU1Po6uqiV69eePLkSYWckzeVuwtOR0cHLVq0gKmpaUXE894TBAE5OTnVHYZCSX6dX6kw1Cv6L4Ss7GzsPHYQBjp6aGhX9A1bX2ekY++JQ7A2rwlLU7NKi5XKJzc3F3+cPY3XGZloXt8RTxLi8fxVIj5u2kJso6GugdYNnXDtbnSR+3idkYH9p8JQ28wCFiY1qip0Kqes7CzsOfUbhnbuW2S3SVZ2FrYc3geprj4a2zWohgiVT1UnOEuWLMG6deuwevVqREdHIzg4GN9++y1WrVoltgkODsayZcuwevVqREREwMLCAp6enkhJSRHb+Pv7IzQ0FHv27MHZs2eRmpqKHj16VPhlZko0Bmfq1Kkl3uGyZcvKHIw8bm5uaNKkCbS0tPDjjz9CQ0MD48aNw/z58wEASUlJmD59Og4cOICMjAy0atUKy5cvR9Om+X29Pj4+ePXqFQ4cOCDu09/fH1FRUTh9+jR8fHwQHh6O8PBwfP/99wCAmJgYPHz4EB07dsSRI0cwe/Zs3LhxA0ePHoW1tTWmTp2KixcvIi0tDY6OjggKCoKHh0elHL+iEgQBX29ejdaOTdDApo7MuuMR5zBx6QKkZ2bAzMgEOxcsg7GBoUybkEOhCNy2Fq8z0lGvtg12zl8ODXX1KjwCKom7j2IwaPYUZGZlQUdLGz/MmIN6Vja4+tcdAICJoZFMe1NDIzx9qzqz88hv+G7HJrzOyECdWlbYMjeQ77UC+f3CCSSlpmCoxycyyw9fOo3PlkzD68wMWBjXwK+LfoSp1KiYvVBplHeqd2m3vXDhAnr37i3Olra1tcXu3btx5coVAPk/71esWIHZs2ejb9++AICQkBCYm5tj165dGDt2LJKSkrBp0yZs375d/H25Y8cOWFlZ4fjx4/Dy8irz8bytRBWca9eulegRFRVVYYEVJSQkBLq6urh06RKCg4Px9ddfIywsDIIgoHv37oiPj8ehQ4cQGRmJFi1awN3dHf/991+J9v3999/D2dkZo0ePRlxcHOLi4mBl9f8DHGfMmIGgoCBER0ejSZMmSE1NRbdu3XD8+HFxLFLPnj3x+PHjEh9PZmYmkpOTZR7K5qsNy/HXwwf4Ydq8QutcnFrgyPLNOLB4Ldyat8WEb+fhxatEmTafuHriyLJN+GnRKtjWrI0J385FRlZmVYVPJWRnWRsHvl2DvYErMNirO2auXoq/Yx+J69/+OSoIQqGFvdp3Qui3P2DH19/CpqYl/JcFIvOtK6XT+2vbsf3wbNUeNU1kK6wdmrbBudX7cXzpLni0/Bgjgqbi+auX1RQlFeXt30OZmUX/jP34449x4sQJ3Lt3DwBw/fp1nD17Ft26dQOQXxSIj49H586dxW00NTXh6uqK8+fPAwAiIyORnZ0t08bS0hKNGzcW21QUhbrZZpMmTTBvXv4vSnt7e6xevRonTpyAqqoqbt68iYSEBGhq5g+4+u6773DgwAH8/PPPGDNmzDv3LZVKoaGhAR0dHVhYWBRa//XXX8PT01N8bmJiIlaHAGDhwoUIDQ3FwYMHMWnSpBIdT1BQEBYsWFCitopozoblCLt8Dj8HrkLNIrqVdLS0YVezNuxq1kYLh0ZoP34w9hz/HZP6DRPbGOjqwUBXD3aWVmhRvxEaD+2GIxfPoE8HVsreJxrq6rCpmT/I2Klefdz8+x62HTqA0X0GAABeJCbCzMhEbP8y6VWhv+L1dXWhr6sL25q10NS+Adr49EPY5XPo8XHHqjsQKpPHz/7FqagL2Dn7+0LrdLV0UNfSBnUtbdCmQVM0G9UFIUd/QcDAd/9cJvlUIIFKOW6ZWbDtm3/MA8C8efPE3pE3zZw5E0lJSWjQoAFUVVWRm5uLRYsWYfDgwQCA+Pj88ZHm5uYy25mbm+PRo0diGw0NDRgZGRVqU7B9RSnzvaiqw9v3uapZsyYSEhIQGRmJ1NRUmJiYyKxPT0/HgwcPUBFatWol8zwtLQ0LFizA77//jqdPnyInJwfp6emlquDMmjVLpvsvOTm50AdNEQmCgDkbV+DIxT/x08KVsDa3LPF2WdnZJWjDv+rfd4KQP7aqtpkFahga4dyNa2hYJ398VVZ2NiLu3ETA0JEl2ge9/3aEhaKG1Bhd2rz7xsz8Dleciuqiio2NlZlFVVAoeNvevXuxY8cO7Nq1C40aNUJUVBT8/f1haWmJESNGFNpvAUEQ3hlnSdqUlkIlOOpv9cdLJBLk5eUhLy8PNWvWxOnTpwttY2hoCABQUVHB2zPis0vxw1NXV1fm+fTp03H06FF89913qFevHrS1tdGvX79CNx+VR1NTs9gPkiKbvX4Zfv3zOH78MhC62jpISMwvR+vr6EFbUxOvM9Kx8qdt6NzmY5gZmSAxJQnbDoci/uVzdP8o/6/1R/FP8dvZE+jQrA1MpIaIf/kca/bvhJamJjq1dK7Ow6O3LNu5BR2at4aFqSnS0tNx6Fw4Lt+5gR9nL4REIsHw7p9g/f49sK1pCZuatbB+/x5oaWqiR/v89zr2WRwOnQvHR01bwthAimf/vcDGAz9BS0MDri3aVPPR0bvk5eVhR1govD36QE31/3+lpGW8xrd71qNbu06wMDLFfylJ2Pj7bvz74hk+aV9x4yyo/AwMDEo0TXz69On44osvMGjQIAD5F/h99OgRgoKCMGLECLH3Iz4+Xua6eAkJCWJVx8LCAllZWUhMTJSp4iQkJMDFxaUiD0uxEpzitGjRAvHx8VBTU4OtrW2RbWrUqIFbt27JLIuKipJJmjQ0NEo8ivvMmTPw8fHBJ5/kD6hLTU3Fw4cPyxS/stl+5AAAYMBXfjLLl06ehQHu3aCiooIH/z7GmCVfITE5CYb6Bmhq74ifA1fDwdoOAKCpoYHLd25g028/ISktBaZSY7Rt1BQHFq+FqSEHKL5PXiQlYsaqYCQkJkJfRwcONnb4cfZCfPS/mVOj+/RHZlYmFmxcjaS0VDS1b4DNcwLFa+BoqGvgSvRthPxxAMlpqTCRGqKVoxN2L1oGE6lhNR4ZlcSpqAuIfR6HYZ59ZZarqqji3pMY7Fr0OV4mJcLYwBAt6jfG0W+3w9HGvpqiVS5VfbPN169fQ0VFduiuqqqqOE3czs4OFhYWCAsLQ/PmzQEAWVlZCA8Px5IlSwAALVu2hLq6OsLCwjBgQH4XdlxcHG7duoXg4OAyH0tRlCLB8fDwgLOzM/r06YMlS5bAwcEBT58+xaFDh9CnTx+0atUKnTp1wrfffott27bB2dkZO3bswK1bt8Q3AcgfEX7p0iU8fPgQenp6MDYu/kJU9erVw/79+9GzZ09IJBLMmTNH5loAH7LYA2fkrtfS0MTGLxbJbWNhbIptc7+tyLCokgROkD/LUiKRYPLAYZg8cFiR682NTbBx9jeVERpVAfcWHyHl0J1Cy7U0NLHrq5XVENGHQ/K/f+XZvjR69uyJRYsWwdraGo0aNcK1a9ewbNkyjByZ390skUjg7++PwMBA2Nvbw97eHoGBgdDR0YG3tzeA/PGuvr6+mDZtGkxMTGBsbIyAgAA4OTlV+CxkpUhwJBIJDh06hNmzZ2PkyJF4/vw5LCws0KFDB7Es5uXlhTlz5mDGjBnIyMjAyJEjMXz4cNy8eVPcT0BAAEaMGIGGDRsiPT0dMTExxb7m8uXLMXLkSLi4uMDU1BQzZ85UyllQREREALBq1SrMmTMHEyZMQEJCAiwtLTF27FjMnTtXbDNjxgykp6djwoQJSExMRNu2bXHs2DHo6///1fmXL18ONTU1DBgwAOnp6XB3d8fWrRV/1fJS36oBALZv345169YhJiYGFy5cgI2NDVasWAE7Ozv07t27QgP8kCjLrRqoZJTlVg1UMsp4qwYqrCpv1TDteEC5b9Ww1OM73qqhwNq1azF16lR069YNr169EsesGBoaYsWKFRUdHxERERWhqq9krGhKneCsWrUKGzduxOzZs2XKSa1atZLp7iEiIiKqLqUegxMTEyMzMLeApqYm0tJYciciIqoKkv9d6q882yuzUh+dnZ1dkbdkOHz4MBo2bFgRMREREdE7qKCcXVTlmIGlCEpdwZk+fTomTpyIjIwMCIKAy5cvY/fu3QgKCsKPP/5YGTESERHR2ySlv2Hm29srs1InOJ999hlycnIwY8YMvH79Gt7e3qhVqxa+//578eqGRERERNWpTNfBGT16NEaPHo0XL14gLy8PZmaFb6RIRERElaeqL/SnaMp1oT9TU9OKioOIiIhKoapv1aBoSp3g2NnZye3z++eff8oVEBEREVF5lTrB8ff3l3menZ2Na9eu4ciRI5g+fXpFxUVERERySCSScg0yLtcAZQVQ6gTn888/L3L5Dz/8gCtXrpQ7ICIiIno3lf/9K8/2yqzCjq5r16745ZdfKmp3RERERGVWYXcT//nnn2FsbFxRuyMiIiI52EUlX6kTnObNm8ucFEEQEB8fj+fPn2PNmjUVGhwREREVjQmOfKVOcPr06SPzXEVFBTVq1ICbmxsaNGhQUXERERERlVmpEpycnBzY2trCy8sLFhYWlRUTERERvYMKync/KWW/F1WpBhmrqalh/PjxyMzMrKx4iIiIqAQKuqjK81BmpZ5F1bZtW1y7dq0yYiEiIqISKtedxMt5FWRFUOoxOBMmTMC0adPw5MkTtGzZErq6ujLrmzRpUmHBEREREZVFiROckSNHYsWKFRg4cCAAwM/PT1wnkUggCAIkEglyc3MrPkoiIiKSwZttylfiBCckJASLFy9GTExMZcZDREREJaAiUYGKpBxXMi7HtoqgxAmOIAgAABsbm0oLhoiIiKgilGoMjrKPuCYiIlIUvNCffKVKcOrXr//OE/Lff/+VKyAiIiIqifKNwQHH4Py/BQsWQCqVVlYsRERERBWiVAnOoEGDYGZmVlmxEBERUQmV91o2vA7O/yh7Xx0REZEi4TRx+Uo8R6xgFhURERHR+67EFZy8vLzKjIOIiIhKQUVSvm4mFeUu4JT+Vg1ERERU/SQSFUjKcbG+8myrCJjgEBERKSCOwZFPudM3IiIi+iCxgkNERKSAOE1cPiY4RERECoi3apCPXVRERESkdFjBISIiUkAqkEClHAOFy7OtImCCQ0REpIDYRSUfu6iIiIioRP79918MHToUJiYm0NHRQbNmzRAZGSmuFwQB8+fPh6WlJbS1teHm5obbt2/L7CMzMxOTJ0+GqakpdHV10atXLzx58qTCY2WCQ0REpIAKLvRXnkdpJCYm4qOPPoK6ujoOHz6MO3fuYOnSpTA0NBTbBAcHY9myZVi9ejUiIiJgYWEBT09PpKSkiG38/f0RGhqKPXv24OzZs0hNTUWPHj2Qm5tbUacGALuoiIiIFFJVj8FZsmQJrKyssGXLFnGZra2t+H9BELBixQrMnj0bffv2BQCEhITA3Nwcu3btwtixY5GUlIRNmzZh+/bt8PDwAADs2LEDVlZWOH78OLy8vMp8PG9jBYeIiOgDlpycLPPIzMwsst3BgwfRqlUr9O/fH2ZmZmjevDk2btworo+JiUF8fDw6d+4sLtPU1ISrqyvOnz8PAIiMjER2drZMG0tLSzRu3FhsU1GY4BARESmggkHG5XkAgJWVFaRSqfgICgoq8vX++ecfrF27Fvb29jh69CjGjRsHPz8/bNu2DQAQHx8PADA3N5fZztzcXFwXHx8PDQ0NGBkZFdumorCLioiISCGV715U+N+2sbGxMDAwEJdqamoW2TovLw+tWrVCYGAgAKB58+a4ffs21q5di+HDh///Xt+anSUIwjtnbJWkTWmxgkNERKSAJChnBed/CY6BgYHMo7gEp2bNmmjYsKHMMkdHRzx+/BgAYGFhAQCFKjEJCQliVcfCwgJZWVlITEwstk1FYYJDRERE7/TRRx/h7t27Msvu3bsHGxsbAICdnR0sLCwQFhYmrs/KykJ4eDhcXFwAAC1btoS6urpMm7i4ONy6dUtsU1HYRUVERKSAqnoW1ZQpU+Di4oLAwEAMGDAAly9fxoYNG7BhwwYA+V1T/v7+CAwMhL29Pezt7REYGAgdHR14e3sDAKRSKXx9fTFt2jSYmJjA2NgYAQEBcHJyEmdVVRQmOERERAqoLNeyeXv70mjdujVCQ0Mxa9YsfP3117Czs8OKFSswZMgQsc2MGTOQnp6OCRMmIDExEW3btsWxY8egr68vtlm+fDnU1NQwYMAApKenw93dHVu3boWqqmqZj6UoEkEQhArdI5VZcnIypFIp7jy9Dn0D/XdvQArtdU5adYdAVchSx7q6Q6AqkJycjFqmVkhKSpIZuFvRryGVSrH52nro6GuXeT+vU9IxsvnYSo21OrGCQ0REpIAk5ZxFVb4ZWO8/JjhEREQKSCIp3w0zlfxem5xFRURERMqHFRwiIiIFxC4q+ZjgEBERKaA3b7dQ1u2VGbuoiIiISOmwgvMe0lHTh64ap4krOyMNk+oOgarQ84yKvZEgvZ9SMlKr7LWq+kJ/ioYJDhERkQJiF5V8THCIiIgUkOR/NZzybK/MlPvoiIiI6IPECg4REZECYheVfExwiIiIFBCvgyMfu6iIiIhI6bCCQ0REpIBUJBKolKObqTzbKgImOERERAqIXVTysYuKiIiIlA4rOERERAqIs6jkY4JDRESkkMp3oT9l78RR7qMjIiKiDxIrOERERAqIXVTyMcEhIiJSQLybuHxMcIiIiBQQKzjycQwOERERKR1WcIiIiBQQL/QnHxMcIiIiBcQuKvnYRUVERERKhxUcIiIiBZTfQVX2OgW7qIiIiOi9w7uJy8cuKiIiIlI6rOAQEREpIM6iko8JDhERkQLiLCr52EVFRERESocVHCIiIgXELir5mOAQEREpIHZRyccEh4iISAGp/O9febZXZsp9dERERPRBYgWHiIhIAbGLSj5WcIiIiBSQpAL+lVVQUBAkEgn8/f3FZYIgYP78+bC0tIS2tjbc3Nxw+/Ztme0yMzMxefJkmJqaQldXF7169cKTJ0/KHIc8THCIiIioxCIiIrBhwwY0adJEZnlwcDCWLVuG1atXIyIiAhYWFvD09ERKSorYxt/fH6GhodizZw/Onj2L1NRU9OjRA7m5uRUeJxMcIiIiRfS/LqqyPlCGLqrU1FQMGTIEGzduhJGRkbhcEASsWLECs2fPRt++fdG4cWOEhITg9evX2LVrFwAgKSkJmzZtwtKlS+Hh4YHmzZtjx44duHnzJo4fP15hp6UAExwiIiIFVFFdVMnJyTKPzMzMYl9z4sSJ6N69Ozw8PGSWx8TEID4+Hp07dxaXaWpqwtXVFefPnwcAREZGIjs7W6aNpaUlGjduLLapSExwiIiIPmBWVlaQSqXiIygoqMh2e/bswdWrV4tcHx8fDwAwNzeXWW5ubi6ui4+Ph4aGhkzl5+02FYmzqIiIiBRQRV3JODY2FgYGBuJyTU3NQm1jY2Px+eef49ixY9DS0ip+n291ewmC8M7ZWiVpUxas4BARESmignE05XkAMDAwkHkUleBERkYiISEBLVu2hJqaGtTU1BAeHo6VK1dCTU1NrNy8XYlJSEgQ11lYWCArKwuJiYnFtqlITHCIiIhILnd3d9y8eRNRUVHio1WrVhgyZAiioqJQp04dWFhYICwsTNwmKysL4eHhcHFxAQC0bNkS6urqMm3i4uJw69YtsU1FYhcVERGRAqrKm23q6+ujcePGMst0dXVhYmIiLvf390dgYCDs7e1hb2+PwMBA6OjowNvbGwAglUrh6+uLadOmwcTEBMbGxggICICTk1OhQcsVgQkOERGRAnrfrmQ8Y8YMpKenY8KECUhMTETbtm1x7Ngx6Ovri22WL18ONTU1DBgwAOnp6XB3d8fWrVuhqqpaobEAgEQQBKHC90plkpycDKlUiocJ/8DAQP/dG5BC01DRqO4QqAo9z6j4WSL0/klJTkWT2i2RlJQkM3C3IhX8rvgz5gT09HXLvJ/UlDR0sHOv1FirE8fgEBERkdJhFxUREZECkqB042iK2l6ZMcEhIiJSQBKUcwyOkqc47KIiIiIipcMKDhERkQKqymniiogJDhERkQJigiMfu6iIiIhI6bCCQ0REpIDetwv9vW+Y4BARESkgdlHJxy4qIiIiUjqs4BARESkgdlHJxwSHiIhIAbGLSj4mOERERAqICY58HINDRERESocVHKoU529FYtUvIbj+IBrx/z3H9tnL0N25EwAgOycbi7b/gLArZ/Eo/gkMdPXh2rQt5vr4oaaJmcx+Lkdfx6LtqxF59ybU1NTgZOeAfQt+gLamVnUcFpXQ0xfPMGfLUoRdOYP0rEzUq2WDNZ8vRHP7RoXaTl41D1sO/4QlY77AxD7DqyFaKqk1v+zC0Ytn8ODfx9DS0ESLBo0wc9ho1K1lLdPu7yePsHjbBly+cwN5eXmwt7LF6oC5qFXDXGxz9e5tfLdzE6Lu/wU1VVU0tKuHrV8thpamZlUflsLiGBz5PrgE5/Tp0+jYsSMSExNhaGhYbDtbW1v4+/vD39+/ymJTJmkZ6Whcpz68PXtjROA0mXXpmRm4/iAaAYNGo7GdA16lJuPLjd9iyDf+OLlil9jucvR19J83EVP6j8TisTOhoaaOWzH3oKLCwuP7LDElCR4BQ9ChSRvs/3o9ahia4J+4x5Dq6Rdq+9v547hy90ahxJbeT5duX8ewrr3RpJ4DcnLzsHTXJgxfMANhK7dAR0sbAPAo/l/0//JzDPDoiimDfKCvo4u/nzyGprqGuJ+rd2/D55svML7vYMwfNRnqauqIfvgAEhXl/oVb0dhFJd8Hl+C4uLggLi4OUqkUALB161b4+/vj1atXMu0iIiKgq6tbDREqB89WH8Oz1cdFrjPQ1UfowvUyy5aMnQmPqUPxJCEOtc1qAgBm//gdxvQcDP/+I8V2dWvZVF7QVCGW/7wJtWpYYN3UQHGZjXmtQu2evniGaWsX4cDCDeg3b3xVhkhlFDJ3iczz4Ekz0Oqzvrj54B7aNmoKAPhu52a4tWyDWcPHiu2sLSxltvtm8xqM6PYJxvf1FpfZWdauxMjpQ/TB/SmsoaEBCwuLd5bmatSoAR0dnSqKipJfp0IikcDgf3/lP3/1HyLv3kQNQ2N4BQyHw9BO6PGFLy7evlbNkdK7/HHxJFrYN8bQQH/YDv4YLpP6YsuRn2Ta5OXlYdR3X+DzT0eioY19NUVK5ZXyOg0AYKhnACD/fT0VeRF2Na0w/OsZaOXTF31mTsCxS2fFbV68SkTU/WiYSA3x6axJaPXZpxj4lT8iom9WyzEoMkkF/FNm72WC4+bmhkmTJmHSpEkwNDSEiYkJvvrqKwiCAABITEzE8OHDYWRkBB0dHXTt2hX3798Xt3/06BF69uwJIyMj6OrqolGjRjh06BCA/C4qiUSCV69e4fTp0/jss8+QlJQk9mXOnz8fQH4X1YoVKwAAgwcPxqBBg2RizM7OhqmpKbZs2QIAEAQBwcHBqFOnDrS1tdG0aVP8/PPPlXymlENGVia+3roS/Vy7wkBHDwDwMP4JAGDJrnUY7tUXPy1YgyZ1G6DP7DF48O+j6gyX3uFh/BP8+Mce1LO0wa8LN8C320BMXxeIXSd+Fdss++lHqKmqYkLvodUYKZWHIAhYuGUNWjk6wcHGDgDwMukV0jLSsS50N1ybt8a2ecHwavsxxgXPw8Xb1wEAsc/iAADf792GQR7dETJnMRrXscfQeQGIefqk2o5HIf3v91ZZH+AYnOoREhICX19fXLp0CVeuXMGYMWNgY2OD0aNHw8fHB/fv38fBgwdhYGCAmTNnolu3brhz5w7U1dUxceJEZGVl4c8//4Suri7u3LkDPT29Qq/h4uKCFStWYO7cubh79y4AFNluyJAhGDBgAFJTU8X1R48eRVpaGj799FMAwFdffYX9+/dj7dq1sLe3x59//omhQ4eiRo0acHV1LfIYMzMzkZmZKT5PTk4u93lTNNk52RgVPBN5Qh6+nfCluDxPyAMA+HT5FEM8+wAAmtRtgD+vX8bOsF8x18evOsKlEsgT8tDCvjHm+0wBADSt2xDRj//Gj3/sgbd7b1y7fxtrDm7HuZW/KP0gR2U2d+NK/PXoH/y0aKW4rOB769nGBb49+wMAGtrVQ+Rft7Hr6EG0a9RUbOPduQf6u3cFADSqY49zN6/hp5OHMWPo6Co+ElJW722CY2VlheXLl0MikcDBwQE3b97E8uXL4ebmhoMHD+LcuXNwcXEBAOzcuRNWVlY4cOAA+vfvj8ePH+PTTz+Fk5MTAKBOnTpFvoaGhgakUikkEgksLCyKjcXLywu6uroIDQ3FsGHDAAC7du1Cz549YWBggLS0NCxbtgwnT56Es7Oz+Jpnz57F+vXri01wgoKCsGDBgjKfI0WXnZONkYtn4FH8U/wauEGs3gCAhVENAICDdV2Zbepb2eHJ87gqjZNKx8KoBhpYyb5vDlZ18eu5MADA+duReP7qPzQY4S6uz83Lxawfg/HDgW24s/V4lcZLpTdv40qciDiPvQtXoKZpDXG5kb4UaqqqqFdbdqxcvdo2uPK/LigzI5P8ZVZvtalljafPEyo5cmUj+d+jPNsrr/c2wWnXrp3MX3fOzs5YunQp7ty5AzU1NbRt21ZcZ2JiAgcHB0RHRwMA/Pz8MH78eBw7dgweHh749NNP0aRJkzLHoq6ujv79+2Pnzp0YNmwY0tLS8Ouvv2LXrvwZP3fu3EFGRgY8PT1ltsvKykLz5s2L3e+sWbMwdepU8XlycjKsrKzKHKciKUhuHjx9jINBG2FsYCiz3trcEjWNa+D+k4cyyx/8+wgeLT+qukCp1No1bIF7/8bILPv734ewNssfaDqoUy+4NXOWWd9nzmgM7tQLQz0/qbI4qfQEQcC8H1fi2KWz2P31cliZ15RZr6Gujib1HPDP01iZ5TFPY1HLLH+KeG0zC5gbm+Cff99qE/cEbs3bVO4BKBlOE5fvvU1wSksQBPHNGjVqFLy8vPDHH3/g2LFjCAoKwtKlSzF58uQy73/IkCFwdXVFQkICwsLCoKWlha5d88ureXn5Jdc//vgDtWrJzhbRlHNNB01NTbnrFVlq+mvExD0Wnz969i9u/vMXjPSksDCpAZ+g6bj+IBp75q5Ebl4eniW+AAAY6Umhoa4OiUSCSZ+OwOKd69DYrj6c6jhg94nfcP/JQ2yd9V11HRaVwKRPhsN92hB8u3c9+rbvgsi7N7Hl8E9Y5TcfAGBiYAiTtxJadVU1mBuZon5tu6oPmEps7obv8euZE9gwayH0tHXwPPE/AIC+jq54/ZoxvQdi8rJv0KZhEzg3bo7wa5dx4soF7P5mOYD8X6pjeg/Eir0hcLSti4Z29fDLqaN48O9jrJk+r9qOjZTPe5vgXLx4sdBze3t7NGzYEDk5Obh06ZLYRfXy5Uvcu3cPjo6OYnsrKyuMGzcO48aNw6xZs7Bx48YiExwNDQ3k5ua+Mx4XFxdYWVlh7969OHz4MPr37w8NjfzrOjRs2BCampp4/Phxsd1RH5qo+7fR68v/70v/6selAIDB7j0x03scDl86DQDo4DdQZruDgRvxcZPWAIDxvYciMysLs3/8Dq9SktDIrj72f7MOdjU/jCqXompZ3wm7v1qJeVuXY/GutbCxqI0lY7/AwI49qzs0KqcdRw8CAAbPmSKz/NtJM9CvUxcAgFe79lg4dgrW7t+FBZtWo46lFdbMWIDWjk5i+5E9+yEzOwsLt6zBq9QUONrWwfZ538LGovDlBKh4vA6OfO9tghMbG4upU6di7NixuHr1KlatWoWlS5fC3t4evXv3xujRo7F+/Xro6+vjiy++QK1atdC7d28AgL+/P7p27Yr69esjMTERJ0+elEl+3mRra4vU1FScOHECTZs2hY6OTpHTwyUSCby9vbFu3Trcu3cPp06dEtfp6+sjICAAU6ZMQV5eHj7++GMkJyfj/Pnz0NPTw4gRIyrnJL3HPm7SGv/9HlXsennr3uTff6TMdXBIMXRt64aubd1K3J7jbhRDzP6TJWo3wL0rBvxvAHFxxvf1lrkODpUeExz53stp4gAwfPhwpKeno02bNpg4cSImT56MMWPGAAC2bNmCli1bokePHnB2doYgCDh06BDU1dUBALm5uZg4cSIcHR3RpUsXODg4YM2aNUW+jouLC8aNG4eBAweiRo0aCA4OLjamIUOG4M6dO6hVqxY++kh2HMg333yDuXPnIigoCI6OjvDy8sJvv/0GOzuW3ImIqOKVZ4p4ecfvKAKJUHBxmfeIm5sbmjVrJl6H5kORnJwMqVSKhwn/wMCg8GXtSbloqGi8uxEpjecZ8dUdAlWBlORUNKndEklJSTAwMKiU1yj4XXHj36vQNyh8aZOSSklORZNaLSo11ur03nZRERERUfHyJ4mXp4tKuTHBISIiUkAcgyPfe5ngnD59urpDICIiIgX2XiY4REREJB8v9CcfExwiIiIFxC4q+d7baeJEREREZcUKDhERkQJiF5V8THCIiIgUELuo5GMXFRERESkdVnCIiIgUkgTlu1wfKzhERET0npFUwKM0goKC0Lp1a+jr68PMzAx9+vTB3bt3ZdoIgoD58+fD0tIS2tracHNzw+3bt2XaZGZmYvLkyTA1NYWuri569eqFJ0+elDKad2OCQ0REpICq+mab4eHhmDhxIi5evIiwsDDk5OSgc+fOSEtLE9sEBwdj2bJlWL16NSIiImBhYQFPT0+kpKSIbfz9/REaGoo9e/bg7NmzSE1NRY8ePZCbm1th5wZ4T2+2+aHizTY/LLzZ5oeFN9v8MFTlzTbvxd+Gfjl+V6Qkp6C+RaMyx/r8+XOYmZkhPDwcHTp0gCAIsLS0hL+/P2bOnAkgv1pjbm6OJUuWYOzYsUhKSkKNGjWwfft2DBw4EADw9OlTWFlZ4dChQ/Dy8irz8byNFRwiIiKFVNWdVLKSkpIAAMbGxgCAmJgYxMfHo3PnzmIbTU1NuLq64vz58wCAyMhIZGdny7SxtLRE48aNxTYVhYOMiYiIFFBFDTFOTk6WWa6pqQlNTU252wqCgKlTp+Ljjz9G48aNAQDx8flVSnNzc5m25ubmePTokdhGQ0MDRkZGhdoUbF9RWMEhIiL6gFlZWUEqlYqPoKCgd24zadIk3LhxA7t37y607u2xPYIgvHO8T0nalBYrOERERAqpYmo4sbGxMmNw3lW9mTx5Mg4ePIg///wTtWvXFpdbWFgAyK/S1KxZU1yekJAgVnUsLCyQlZWFxMREmSpOQkICXFxcynEshbGCQ0REpIAqahaVgYGBzKO4BEcQBEyaNAn79+/HyZMnYWdnJ7Pezs4OFhYWCAsLE5dlZWUhPDxcTF5atmwJdXV1mTZxcXG4detWhSc4rOAQERHRO02cOBG7du3Cr7/+Cn19fXHMjFQqhba2NiQSCfz9/REYGAh7e3vY29sjMDAQOjo68Pb2Ftv6+vpi2rRpMDExgbGxMQICAuDk5AQPD48KjZcJDhEREb3T2rVrAQBubm4yy7ds2QIfHx8AwIwZM5Ceno4JEyYgMTERbdu2xbFjx6Cv///T2ZcvXw41NTUMGDAA6enpcHd3x9atW6Gqqlqh8fI6OO8RXgfnw8Lr4HxYeB2cD0NVXgfnwbO75b4OTl1zh0qNtTpxDA4REREpHXZRERERKSDJ//6VZ3tlxgoOERERKR1WcIiIiBRQWW6Y+fb2yowVHCIiIlI6THCIiIhI6bCLioiISCGVb5Bxee8m/r5jBYeIiIiUDis4RERECqlibraprJjgEBERKSCmN/Kxi4qIiIiUDis4RERECojXwZGPCQ4REZFCYieVPOyiIiIiIqXDCg4REZECYv1GPiY4RERECkvZ05SyY4JDRESkgDjIWD6OwSEiIiKlwwSHiIiIlA67qIiIiBSQpJw32yzfjTrff6zgEBERkdJhBYeIiEghcaK4PExwiIiIFBDTG/nYRUVERERKhxUcIiIiBcTr4MjHBIeIiEghsZNKHnZRERERkdJhBYeIiEgBsX4jHxMcIiIihcQURx4mOERERAqIg4zl4xgcIiIiUjpMcIiIiEjpsIuKiIhIAfFmm/IxwXmPCIIAAEhJSanmSKgqaKioV3cIVIVSMlKrOwSqAqkp+e9zwc/zypScXL7fFeXd/n3HBOc9UpDYONVtWs2REBFReaSkpEAqlVbKvjU0NGBhYQF72/rl3peFhQU0NDQqIKr3j0SoijSTSiQvLw9Pnz6Fvr6+0o9uf1NycjKsrKwQGxsLAwOD6g6HKhHf6w/Hh/peC4KAlJQUWFpaQkWl8oa5ZmRkICsrq9z70dDQgJaWVgVE9P5hBec9oqKigtq1a1d3GNXGwMDgg/pB+CHje/3h+BDf68qq3LxJS0tLaROTisJZVERERKR0mOAQERGR0mGCQ9VOU1MT8+bNg6amZnWHQpWM7/WHg+81VTcOMiYiIiKlwwoOERERKR0mOERERKR0mOAQERGR0mGCQwpl/vz5aNasWXWHQe8ZW1tbrFixorrDIACnT5+GRCLBq1ev5Lbje0aVjQkOvbckEgkOHDggsywgIAAnTpyonoCowri5ucHf37+6w6BK4OLigri4OPFid1u3boWhoWGhdhERERgzZkwVR0cfEl7JmBSKnp4e9PT0qjsMqgKCICA3NxdqavwxpUgK7pP0LjVq1KiCaOhDxgoOFeLm5gY/Pz/MmDEDxsbGsLCwwPz588X1SUlJGDNmDMzMzGBgYIBOnTrh+vXrMvtYuHAhzMzMoK+vj1GjRuGLL76Q6VqKiIiAp6cnTE1NIZVK4erqiqtXr4rrbW1tAQCffPIJJBKJ+PzNLqqjR49CS0urUCncz88Prq6u4vPz58+jQ4cO0NbWhpWVFfz8/JCWllbu86Ssyvv++/j4oE+fPjL79Pf3h5ubm7g+PDwc33//PSQSCSQSCR4+fCh2bRw9ehStWrWCpqYmzpw5gwcPHqB3794wNzeHnp4eWrdujePHj1fBmVBebm5umDRpEiZNmgRDQ0OYmJjgq6++Eu+AnZiYiOHDh8PIyAg6Ojro2rUr7t+/L27/6NEj9OzZE0ZGRtDV1UWjRo1w6NAhALJdVKdPn8Znn32GpKQk8b0u+Cy92UU1ePBgDBo0SCbG7OxsmJqaYsuWLQDyE97g4GDUqVMH2traaNq0KX7++edKPlOkyJjgUJFCQkKgq6uLS5cuITg4GF9//TXCwsIgCAK6d++O+Ph4HDp0CJGRkWjRogXc3d3x33//AQB27tyJRYsWYcmSJYiMjIS1tTXWrl0rs/+UlBSMGDECZ86cwcWLF2Fvb49u3bqJd1SPiIgAAGzZsgVxcXHi8zd5eHjA0NAQv/zyi7gsNzcX+/btw5AhQwAAN2/ehJeXF/r27YsbN25g7969OHv2LCZNmlQp501ZlOf9f5fvv/8ezs7OGD16NOLi4hAXFwcrKytx/YwZMxAUFITo6Gg0adIEqamp6NatG44fP45r167By8sLPXv2xOPHjyvr8D8IISEhUFNTw6VLl7By5UosX74cP/74I4D8JPTKlSs4ePAgLly4AEEQ0K1bN2RnZwMAJk6ciMzMTPz555+4efMmlixZUmRl1cXFBStWrICBgYH4XgcEBBRqN2TIEBw8eBCpqanisqNHjyItLQ2ffvopAOCrr77Cli1bsHbtWty+fRtTpkzB0KFDER4eXhmnh5SBQPQWV1dX4eOPP5ZZ1rp1a2HmzJnCiRMnBAMDAyEjI0Nmfd26dYX169cLgiAIbdu2FSZOnCiz/qOPPhKaNm1a7Gvm5OQI+vr6wm+//SYuAyCEhobKtJs3b57Mfvz8/IROnTqJz48ePSpoaGgI//33nyAIgjBs2DBhzJgxMvs4c+aMoKKiIqSnpxcbz4esvO//iBEjhN69e8us//zzzwVXV1eZ1/j8889l2pw6dUoAIBw4cOCdMTZs2FBYtWqV+NzGxkZYvnz5uw+OBEHIP/+Ojo5CXl6euGzmzJmCo6OjcO/ePQGAcO7cOXHdixcvBG1tbWHfvn2CIAiCk5OTMH/+/CL3XfA+JiYmCoIgCFu2bBGkUmmhdm++Z1lZWYKpqamwbds2cf3gwYOF/v37C4IgCKmpqYKWlpZw/vx5mX34+voKgwcPLvXx04eBFRwqUpMmTWSe16xZEwkJCYiMjERqaipMTEzE8TB6enqIiYnBgwcPAAB3795FmzZtZLZ/+3lCQgLGjRuH+vXrQyqVQiqVIjU1tdR/lQ8ZMgSnT5/G06dPAeRXj7p16wYjIyMAQGRkJLZu3SoTq5eXF/Ly8hATE1Oq1/qQlOf9L69WrVrJPE9LS8OMGTPQsGFDGBoaQk9PD3/99RcrOOXUrl07SCQS8bmzszPu37+PO3fuQE1NDW3bthXXmZiYwMHBAdHR0QDyu4EXLlyIjz76CPPmzcONGzfKFYu6ujr69++PnTt3Ash/z3/99VexEnvnzh1kZGTA09NT5nO3bdu2CvvckfLh6D0qkrq6usxziUSCvLw85OXloWbNmjh9+nShbd6cKfHmD04AYt9+AR8fHzx//hwrVqyAjY0NNDU14ezsjKysrFLF2aZNG9StWxd79uzB+PHjERoaKvbZA0BeXh7Gjh0LPz+/QttaW1uX6rU+JOV5/1VUVAq93wVdGyWhq6sr83z69Ok4evQovvvuO9SrVw/a2tro169fqT8rVD6CIIjf61GjRsHLywt//PEHjh07hqCgICxduhSTJ08u8/6HDBkCV1dXJCQkICwsDFpaWujatSuA/O8xAPzxxx+oVauWzHa81xUVhwkOlUqLFi0QHx8PNTU1ceDv2xwcHHD58mUMGzZMXHblyhWZNmfOnMGaNWvQrVs3AEBsbCxevHgh00ZdXR25ubnvjMnb2xs7d+5E7dq1oaKigu7du8vEe/v2bdSrV6+kh0hylOT9r1GjBm7duiWzLCoqSiZp0tDQKNF7C+R/Vnx8fPDJJ58AAFJTU/Hw4cMyxU//7+LFi4We29vbo2HDhsjJycGlS5fg4uICAHj58iXu3bsHR0dHsb2VlRXGjRuHcePGYdasWdi4cWORCU5J32sXFxdYWVlh7969OHz4MPr37w8NDQ0AQMOGDaGpqYnHjx/LTCAgkoddVFQqHh4ecHZ2Rp8+fXD06FE8fPgQ58+fx1dffSUmMZMnT8amTZsQEhKC+/fvY+HChbhx44ZMVadevXrYvn07oqOjcenSJQwZMgTa2toyr2Vra4sTJ04gPj4eiYmJxcY0ZMgQXL16FYsWLUK/fv2gpaUlrps5cyYuXLiAiRMnIioqCvfv38fBgwfL9Zfmh6wk73+nTp1w5coVbNu2Dffv38e8efMKJTy2tra4dOkSHj58iBcvXoh/oRelXr162L9/P6KionD9+nV4e3vLbU8lExsbi6lTp+Lu3bvYvXs3Vq1ahc8//xz29vbo3bs3Ro8ejbNnz+L69esYOnQoatWqhd69ewPInxV39OhRxMTE4OrVqzh58qRM8vMmW1tbpKam4sSJE3jx4gVev35dZDuJRAJvb2+sW7cOYWFhGDp0qLhOX18fAQEBmDJlCkJCQvDgwQNcu3YNP/zwA0JCQir+5JBSYIJDpSKRSHDo0CF06NABI0eORP369TFo0CA8fPgQ5ubmAPITjlmzZiEgIAAtWrRATEwMfHx8ZBKPzZs3IzExEc2bN8ewYcPg5+cHMzMzmddaunQpwsLCYGVlhebNmxcbk729PVq3bo0bN26IffYFmjRpgvDwcNy/fx/t27dH8+bNMWfOHNSsWbMCz8qHoyTvv5eXF+bMmYMZM2agdevWSElJwfDhw2X2ExAQAFVVVTRs2BA1atSQO55m+fLlMDIygouLC3r27AkvLy+0aNGiUo/zQzB8+HCkp6ejTZs2mDhxIiZPnixeeG/Lli1o2bIlevToAWdnZwiCgEOHDolVuNzcXEycOBGOjo7o0qULHBwcsGbNmiJfx8XFBePGjcPAgQNRo0YNBAcHFxvTkCFDcOfOHdSqVQsfffSRzLpvvvkGc+fORVBQEBwdHeHl5YXffvsNdnZ2FXRGSNlIhLc7y4kqgaenJywsLLB9+/bqDoXog+fm5oZmzZrxVgmk1DgGhyrc69evsW7dOnh5eUFVVRW7d+/G8ePHERYWVt2hERHRB4IJDlW4gm6MhQsXIjMzEw4ODvjll1/g4eFR3aEREdEHgl1UREREpHQ4yJiIiIiUDhMcIiIiUjpMcIiIiEjpMMEhIiIipcMEh4hkzJ8/H82aNROf+/j4oE+fPlUex8OHDyGRSBAVFVVsG1tb21Jdy2Xr1q0y90wrK4lEggMHDpR7P0RUeZjgECkAHx8fSCQSSCQSqKuro06dOggICEBaWlqlv/b333+PrVu3lqhtSZISIqKqwOvgECmILl26YMuWLcjOzsaZM2cwatQopKWlYe3atYXaZmdnF7ojeFlJpdIK2Q8RUVViBYdIQWhqasLCwgJWVlbw9vbGkCFDxG6Sgm6lzZs3o06dOtDU1IQgCEhKSsKYMWNgZmYGAwMDdOrUCdevX5fZ7+LFi2Fubg59fX34+voiIyNDZv3bXVR5eXlYsmQJ6tWrB01NTVhbW2PRokUAIN4XqHnz5pBIJHBzcxO327JlCxwdHaGlpYUGDRoUunfR5cuX0bx5c2hpaaFVq1a4du1aqc/RsmXL4OTkBF1dXVhZWWHChAlITU0t1O7AgQOoX78+tLS04OnpidjYWJn1v/32G1q2bAktLS3UqVMHCxYsQE5OTqnjIaLqwwSHSEFpa2sjOztbfP73339j3759+OWXX8Quou7duyM+Ph6HDh1CZGQkWrRoAXd3d/z3338AgH379mHevHlYtGgRrly5gpo1axZ708QCs2bNwpIlSzBnzhzcuXMHu3btEm+0efnyZQDA8ePHERcXh/379wMANm7ciNmzZ2PRokWIjo5GYGAg5syZI94JOi0tDT169ICDgwMiIyMxf/58BAQElPqcqKioYOXKlbh16xZCQkJw8uRJzJgxQ6bN69evsWjRIoSEhODcuXNITk7GoEGDxPVHjx7F0KFD4efnhzt37mD9+vXYunWrmMQRkYIQiOi9N2LECKF3797i80uXLgkmJibCgAEDBEEQhHnz5gnq6upCQkKC2ObEiROCgYGBkJGRIbOvunXrCuvXrxcEQRCcnZ2FcePGyaxv27at0LRp0yJfOzk5WdDU1BQ2btxYZJwxMTECAOHatWsyy62srIRdu3bJLPvmm28EZ2dnQRAEYf369YKxsbGQlpYmrl+7dm2R+3qTjY2NsHz58mLX79u3TzAxMRGfb9myRQAgXLx4UVwWHR0tABAuXbokCIIgtG/fXggMDJTZz/bt24WaNWuKzwEIoaGhxb4uEVU/jsEhUhC///479PT0kJOTg+zsbPTu3RurVq0S19vY2KBGjRri88jISKSmpsLExERmP+np6Xjw4AEAIDo6GuPGjZNZ7+zsjFOnThUZQ3R0NDIzM+Hu7l7iuJ8/f47Y2Fj4+vpi9OjR4vKcnBxxfE90dDSaNm0KHR0dmThK69SpUwgMDMSdO3eQnJyMnJwcZGRkIC0tDbq6ugAANTU1tGrVStymQYMGMDQ0RHR0NNq0aYPIyEhERETIVGxyc3ORkZGB169fy8RIRO8vJjhECqJjx45Yu3Yt1NXVYWlpWWgQccEv8AJ5eXmoWbMmTp8+XWhfZZ0qra2tXept8vLyAOR3U7Vt21ZmnaqqKgBAqIBb4j169AjdunXDuHHj8M0338DY2Bhnz56Fr6+vTFcekD/N+20Fy/Ly8rBgwQL07du3UBstLa1yx0lEVYMJDpGC0NXVRb169UrcvkWLFoiPj4eamhpsbW2LbOPo6IiLFy9i+PDh4rKLFy8Wu097e3toa2vjxIkTGDVqVKH1GhoaAPIrHgXMzc1Rq1Yt/PPPPxgyZEiR+23YsCG2b9+O9PR0MYmSF0dRrly5gpycHCxduhQqKvnDC/ft21eoXU5ODq5cuYI2bdoAAO7evYtXr16hQYMGAPLP2927d0t1rono/cMEh0hJeXh4wNnZGX369MGSJUvg4OCAp0+f4tChQ+jTpw9atWqFzz//HCNGjECrVq3w8ccfY+fOnbh9+zbq1KlT5D61tLQwc+ZMzJgxAxoaGvjoo4/w/Plz3L59G76+vjAzM4O2tjaOHDmC2rVrQ0tLC1KpFPPnz4efnx8MDAzQtWtXZGZm4sqVK0hMTMTUqVPh7e2N2bNnw9fXF1999RUePnyI7777rlTHW7duXeTk5GDVqlXo2bMnzp07h3Xr1hVqp66ujsmTJ2PlypVQV1fHpEmT0K5dOzHhmTt3Lnr06AErKyv0798fKioquHHjBm7evImFCxeW/o0gomrBWVRESkoikeDQoUPo0KEDRo4cifr162PQoEF4+PChOOtp4MCBmDt3LmbOnImWLVvi0aNHGD9+vNz9zpkzB9OmTcPcuXPh6OiIgQMHIiEhAUD++JaVK1di/fr1sLS0RO/evQEAo0aNwo8//oitW7fCyckJrq6u2Lp1qzitXE9PD7/99hvu3LmD5s2bY/bs2ViyZEmpjrdZs2ZYtmwZlixZgsaNG2Pnzp0ICgoq1E5HRwczZ86Et7c3nJ2doa2tjT179ojrvby88PvvvyMsLAytW7dGu3btsGzZMtjY2JQqHiKqXhKhIjq/iYiIiN4jrOAQERGR0mGCQ0REREqHCQ4REREpHSY4REREpHSY4BAREZHSYYJDRERESocJDhERESkdJjhERESkdJjgEBERkdJhgkNERERKhwkOERERKR0mOERERKR0/g+JzX6YyeizhwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test_2, y_pred_glove, labels = best_model.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix = cm, display_labels = best_model.classes_)\n",
    "disp.plot(cmap = 'Greens', values_format = 'd')\n",
    "\n",
    "plt.title(\"Confusion Matrix - GloVe (Fine-Tuned Best Model)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8580f67b-6f51-47b7-b576-f4451d85470c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### **SUMMARY**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529fbae4-6744-493d-924d-de1a7e7fc6ca",
   "metadata": {},
   "source": [
    "> Based on both accuracy and F1-score, the best-performing model is Model 9 (GloVe with fine-tuning, without SMOTE), achieving 74% accuracy and a macro F1 of 0.73.  \n",
    "> This strong performance is likely due to the use of a pretrained GloVe model trained on Twitter data, which aligns well with the linguistic style and structure of the dataset, also composed of tweets.  \n",
    "> Another observation is that while SMOTE generally helps other models by balancing class representation, GloVe performs well even without it.  \n",
    "> This suggests that GloVe’s global co-occurrence embeddings already capture the underlying relationships between words across classes, reducing the need for additional balancing.  \n",
    "> However, for other representations such as BOW or TF-IDF, SMOTE remains beneficial to improve model fairness and recall for minority sentiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (text mining)",
   "language": "python",
   "name": "textmining"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
